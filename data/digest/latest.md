# Daily AI SOTA Digest - 2026-02-15

Focus: AI Platform Engineering

## 1. Moonshine v2: Ergodic Streaming Encoder ASR for Latency-Critical Speech Applications
- Type: paper | Source: arxiv_cs_lg
- URL: http://arxiv.org/abs/2602.12241v1
- Score: 8.272 | Reliability: 1.0 | Maturity: production-ready
- Tags: inference, latency, cost
- Why it matters: Likely impact on inference, latency, cost workflows and platform decisions.

## 2. Running Pydantic's Monty Rust sandboxed Python subset in WebAssembly
- Type: news | Source: simon_willison
- URL: https://simonwillison.net/2026/Feb/6/pydantic-monty/#atom-everything
- Score: 7.51 | Reliability: 1.0 | Maturity: production-ready
- Tags: latency, cost, agent
- Why it matters: Likely impact on latency, cost, agent workflows and platform decisions.

## 3. Show HN: Agent Lens – Code assistant observability in VSCode
- Type: news | Source: hackernews_ai
- URL: https://github.com/23min/agent-lens
- Score: 7.287 | Reliability: 1.0 | Maturity: research
- Tags: observability, agent
- Why it matters: Likely impact on observability, agent workflows and platform decisions.

## 4. Inference Providers Cut AI Costs by 10x with Open Source Models on Blackwell
- Type: news | Source: hackernews_ai
- URL: https://blogs.nvidia.com/blog/inference-open-source-models-blackwell-reduce-cost-per-token/
- Score: 7.193 | Reliability: 1.0 | Maturity: research
- Tags: inference, cost
- Why it matters: Likely impact on inference, cost workflows and platform decisions.

## 5. Presentation: Building Embedding Models for Large-Scale Real-World Applications
- Type: news | Source: infoq_ai_ml
- URL: https://www.infoq.com/presentations/llm-large-scale-applications/?utm_campaign=infoq_content&utm_source=infoq&utm_medium=feed&utm_term=AI%2C+ML+%26+Data+Engineering
- Score: 6.918 | Reliability: 1.0 | Maturity: production-ready
- Tags: latency, rag
- Why it matters: Likely impact on latency, rag workflows and platform decisions.

## 6. Covering electricity price increases from our data centers
- Type: news | Source: simon_willison
- URL: https://simonwillison.net/2026/Feb/12/covering-electricity-price-increases/#atom-everything
- Score: 6.882 | Reliability: 1.0 | Maturity: research
- Tags: inference, cost
- Why it matters: Likely impact on inference, cost workflows and platform decisions.

## 7. v0.16.0
- Type: release | Source: vllm_releases
- URL: https://github.com/vllm-project/vllm/releases/tag/v0.16.0
- Score: 14.697 | Reliability: 1.0 | Maturity: production-ready
- Tags: serving, throughput, optimization, quantization, triton
- Why it matters: Major LLM serving infra release: 30.8% throughput gains, async+PP, realtime API, RLHF workflow improvements for production deployment

## 8. v0.15.0
- Type: release | Source: vllm_releases
- URL: https://github.com/vllm-project/vllm/releases/tag/v0.15.0
- Score: 14.604 | Reliability: 1.0 | Maturity: production-ready
- Tags: inference, throughput, optimization, quantization, triton
- Why it matters: vLLM v0.15.0 delivers production-critical infra: async+pipeline parallelism, Mamba prefix caching (~2x speedup), session-based streaming, multi-hardware perf gains (65% FP4 faster on Blackwell)—directly enables reliable coding-agent serving at scale.

## 9. Release 2.59.0 corresponding to NGC container 25.06
- Type: release | Source: triton_releases
- URL: https://github.com/triton-inference-server/server/releases/tag/v2.59.0
- Score: 10.9 | Reliability: 1.0 | Maturity: production-ready
- Tags: inference, latency, throughput, agent, triton
- Why it matters: Generic inference server release notes; lacks agentic coding, automation, or delivery pipeline relevance.

## 10. Scaling Verification Can Be More Effective than Scaling Policy Learning for Vision-Language-Action Alignment
- Type: paper | Source: arxiv_cs_ai
- URL: http://arxiv.org/abs/2602.12281v1
- Score: 6.476 | Reliability: 1.0 | Maturity: production-ready
- Tags: inference, benchmark
- Why it matters: Likely impact on inference, benchmark workflows and platform decisions.

## 11. Agentic Test-Time Scaling for WebAgents
- Type: paper | Source: arxiv_cs_ai
- URL: http://arxiv.org/abs/2602.12276v1
- Score: 6.475 | Reliability: 1.0 | Maturity: production-ready
- Tags: inference, agent
- Why it matters: Likely impact on inference, agent workflows and platform decisions.

## 12. MonarchRT: Efficient Attention for Real-Time Video Generation
- Type: paper | Source: arxiv_cs_lg
- URL: http://arxiv.org/abs/2602.12271v1
- Score: 6.475 | Reliability: 1.0 | Maturity: research
- Tags: cost, triton
- Why it matters: Likely impact on cost, triton workflows and platform decisions.
