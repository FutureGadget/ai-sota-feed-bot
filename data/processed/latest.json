[
  {
    "id": "80a9e576f04115fb",
    "source": "simon_willison",
    "source_weight": 1.25,
    "title": "SWE-bench February 2026 leaderboard update",
    "url": "https://simonwillison.net/2026/Feb/19/swe-bench/#atom-everything",
    "summary": "<p><strong><a href=\"https://www.swebench.com/\">SWE-bench February 2026 leaderboard update</a></strong></p>\nSWE-bench is one of the benchmarks that the labs love to list in their model releases. The official leaderboard is infrequently updated but they just did a full run of it against the current generation of models, which is notable because it's always good to see benchmark results like this that <em>weren't</em> self-reported by the labs.</p>\n<p>The fresh results are for their \"Bash Only\" benchmark, which runs their <a href=\"https://github.com/SWE-agent/mini-swe-agent\">mini-swe-bench</a> agent (~9,000 lines of Python, <a href=\"https://github.com/SWE-agent/mini-swe-agent/blob/v2.2.1/src/minisweagent/config/benchmarks/swebench.yaml\">here are the prompts</a> they use) against the <a href=\"https://huggingface.co/datasets/princeton-nlp/SWE-bench\">SWE-bench</a> dataset of coding problems - 2,294 real-world examples pulled from 12 open source repos: <a href=\"https://github.com/django/django\">django/django</a> (850), <a href=\"https://github.com/sympy/sympy\">sympy/sympy</a> (386), <a href=\"https://github.com/scikit-learn/scikit-learn\">scikit-learn/scikit-learn</a> (229), <a href=\"https://github.com/sphinx-doc/sphinx\">sphinx-doc/sphinx</a> (187), <a href=\"https://github.com/matplotlib/matplotlib\">matplotlib/matplotlib</a> (184), <a href=\"https://github.com/pytest-dev/pytest\">pytest-dev/pytest</a> (119), <a href=\"https://github.com/pydata/xarray\">pydata/xarray</a> (110), <a href=\"https://github.com/astropy/astropy\">astropy/astropy</a> (95), <a href=\"https://github.com/pylint-dev/pylint\">pylint-dev/pylint</a> (57), <a href=\"https://github.com/psf/requests\">psf/requests</a> (44), <a href=\"https://github.com/mwaskom/seaborn\">mwaskom/seaborn</a> (22), <a href=\"https://github.com/pallets/flask\">pallets/flask</a> (11).</p>\n<p><strong>Correction</strong>: <em>The Bash only benchmark runs against SWE-bench Verified, not original SWE-bench. Verified is a manually curated subset of 500 samples <a href=\"https://openai.com/index/introducing-swe-bench-verified/\">described here</a>, funded by OpenAI. Here's <a href=\"https://huggingface.co/datasets/princeton-nlp/SWE-bench_Verified\">SWE-bench Verified</a> on Hugging Face - since it's just 2.1MB of Parquet it's easy to browse <a href=\"https://lite.datasette.io/?parquet=https%3A%2F%2Fhuggingface.co%2Fdatasets%2Fprinceton-nlp%2FSWE-bench_Verified%2Fresolve%2Fmain%2Fdata%2Ftest-00000-of-00001.parquet#/data/test-00000-of-00001?_facet=repo\">using Datasette Lite</a>, which cuts those numbers down to django/django (231), sympy/sympy (75), sphinx-doc/sphinx (44), matplotlib/matplotlib (34), scikit-learn/scikit-learn (32), astropy/astropy (22), pydata/xarray (22), pytest-dev/pytest (19), pylint-dev/pylint (10), psf/requests (8), mwaskom/seaborn (2), pallets/flask (1)</em>.</p>\n<p>Here's how the top ten models performed:</p>\n<p><img alt=\"Bar chart showing &quot;% Resolved&quot; by &quot;Model&quot;. Bars in descending order: Claude 4.5 Opus (high reasoning) 76.8%, Gemini 3 Flash (high reasoning) 75.8%, MiniMax M2.5 (high reasoning) 75.8%, Claude Opus 4.6 75.6%, GLM-5 (high reasoning) 72.8%, GPT-5.2 (high reasoning) 72.8%, Claude 4.5 Sonnet (high reasoning) 72.8%, Kimi K2.5 (high reasoning) 71.4%, DeepSeek V3.2 (high reasoning) 70.8%, Claude 4.5 Haiku (high reasoning) 70.0%, and a partially visible final bar at 66.6%.\" src=\"https://static.simonwillison.net/static/2026/swbench-feb-2026.jpg\" /></p>\n<p>It's interesting to see Claude Opus 4.5 beat Opus 4.6, though only by about a percentage point. 4.5 Opus is top, then Gemini 3 Flash, then MiniMax M2.5 - a 229B model released <a href=\"https://www.minimax.io/news/minimax-m25\">last week</a> by Chinese lab MiniMax. GLM-5, Kimi K2.5 and DeepSeek V3.2 are three more Chinese models that make the top ten as well.</p>\n<p>OpenAI's GPT-5.2 is their highest performing model at position 6, but it's worth noting that their best coding model, GPT-5.3-Codex, is not represented - maybe because it's not yet available in the OpenAI API.</p>\n<p>This benchmark uses the same system prompt for every model, which is important for a fair comparison but does mean that the quality of the different harnesses or optimized prompts is not being measured here.</p>\n<p>The chart above is a screenshot from the SWE-bench website, but their charts don't include the actual percentage values visible on the bars. I successfully used Claude for Chrome to add these - <a href=\"https://claude.ai/share/81a0c519-c727-4caa-b0d4-0d866375d0da\">transcript here</a>. My prompt sequence included:</p>\n<blockquote>\n<p>Use claude in chrome to open https://www.swebench.com/</p>\n<p>Click on \"Compare results\" and then select \"Select top 10\"</p>\n<p>See those bar charts? I want them to display the percentage on each bar so I can take a better screenshot, modify the page like that</p>\n</blockquote>\n<p>I'm impressed at how well this worked - Claude injected custom JavaScript into the page to draw additional labels on top of the existing chart.</p>\n<p><img alt=\"Screenshot of a Claude AI conversation showing browser automation. A thinking step reads &quot;Pivoted strategy to avoid recursion issues with chart labeling &gt;&quot; followed by the message &quot;Good, the chart is back. Now let me carefully add the labels using an inline plugin on the chart instance to avoid the recursion issue.&quot; A collapsed &quot;Browser_evaluate&quot; section shows a browser_evaluate tool call with JavaScript code using Chart.js canvas context to draw percentage labels on bars: meta.data.forEach((bar, index) =&gt; { const value = dataset.data[index]; if (value !== undefined &amp;&amp; value !== null) { ctx.save(); ctx.textAlign = 'center'; ctx.textBaseline = 'bottom'; ctx.fillStyle = '#333'; ctx.font = 'bold 12px sans-serif'; ctx.fillText(value.toFixed(1) + '%', bar.x, bar.y - 5); A pending step reads &quot;Let me take a screenshot to see if it worked.&quot; followed by a completed &quot;Done&quot; step, and the message &quot;Let me take a screenshot to check the result.&quot;\" src=\"https://static.simonwillison.net/static/2026/claude-chrome-draw-on-chart.jpg\" /></p>\n<p><strong>Update</strong>: If you look at the transcript Claude claims to have switched to Playwright, which is confusing because I didn't think I had that configured.\n\n    <p><small></small>Via <a href=\"https://twitter.com/KLieret/status/2024176335782826336\">@KLieret</a></small></p>\n\n\n    <p>Tags: <a href=\"https://simonwillison.net/tags/benchmarks\">benchmarks</a>, <a href=\"https://simonwillison.net/tags/django\">django</a>, <a href=\"https://simonwillison.net/tags/ai\">ai</a>, <a href=\"https://simonwillison.net/tags/openai\">openai</a>, <a href=\"https://simonwillison.net/tags/generative-ai\">generative-ai</a>, <a href=\"https://simonwillison.net/tags/llms\">llms</a>, <a href=\"https://simonwillison.net/tags/anthropic\">anthropic</a>, <a href=\"https://simonwillison.net/tags/claude\">claude</a>, <a href=\"https://simonwillison.net/tags/coding-agents\">coding-agents</a>, <a href=\"https://simonwillison.net/tags/ai-in-china\">ai-in-china</a>, <a href=\"https://simonwillison.net/tags/minimax\">minimax</a></p>",
    "image_url": "https://static.simonwillison.net/static/2026/swbench-feb-2026.jpg",
    "published": "2026-02-19T04:48:47+00:00",
    "collected_at": "2026-02-20T01:20:52.223186+00:00",
    "ingest_batch_id": "20260220-012052",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.839,
    "freshness": 0.598,
    "tier1_quick_score": 2.841,
    "v2_slot": "practitioner_analysis",
    "v2_prefilter_score": 2.687,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "SWE-bench February 2026 leaderboard update SWE-bench is one of the benchmarks that the labs love to list in their model releases. The official leaderboard is infrequently updated but they just did a full run of it aga...",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 3.55,
    "v2_source_bias": 0.08,
    "v2_topical_bias": 0.0,
    "v2_final_score": 3.187,
    "summary_1line": "SWE-bench Feb 2026 leaderboard: Claude 4.5 Opus leads at 76.8% on 500 real-world coding tasks; independent benchmarking shows Gemini, MiniMax, DeepSeek competitive.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.546,
    "v2_global_score": 3.733
  },
  {
    "id": "6fba5ffc6dac4476",
    "source": "claude_code_releases",
    "source_weight": 2.2,
    "title": "v2.1.49",
    "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.49",
    "summary": "<h2>What's changed</h2>\n<ul>\n<li>Fixed Ctrl+C and ESC being silently ignored when background agents are running and the main thread is idle. Pressing twice within 3 seconds now kills all background agents.</li>\n<li>Fixed prompt suggestion cache regression that reduced cache hit rates.</li>\n<li>Fixed <code>plugin enable</code> and <code>plugin disable</code> to auto-detect the correct scope when <code>--scope</code> is not specified, instead of always defaulting to user scope</li>\n<li>Simple mode (<code>CLAUDE_CODE_SIMPLE</code>) now includes the file edit tool in addition to the Bash tool, allowing direct file editing in simple mode.</li>\n<li>Permission suggestions are now populated when safety checks trigger an ask response, enabling SDK consumers to display permission options</li>\n<li>Sonnet 4.5 with 1M context is being removed from the Max plan in favor of our frontier Sonnet 4.6 model, which now has 1M context. Please switch in /model.</li>\n<li>Fixed verbose mode not updating thinking block display when toggled via <code>/config</code> — memo comparators now correctly detect verbose changes</li>\n<li>Fixed unbounded WASM memory growth during long sessions by periodically resetting the tree-sitter parser</li>\n<li>Fixed potential rendering issues caused by stale yoga layout references</li>\n<li>Improved performance in non-interactive mode (<code>-p</code>) by skipping unnecessary API calls during startup</li>\n<li>Improved performance by caching authentication failures for HTTP and SSE MCP servers, avoiding repeated connection attempts to servers requiring auth</li>\n<li>Fixed unbounded memory growth during long-running sessions caused by Yoga WASM linear memory never shrinking</li>\n<li>SDK model info now includes <code>supportsEffort</code>, <code>supportedEffortLevels</code>, and <code>supportsAdaptiveThinking</code> fields so consumers can discover model capabilities.</li>\n<li>Added <code>ConfigChange</code> hook event that fires when configuration files change during a session, enabling enterprise security auditing and optional blocking of settings changes.</li>\n<li>Improved startup performance by caching MCP auth failures to avoid redundant connection attempts</li>\n<li>Improved startup performance by reducing HTTP calls for analytics token counting</li>\n<li>Improved startup performance by batching MCP tool token counting into a single API call</li>\n<li>Fixed <code>disableAllHooks</code> setting to respect managed settings hierarchy — non-managed settings can no longer disable managed hooks set by policy (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26637\">#26637</a>)</li>\n<li>Fixed <code>--resume</code> session picker showing raw XML tags for sessions that start with commands like <code>/clear</code>. Now correctly falls through to the session ID fallback.</li>\n<li>Improved permission prompts for path safety and working directory blocks to show the reason for the restriction instead of a bare prompt with no context</li>\n</ul>",
    "image_url": "",
    "published": "2026-02-19T23:28:27Z",
    "collected_at": "2026-02-20T01:20:52.223186+00:00",
    "ingest_batch_id": "20260220-012052",
    "tier": "tier1",
    "type": "release",
    "source_reliability": 0.839,
    "freshness": 0.967,
    "tier1_quick_score": 4.013,
    "v2_slot": "agent_tooling_releases",
    "v2_prefilter_score": 4.006,
    "llm_label_source": "llm",
    "llm_category": "release",
    "llm_summary_1line": "Claude Code v2.1.49 ships background agent control fixes, prompt cache regression repair, and SDK capability discovery fields for enterprise integration.",
    "llm_why_1line": "Direct fixes for agent reliability (Ctrl+C handling, memory leaks) and SDK introspection; immediately actionable for platform engineers building agentic harnesses.",
    "v2_llm_score": 3.45,
    "v2_source_bias": 0.0,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.905,
    "summary_1line": "Claude Code v2.1.49 fixes signal handling, cache regressions, memory leaks, and adds SDK model capability discovery for enterprise automation.",
    "why_it_matters": "Direct fixes for agent reliability (Ctrl+C handling, memory leaks) and SDK introspection; immediately actionable for platform engineers building agentic harnesses.",
    "v2_slot_priority": 0.533,
    "v2_global_score": 3.438
  },
  {
    "id": "bcc5108faba05996",
    "source": "langgraph_releases",
    "source_weight": 0.95,
    "title": "langgraph-sdk==0.3.8",
    "url": "https://github.com/langchain-ai/langgraph/releases/tag/sdk%3D%3D0.3.8",
    "summary": "<p>Changes since sdk==0.3.7</p>\n<ul>\n<li>release(sdk-py): 0.3.8 (<a class=\"issue-link js-issue-link\" href=\"https://github.com/langchain-ai/langgraph/pull/6873\">#6873</a>)</li>\n<li>feat(sdk-py): add stream_mode, stream_subgraphs, stream_resumable, durability to crons (<a class=\"issue-link js-issue-link\" href=\"https://github.com/langchain-ai/langgraph/pull/6876\">#6876</a>)</li>\n<li>release: langgraph + prebuilt (<a class=\"issue-link js-issue-link\" href=\"https://github.com/langchain-ai/langgraph/pull/6875\">#6875</a>)</li>\n<li>feat(sdk-py): improve store auth type safety and docstrings (<a class=\"issue-link js-issue-link\" href=\"https://github.com/langchain-ai/langgraph/pull/6867\">#6867</a>)</li>\n</ul>",
    "image_url": "",
    "published": "2026-02-19T19:12:53Z",
    "collected_at": "2026-02-20T01:20:52.223186+00:00",
    "ingest_batch_id": "20260220-012052",
    "tier": "tier1",
    "type": "release",
    "source_reliability": 0.839,
    "freshness": 0.896,
    "tier1_quick_score": 2.707,
    "v2_slot": "agent_tooling_releases",
    "v2_prefilter_score": 2.685,
    "llm_label_source": "llm",
    "llm_category": "release",
    "llm_summary_1line": "LangGraph SDK 0.3.8 adds cron job streaming modes (resumable, subgraphs, durability) and improves store auth type safety for production workflows.",
    "llm_why_1line": "Concrete cron reliability & resumability features directly address production agent orchestration; store auth improvements reduce integration bugs.",
    "v2_llm_score": 3.65,
    "v2_source_bias": 0.06,
    "v2_topical_bias": 0.0,
    "v2_final_score": 2.884,
    "summary_1line": "LangGraph SDK 0.3.8 adds streaming modes, subgraph streaming, and durability controls to cron jobs for more flexible agent scheduling and resumable workflows.",
    "why_it_matters": "Concrete cron reliability & resumability features directly address production agent orchestration; store auth improvements reduce integration bugs.",
    "v2_slot_priority": 0.533,
    "v2_global_score": 3.417
  },
  {
    "id": "6ed48b697f4e1625",
    "source": "anthropic_newsroom",
    "source_weight": 1.8,
    "title": "Claude Sonnet 4 6",
    "url": "https://www.anthropic.com/news/claude-sonnet-4-6",
    "summary": "",
    "image_url": "",
    "published": "2026-02-17T18:00:00+00:00",
    "collected_at": "2026-02-20T01:20:52.223186+00:00",
    "ingest_batch_id": "20260220-012052",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.839,
    "freshness": 0.501,
    "tier1_quick_score": 3.103,
    "v2_slot": "frontier_official",
    "v2_prefilter_score": 3.14,
    "llm_label_source": "llm",
    "llm_category": "release",
    "llm_summary_1line": "Claude Sonnet 4.6 update from Anthropic; check release notes for coding capability improvements and inference changes.",
    "llm_why_1line": "Model release relevant to agent platform, but newsroom source lacks technical depth; need detailed benchmarks and capability breakdowns.",
    "v2_llm_score": 3.05,
    "v2_source_bias": 0.06,
    "v2_topical_bias": 0.0,
    "v2_final_score": 2.6,
    "summary_1line": "Claude Sonnet 4.6 announced; model details and performance benchmarks not yet available in public newsroom.",
    "why_it_matters": "Model release relevant to agent platform, but newsroom source lacks technical depth; need detailed benchmarks and capability breakdowns.",
    "v2_slot_priority": 0.659,
    "v2_global_score": 3.259
  },
  {
    "id": "13463e1f08e717b4",
    "source": "simon_willison",
    "source_weight": 1.25,
    "title": "The A.I. Disruption We’ve Been Waiting for Has Arrived",
    "url": "https://simonwillison.net/2026/Feb/18/the-ai-disruption/#atom-everything",
    "summary": "<p><strong><a href=\"https://www.nytimes.com/2026/02/18/opinion/ai-software.html?unlocked_article_code=1.NFA.UkLv.r-XczfzYRdXJ&amp;smid=url-share\">The A.I. Disruption We’ve Been Waiting for Has Arrived</a></strong></p>\nNew opinion piece from Paul Ford in the New York Times. Unsurprisingly for a piece by Paul it's packed with quoteworthy snippets, but a few stood out for me in particular.</p>\n<p>Paul describes the <a href=\"https://simonwillison.net/2026/Jan/4/inflection/\">November moment</a> that so many other programmers have observed, and highlights Claude Code's ability to revive old side projects:</p>\n<blockquote>\n<p>[Claude Code] was always a helpful coding assistant, but in November it suddenly got much better, and ever since I’ve been knocking off side projects that had sat in folders for a decade or longer. It’s fun to see old ideas come to life, so I keep a steady flow. Maybe it adds up to a half-hour a day of my time, and an hour of Claude’s.</p>\n<p>November was, for me and many others in tech, a great surprise. Before, A.I. coding tools were often useful, but halting and clumsy. Now, the bot can run for a full hour and make whole, designed websites and apps that may be flawed, but credible. I spent an entire session of therapy talking about it.</p>\n</blockquote>\n<p>And as the former CEO of a respected consultancy firm (Postlight) he's well positioned to evaluate the potential impact:</p>\n<blockquote>\n<p>When you watch a large language model slice through some horrible, expensive problem — like migrating data from an old platform to a modern one — you feel the earth shifting. I was the chief executive of a software services firm, which made me a professional software cost estimator. When I rebooted my messy personal website a few weeks ago, I realized: I would have paid $25,000 for someone else to do this. When a friend asked me to convert a large, thorny data set, I downloaded it, cleaned it up and made it pretty and easy to explore. In the past I would have charged $350,000.</p>\n<p>That last price is full 2021 retail — it implies a product manager, a designer, two engineers (one senior) and four to six months of design, coding and testing. Plus maintenance. Bespoke software is joltingly expensive. Today, though, when the stars align and my prompts work out, I can do hundreds of thousands of dollars worth of work for fun (fun for me) over weekends and evenings, for the price of the Claude $200-a-month plan.</p>\n</blockquote>\n<p>He also neatly captures the inherent community tension involved in exploring this technology:</p>\n<blockquote>\n<p>All of the people I love hate this stuff, and all the people I hate love it. And yet, likely because of the same personality flaws that drew me to technology in the first place, I am annoyingly excited.</p>\n</blockquote>\n\n\n    <p>Tags: <a href=\"https://simonwillison.net/tags/new-york-times\">new-york-times</a>, <a href=\"https://simonwillison.net/tags/paul-ford\">paul-ford</a>, <a href=\"https://simonwillison.net/tags/careers\">careers</a>, <a href=\"https://simonwillison.net/tags/ai\">ai</a>, <a href=\"https://simonwillison.net/tags/generative-ai\">generative-ai</a>, <a href=\"https://simonwillison.net/tags/llms\">llms</a>, <a href=\"https://simonwillison.net/tags/ai-assisted-programming\">ai-assisted-programming</a>, <a href=\"https://simonwillison.net/tags/ai-ethics\">ai-ethics</a>, <a href=\"https://simonwillison.net/tags/coding-agents\">coding-agents</a>, <a href=\"https://simonwillison.net/tags/claude-code\">claude-code</a></p>",
    "image_url": "",
    "published": "2026-02-18T17:07:31+00:00",
    "collected_at": "2026-02-20T01:20:52.223186+00:00",
    "ingest_batch_id": "20260220-012052",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.839,
    "freshness": 0.447,
    "tier1_quick_score": 2.728,
    "v2_slot": "practitioner_analysis",
    "v2_prefilter_score": 2.536,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "The A.I. Disruption We’ve Been Waiting for Has Arrived New opinion piece from Paul Ford in the New York Times. Unsurprisingly for a piece by Paul it's packed with quoteworthy snippets, but a few stood out for me in pa...",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.6,
    "v2_source_bias": 0.08,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.557,
    "summary_1line": "Paul Ford's NYT opinion: Claude Code now handles full project workflows in hours, reshaping economics of bespoke software delivery.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.546,
    "v2_global_score": 3.103
  },
  {
    "id": "8de56f934385a8fc",
    "source": "infoq_ai_ml",
    "source_weight": 1.15,
    "title": "Hugging Face Introduces Community Evals for Transparent Model Benchmarking",
    "url": "https://www.infoq.com/news/2026/02/hugging-face-evals/?utm_campaign=infoq_content&utm_source=infoq&utm_medium=feed&utm_term=AI%2C+ML+%26+Data+Engineering",
    "summary": "<img src=\"https://res.infoq.com/news/2026/02/hugging-face-evals/en/headerimage/generatedHeaderImage-1771448477065.jpg\" /><p>Hugging Face has launched Community Evals, a feature that enables benchmark datasets on the Hub to host their own leaderboards and automatically collect evaluation results from model repositories.</p> <i>By Daniel Dominguez</i>",
    "image_url": "https://res.infoq.com/news/2026/02/hugging-face-evals/en/headerimage/generatedHeaderImage-1771448477065.jpg",
    "published": "Thu, 19 Feb 2026 10:55:00 GMT",
    "collected_at": "2026-02-20T01:20:52.223186+00:00",
    "ingest_batch_id": "20260220-012052",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.839,
    "freshness": 0.697,
    "tier1_quick_score": 2.807,
    "v2_slot": "practitioner_analysis",
    "v2_prefilter_score": 2.686,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "Hugging Face has launched Community Evals, a feature that enables benchmark datasets on the Hub to host their own leaderboards and automatically collect evaluation results from model repositories. By Daniel Dominguez",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.75,
    "v2_source_bias": 0.08,
    "v2_topical_bias": 0.0,
    "v2_final_score": 2.522,
    "summary_1line": "Hugging Face adds community-driven leaderboards to benchmark datasets, automating eval result collection from model repos.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.546,
    "v2_global_score": 3.068
  },
  {
    "id": "9c7cc346655a7ad3",
    "source": "hackernews_ai",
    "source_weight": 1.1,
    "title": "Show HN: I open-sourced an AI sales CRM – and the \"experience\" problem I learned",
    "url": "https://github.com/dylanmeyford/radiant-ai-crm-oss",
    "summary": "<p>Over the past 12 months I built an AI CRM that changed my life. I funnelled every neuron of sales knowledge I had into it.<p>Today, I open-sourced the whole thing — code, prompts, agents, orchestration - the whole lot.<p><i>What it does:</i><p>- Connects to your email and calendar<p>- Automatically analyses every activity<p>- Joins, records and analyses every meeting<p>- Thinks about every deal like a seasoned sales pro and actively drafts the next best action to move the deal forward.<p>- Consumes your files and playbooks and uses it to draft and inform decisions.<p>- Sends, Schedules, Drafts and Cancels emails<p>- Sends, Schedules, Drafts and Cancels meeting invites<p>- Automatically researches and enriches contacts and deals<p>- Automatically creates meeting agendas<p>- Automatically finds new contacts to add to the deal<p>The output is a set of drafted actions: follow-up emails, meeting agendas, deal risk flags, new stakeholders to add. You wake up, review, approve.<p><i>The hard part + key unlock:</i>\nI built it because I was a founder trying to do EVERYTHING and the sales admin was killing me.<p>It took me 3 whole attempts to get right. I had to think deeply about what a human sales rep is 'actually' doing, consciously and unconsciously, when running a sales motion.<p>Key unlock: sales is all about people. The first versions I built were about the emails and calls. Didn't work. BUT, when I orientated the intelligence processing pipeline to first build up a story on each person in the deal, their responsiveness, role, contributions, what they care about, history, and only after roll that into overall deal health and intelligence - that's when it started behaving like a real rep.<p><i>Why open-source it?</i><p>Honest answer: the math. \nThere are well-funded teams building closed AI CRMs right now. I'm just one dude.\nIf I stay closed, I'm a small fish competing on their terms. \nOpen-sourcing makes me the only one in that category. \nFunded competitors don't need my code — they have their own infra. \nWhat they don't have is an open-source community. A room of genius founders just trying to make the product as great as possible.<p><i>The harder problem building Radiant uncovered:</i><p>Building this taught me something I can't stop thinking about. \nAgents are becoming more and more capable.\nBut the gap between an LLM and an actual professional isn't capability - it's <i>Judgement*<p>An LLM can write a follow-up email. But it doesn't know that a prospect's silence after you mention a competitor isn't them thinking, but actually a deal risk that calls for a battle card and timely landmine email - not a check-in email next week.<p>I only 'know' that because I learnt those signals the hard way by putting the reps in.<p>When I built Radiant, what I was really trying to was encode that judgment into a system.<p>This led me to a side project: a spec called OpenExperts — a structured way for professionals to package their decision heuristics, workflows, and deep domain knowledge into a format any AI agent can consume.<p>My first attempt will be to take the intelligence pipeline from Radiant and transform it into an 'expert package' - then see if OpenClaw can do it all for me.<p>The idea is that any agent could 'install' an expert package and immediately be a top tier expert in that field.<p></i>Links*<p>GitHub: <a href=\"https://github.com/dylanmeyford/radiant-ai-crm-oss\" rel=\"nofollow\">https://github.com/dylanmeyford/radiant-ai-crm-oss</a><p>OpenExperts spec: <a href=\"https://openexperts.ai\" rel=\"nofollow\">https://openexperts.ai</a><p>Happy to go deep on the architecture, the orchestration approach, or the OpenExperts idea — curious what people here think about the \"encoding expertise\" problem.*</p>\n<hr />\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47081553\">https://news.ycombinator.com/item?id=47081553</a></p>\n<p>Points: 2</p>\n<p># Comments: 0</p>",
    "image_url": "",
    "published": "Thu, 19 Feb 2026 23:51:16 +0000",
    "collected_at": "2026-02-20T01:20:52.223186+00:00",
    "ingest_batch_id": "20260220-012052",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.839,
    "freshness": 0.911,
    "tier1_quick_score": 2.918,
    "v2_slot": "community_signal",
    "v2_prefilter_score": 2.85,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "Over the past 12 months I built an AI CRM that changed my life. I funnelled every neuron of sales knowledge I had into it. Today, I open-sourced the whole thing — code, prompts, agents, orchestration - the whole lot....",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.75,
    "v2_source_bias": 0.0,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.49,
    "summary_1line": "Open-source AI CRM agent that automates sales workflows via email/calendar integration; introduces OpenExperts spec for encoding domain expertise into agent behavior.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.503,
    "v2_global_score": 2.993
  },
  {
    "id": "67ebf46c830f2fe0",
    "source": "infoq_ai_ml",
    "source_weight": 1.15,
    "title": "Presentation: DevOps Modernization: AI Agents, Intelligent Observability and Automation",
    "url": "https://www.infoq.com/presentations/devops-modernization-ai-agents/?utm_campaign=infoq_content&utm_source=infoq&utm_medium=feed&utm_term=AI%2C+ML+%26+Data+Engineering",
    "summary": "<img src=\"https://res.infoq.com/presentations/devops-modernization-ai-agents/en/mediumimage/infoq-live-medium-1771422477828.jpg\" /><p>The panelists share how AI is redefining DevOps and SRE practices by moving teams beyond reactive monitoring toward predictive, automated delivery and operations. They discuss integrating AI agents into CI/CD pipelines and feature management to enable intelligent rollouts and machine-speed remediation.</p> <i>By Olalekan Elesin, Patrick Debois, Mallika Rao, Martin Reynolds, Renato Losio</i>",
    "image_url": "https://res.infoq.com/presentations/devops-modernization-ai-agents/en/mediumimage/infoq-live-medium-1771422477828.jpg",
    "published": "Thu, 19 Feb 2026 13:08:00 GMT",
    "collected_at": "2026-02-20T01:20:52.223186+00:00",
    "ingest_batch_id": "20260220-012052",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.839,
    "freshness": 0.737,
    "tier1_quick_score": 2.833,
    "v2_slot": "practitioner_analysis",
    "v2_prefilter_score": 2.726,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "The panelists share how AI is redefining DevOps and SRE practices by moving teams beyond reactive monitoring toward predictive, automated delivery and operations. They discuss integrating AI agents into CI/CD pipeline...",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.4,
    "v2_source_bias": 0.08,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.431,
    "summary_1line": "Panel discusses AI agents in DevOps/SRE for predictive monitoring, CI/CD automation, and intelligent rollouts.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.546,
    "v2_global_score": 2.977
  },
  {
    "id": "e090493a0ff267ce",
    "source": "openai_blog",
    "source_weight": 2.0,
    "title": "Introducing GPT-5.3-Codex-Spark",
    "url": "https://openai.com/index/introducing-gpt-5-3-codex-spark",
    "summary": "Introducing GPT-5.3-Codex-Spark—our first real-time coding model. 15x faster generation, 128k context, now in research preview for ChatGPT Pro users.",
    "image_url": "",
    "published": "Thu, 12 Feb 2026 10:00:00 GMT",
    "collected_at": "2026-02-20T01:20:52.223186+00:00",
    "ingest_batch_id": "20260220-012052",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.839,
    "freshness": 0.101,
    "tier1_quick_score": 2.917,
    "v2_slot": "frontier_official",
    "v2_prefilter_score": 2.94,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "Introducing GPT-5.3-Codex-Spark—our first real-time coding model. 15x faster generation, 128k context, now in research preview for ChatGPT Pro users.",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.2,
    "v2_source_bias": 0.1,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.08,
    "summary_1line": "OpenAI launches GPT-5.3-Codex-Spark with 15x faster code generation and 128k context in research preview.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.659,
    "v2_global_score": 2.739
  },
  {
    "id": "9d95a891a81b27c3",
    "source": "openai_blog",
    "source_weight": 2.0,
    "title": "Beyond rate limits: scaling access to Codex and Sora",
    "url": "https://openai.com/index/beyond-rate-limits",
    "summary": "How OpenAI built a real-time access system combining rate limits, usage tracking, and credits to power continuous access to Sora and Codex.",
    "image_url": "",
    "published": "Fri, 13 Feb 2026 09:00:00 GMT",
    "collected_at": "2026-02-20T01:20:52.223186+00:00",
    "ingest_batch_id": "20260220-012052",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.839,
    "freshness": 0.135,
    "tier1_quick_score": 2.947,
    "v2_slot": "frontier_official",
    "v2_prefilter_score": 2.974,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "How OpenAI built a real-time access system combining rate limits, usage tracking, and credits to power continuous access to Sora and Codex.",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.0,
    "v2_source_bias": 0.1,
    "v2_topical_bias": 0.2,
    "v2_final_score": 1.927,
    "summary_1line": "OpenAI describes rate-limiting and credit-based access architecture for Codex and Sora APIs, addressing scale and fairness.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.659,
    "v2_global_score": 2.586
  },
  {
    "id": "0f43cce4717b58ca",
    "source": "anthropic_research",
    "source_weight": 1.4,
    "title": "Measuring Agent Autonomy",
    "url": "https://www.anthropic.com/research/measuring-agent-autonomy",
    "summary": "",
    "image_url": "",
    "published": "2026-02-18T15:10:00+00:00",
    "collected_at": "2026-02-20T01:20:52.223186+00:00",
    "ingest_batch_id": "20260220-012052",
    "tier": "tier1",
    "type": "research",
    "source_reliability": 0.839,
    "freshness": 0.737,
    "tier1_quick_score": 2.861,
    "v2_slot": "research_watch",
    "v2_prefilter_score": 2.976,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "Measuring Agent Autonomy",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.0,
    "v2_source_bias": 0.4,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.411,
    "summary_1line": "Anthropic research on quantifying agent autonomy levels—framework for evaluating how independently agents can operate without human intervention.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.317,
    "v2_global_score": 2.728
  },
  {
    "id": "c991b4745e961b3e",
    "source": "latent_space",
    "source_weight": 1.2,
    "title": "[AINews] Anthropic's Agent Autonomy study",
    "url": "https://www.latent.space/p/ainews-anthropics-agent-autonomy",
    "summary": "a quiet day lets us dive deep into Anthropic's own version of the METR data",
    "image_url": "https://substackcdn.com/image/fetch/$s_!c74W!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18a91dee-c7fa-409d-9541-b34e24bba31c_1938x1236.png",
    "published": "Thu, 19 Feb 2026 07:55:36 GMT",
    "collected_at": "2026-02-20T01:20:52.223186+00:00",
    "ingest_batch_id": "20260220-012052",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.839,
    "freshness": 0.647,
    "tier1_quick_score": 2.824,
    "v2_slot": "practitioner_analysis",
    "v2_prefilter_score": 2.686,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "a quiet day lets us dive deep into Anthropic's own version of the METR data",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.2,
    "v2_source_bias": 0.0,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.167,
    "summary_1line": "Anthropic publishes Agent Autonomy study examining capability benchmarks; deep dive into internal agentic evaluation methodology.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.546,
    "v2_global_score": 2.713
  },
  {
    "id": "c58d7596e7e871ef",
    "source": "openai_codex_releases",
    "source_weight": 2.2,
    "title": "0.104.0",
    "url": "https://github.com/openai/codex/releases/tag/rust-v0.104.0",
    "summary": "<h2>New Features</h2>\n<ul>\n<li>Added <code>WS_PROXY</code>/<code>WSS_PROXY</code> environment support (including lowercase variants) for websocket proxying in the network proxy. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11784\">#11784</a>)</li>\n<li>App-server v2 now emits notifications when threads are archived or unarchived, enabling clients to react without polling. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12030\">#12030</a>)</li>\n<li>Protocol/core now carry distinct approval IDs for command approvals to support multiple approvals within a single shell command execution flow. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12051\">#12051</a>)</li>\n</ul>\n<h2>Bug Fixes</h2>\n<ul>\n<li><code>Ctrl+C</code>/<code>Ctrl+D</code> now cleanly exits the cwd-change prompt during resume/fork flows instead of implicitly selecting an option. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12040\">#12040</a>)</li>\n<li>Reduced false-positive safety-check downgrade behavior by relying on the response header model (and websocket top-level events) rather than the response body model slug. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12061\">#12061</a>)</li>\n</ul>\n<h2>Documentation</h2>\n<ul>\n<li>Updated docs and schemas to cover websocket proxy configuration, new thread archive/unarchive notifications, and the command approval ID plumbing. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11784\">#11784</a>, <a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12030\">#12030</a>, <a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12051\">#12051</a>)</li>\n</ul>\n<h2>Chores</h2>\n<ul>\n<li>Made the Rust release workflow resilient to <code>npm publish</code> attempts for an already-published version. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12044\">#12044</a>)</li>\n<li>Standardized remote compaction test mocking and refreshed related snapshots to align with the default production-shaped behavior. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12050\">#12050</a>)</li>\n</ul>\n<h2>Changelog</h2>\n<p>Full Changelog: <a class=\"commit-link\" href=\"https://github.com/openai/codex/compare/rust-v0.103.0...rust-v0.104.0\"><tt>rust-v0.103.0...rust-v0.104.0</tt></a></p>\n<ul>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11784\">#11784</a> feat(network-proxy): add websocket proxy env support <a class=\"user-mention notranslate\" href=\"https://github.com/viyatb-oai\">@viyatb-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12044\">#12044</a> don't fail if an npm publish attempt is for an existing version. <a class=\"user-mention notranslate\" href=\"https://github.com/iceweasel-oai\">@iceweasel-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12040\">#12040</a> tui: exit session on Ctrl+C in cwd change prompt <a class=\"user-mention notranslate\" href=\"https://github.com/charley-oai\">@charley-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12030\">#12030</a> app-server: Emit thread archive/unarchive notifications <a class=\"user-mention notranslate\" href=\"https://github.com/euroelessar\">@euroelessar</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12061\">#12061</a> Chore: remove response model check and rely on header model for downgrade <a class=\"user-mention notranslate\" href=\"https://github.com/shijie-oai\">@shijie-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12051\">#12051</a> feat(core): plumb distinct approval ids for command approvals <a class=\"user-mention notranslate\" href=\"https://github.com/owenlin0\">@owenlin0</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12050\">#12050</a> Unify remote compaction snapshot mocks around default endpoint behavior <a class=\"user-mention notranslate\" href=\"https://github.com/charley-oai\">@charley-oai</a></li>\n</ul>",
    "image_url": "",
    "published": "2026-02-18T07:13:02Z",
    "collected_at": "2026-02-20T01:20:52.223186+00:00",
    "ingest_batch_id": "20260220-012052",
    "tier": "tier1",
    "type": "release",
    "source_reliability": 0.839,
    "freshness": 0.471,
    "tier1_quick_score": 3.596,
    "v2_slot": "agent_tooling_releases",
    "v2_prefilter_score": 3.51,
    "llm_label_source": "heuristic",
    "llm_category": "release",
    "llm_summary_1line": "New Features Added WS_PROXY / WSS_PROXY environment support (including lowercase variants) for websocket proxying in the network proxy. ( #11784 ) App-server v2 now emits notifications when threads are archived or una...",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.6,
    "v2_source_bias": 0.0,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.161,
    "summary_1line": "Claude Code 0.104.0 ships websocket proxy support, thread archive notifications, and multi-approval command flow for better workflow orchestration and safety.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.533,
    "v2_global_score": 2.694
  },
  {
    "id": "c35812ccca3ce7be",
    "source": "openai_blog",
    "source_weight": 2.0,
    "title": "Harness engineering: leveraging Codex in an agent-first world",
    "url": "https://openai.com/index/harness-engineering",
    "summary": "By Ryan Lopopolo, Member of the Technical Staff",
    "image_url": "",
    "published": "Wed, 11 Feb 2026 09:00:00 GMT",
    "collected_at": "2026-02-20T01:20:52.223186+00:00",
    "ingest_batch_id": "20260220-012052",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.839,
    "freshness": 0.074,
    "tier1_quick_score": 2.894,
    "v2_slot": "frontier_official",
    "v2_prefilter_score": 2.913,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "By Ryan Lopopolo, Member of the Technical Staff",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.0,
    "v2_source_bias": 0.1,
    "v2_topical_bias": 0.2,
    "v2_final_score": 1.915,
    "summary_1line": "OpenAI explores harness engineering patterns for Codex in agent-first systems, addressing eval and integration challenges.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.659,
    "v2_global_score": 2.574
  },
  {
    "id": "a424c079248a48dd",
    "source": "arxiv_cs_ai",
    "source_weight": 0.85,
    "title": "Towards a Science of AI Agent Reliability",
    "url": "http://arxiv.org/abs/2602.16666v1",
    "summary": "AI agents are increasingly deployed to execute important tasks. While rising accuracy scores on standard benchmarks suggest rapid progress, many agents still continue to fail in practice. This discrepancy highlights a fundamental limitation of current evaluations: compressing agent behavior into a single success metric obscures critical operational flaws. Notably, it ignores whether agents behave consistently across runs, withstand perturbations, fail predictably, or have bounded error severity. Grounded in safety-critical engineering, we provide a holistic performance profile by proposing twelve concrete metrics that decompose agent reliability along four key dimensions: consistency, robustness, predictability, and safety. Evaluating 14 agentic models across two complementary benchmarks, we find that recent capability gains have only yielded small improvements in reliability. By exposing these persistent limitations, our metrics complement traditional evaluations while offering tools for reasoning about how agents perform, degrade, and fail.",
    "image_url": "",
    "published": "2026-02-18T18:05:44Z",
    "collected_at": "2026-02-20T01:20:52.223186+00:00",
    "ingest_batch_id": "20260220-012052",
    "tier": "tier1",
    "type": "paper",
    "source_reliability": 0.839,
    "freshness": 0.756,
    "tier1_quick_score": 2.337,
    "v2_slot": "research_watch",
    "v2_prefilter_score": 2.445,
    "llm_label_source": "heuristic",
    "llm_category": "research",
    "llm_summary_1line": "AI agents are increasingly deployed to execute important tasks. While rising accuracy scores on standard benchmarks suggest rapid progress, many agents still continue to fail in practice. This discrepancy highlights a...",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.65,
    "v2_source_bias": -0.35,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.216,
    "summary_1line": "New reliability framework proposes 12 metrics across consistency, robustness, predictability, and safety to expose why agents fail despite benchmark gains.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.317,
    "v2_global_score": 2.533
  },
  {
    "id": "b7dd9d05bcdf917e",
    "source": "claude_agent_sdk_python_releases",
    "source_weight": 1.3,
    "title": "v0.1.38",
    "url": "https://github.com/anthropics/claude-agent-sdk-python/releases/tag/v0.1.38",
    "summary": "<h3>Internal/Other Changes</h3>\n<ul>\n<li>Updated bundled Claude CLI to version 2.1.47</li>\n</ul>\n<hr />\n<p><strong>PyPI:</strong> <a href=\"https://pypi.org/project/claude-agent-sdk/0.1.38/\" rel=\"nofollow\">https://pypi.org/project/claude-agent-sdk/0.1.38/</a></p>\n<div class=\"highlight highlight-source-shell notranslate position-relative overflow-auto\"><pre>pip install claude-agent-sdk==0.1.38</pre></div>",
    "image_url": "",
    "published": "2026-02-18T21:57:56Z",
    "collected_at": "2026-02-20T01:20:52.223186+00:00",
    "ingest_batch_id": "20260220-012052",
    "tier": "tier1",
    "type": "release",
    "source_reliability": 0.839,
    "freshness": 0.613,
    "tier1_quick_score": 2.823,
    "v2_slot": "agent_tooling_releases",
    "v2_prefilter_score": 2.752,
    "llm_label_source": "heuristic",
    "llm_category": "release",
    "llm_summary_1line": "Internal/Other Changes Updated bundled Claude CLI to version 2.1.47 PyPI: https://pypi.org/project/claude-agent-sdk/0.1.38/ pip install claude-agent-sdk==0.1.38",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.25,
    "v2_source_bias": 0.0,
    "v2_topical_bias": 0.2,
    "v2_final_score": 1.959,
    "summary_1line": "Claude Agent SDK v0.1.38 updates bundled Claude CLI to 2.1.47 with internal/other changes.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.533,
    "v2_global_score": 2.492
  },
  {
    "id": "e670d8ea6dbcb36a",
    "source": "arxiv_cs_lg",
    "source_weight": 0.85,
    "title": "Parameter-free representations outperform single-cell foundation models on downstream benchmarks",
    "url": "http://arxiv.org/abs/2602.16696v1",
    "summary": "Single-cell RNA sequencing (scRNA-seq) data exhibit strong and reproducible statistical structure. This has motivated the development of large-scale foundation models, such as TranscriptFormer, that use transformer-based architectures to learn a generative model for gene expression by embedding genes into a latent vector space. These embeddings have been used to obtain state-of-the-art (SOTA) performance on downstream tasks such as cell-type classification, disease-state prediction, and cross-species learning. Here, we ask whether similar performance can be achieved without utilizing computationally intensive deep learning-based representations. Using simple, interpretable pipelines that rely on careful normalization and linear methods, we obtain SOTA or near SOTA performance across multiple benchmarks commonly used to evaluate single-cell foundation models, including outperforming foundation models on out-of-distribution tasks involving novel cell types and organisms absent from the training data. Our findings highlight the need for rigorous benchmarking and suggest that the biology of cell identity can be captured by simple linear representations of single cell gene expression data.",
    "image_url": "",
    "published": "2026-02-18T18:42:29Z",
    "collected_at": "2026-02-20T01:20:52.223186+00:00",
    "ingest_batch_id": "20260220-012052",
    "tier": "tier1",
    "type": "paper",
    "source_reliability": 0.839,
    "freshness": 0.761,
    "tier1_quick_score": 2.342,
    "v2_slot": "research_watch",
    "v2_prefilter_score": 2.45,
    "llm_label_source": "heuristic",
    "llm_category": "research",
    "llm_summary_1line": "Single-cell RNA sequencing (scRNA-seq) data exhibit strong and reproducible statistical structure. This has motivated the development of large-scale foundation models, such as TranscriptFormer, that use transformer-ba...",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.55,
    "v2_source_bias": -0.35,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.132,
    "summary_1line": "Study shows simple linear methods match transformer foundation models on single-cell RNA benchmarks, questioning complexity trade-offs.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.317,
    "v2_global_score": 2.449
  },
  {
    "id": "e2fb706f0e744611",
    "source": "anthropic_newsroom",
    "source_weight": 1.8,
    "title": "Donate Public First Action",
    "url": "https://www.anthropic.com/news/donate-public-first-action",
    "summary": "",
    "image_url": "",
    "published": "2026-02-12T11:45:00+00:00",
    "collected_at": "2026-02-20T01:20:52.223186+00:00",
    "ingest_batch_id": "20260220-012052",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.839,
    "freshness": 0.103,
    "tier1_quick_score": 2.719,
    "v2_slot": "frontier_official",
    "v2_prefilter_score": 2.742,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "Donate Public First Action",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.0,
    "v2_source_bias": 0.06,
    "v2_topical_bias": 0.0,
    "v2_final_score": 1.681,
    "summary_1line": "Anthropic announces corporate donation to Public First Action, a nonprofit focused on AI policy advocacy.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.659,
    "v2_global_score": 2.34
  },
  {
    "id": "d90c001d10ad2d99",
    "source": "anthropic_newsroom",
    "source_weight": 1.8,
    "title": "Covering Electricity Price Increases",
    "url": "https://www.anthropic.com/news/covering-electricity-price-increases",
    "summary": "",
    "image_url": "",
    "published": "2026-02-11T20:23:00+00:00",
    "collected_at": "2026-02-20T01:20:52.223186+00:00",
    "ingest_batch_id": "20260220-012052",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.839,
    "freshness": 0.085,
    "tier1_quick_score": 2.704,
    "v2_slot": "frontier_official",
    "v2_prefilter_score": 2.724,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "Covering Electricity Price Increases",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.0,
    "v2_source_bias": 0.06,
    "v2_topical_bias": 0.0,
    "v2_final_score": 1.677,
    "summary_1line": "Anthropic announces pricing adjustments to cover rising electricity costs for Claude API and deployments.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.659,
    "v2_global_score": 2.336
  },
  {
    "id": "5ded8551ab4e9f3f",
    "source": "huggingface_blog",
    "source_weight": 1.1,
    "title": "IBM and UC Berkeley Diagnose Why Enterprise Agents Fail Using IT-Bench and MAST",
    "url": "https://huggingface.co/blog/ibm-research/itbenchandmast",
    "summary": "",
    "image_url": "",
    "published": "Wed, 18 Feb 2026 16:15:45 GMT",
    "collected_at": "2026-02-20T01:20:52.223186+00:00",
    "ingest_batch_id": "20260220-012052",
    "tier": "tier1",
    "type": "research",
    "source_reliability": 0.839,
    "freshness": 0.744,
    "tier1_quick_score": 2.571,
    "v2_slot": "research_watch",
    "v2_prefilter_score": 2.683,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "IBM and UC Berkeley Diagnose Why Enterprise Agents Fail Using IT-Bench and MAST",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.0,
    "v2_source_bias": 0.0,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.012,
    "summary_1line": "IBM and UC Berkeley introduce IT-Bench and MAST to diagnose enterprise agent failures, focusing on IT operations and enterprise task automation.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.317,
    "v2_global_score": 2.329
  },
  {
    "id": "b91259f7d1a90da4",
    "source": "anthropic_newsroom",
    "source_weight": 1.8,
    "title": "Anthropic Codepath Partnership",
    "url": "https://www.anthropic.com/news/anthropic-codepath-partnership",
    "summary": "",
    "image_url": "",
    "published": "2026-02-13T20:47:00+00:00",
    "collected_at": "2026-02-20T01:20:52.223186+00:00",
    "ingest_batch_id": "20260220-012052",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.839,
    "freshness": 0.156,
    "tier1_quick_score": 2.766,
    "v2_slot": "frontier_official",
    "v2_prefilter_score": 2.795,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "Anthropic Codepath Partnership",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.0,
    "v2_source_bias": 0.06,
    "v2_topical_bias": -0.2,
    "v2_final_score": 1.491,
    "summary_1line": "Anthropic partners with Codepath on education initiatives; no technical details on agentic coding or platform capabilities disclosed.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.659,
    "v2_global_score": 2.15
  }
]