[
  {
    "id": "80a9e576f04115fb",
    "source": "simon_willison",
    "source_weight": 1.25,
    "title": "SWE-bench February 2026 leaderboard update",
    "url": "https://simonwillison.net/2026/Feb/19/swe-bench/#atom-everything",
    "summary": "<p><strong><a href=\"https://www.swebench.com/\">SWE-bench February 2026 leaderboard update</a></strong></p>\nSWE-bench is one of the benchmarks that the labs love to list in their model releases. The official leaderboard is infrequently updated but they just did a full run of it against the current generation of models, which is notable because it's always good to see benchmark results like this that <em>weren't</em> self-reported by the labs.</p>\n<p>The fresh results are for their \"Bash Only\" benchmark, which runs their <a href=\"https://github.com/SWE-agent/mini-swe-agent\">mini-swe-bench</a> agent (~9,000 lines of Python, <a href=\"https://github.com/SWE-agent/mini-swe-agent/blob/v2.2.1/src/minisweagent/config/benchmarks/swebench.yaml\">here are the prompts</a> they use) against the <a href=\"https://huggingface.co/datasets/princeton-nlp/SWE-bench\">SWE-bench</a> dataset of coding problems - 2,294 real-world examples pulled from 12 open source repos: <a href=\"https://github.com/django/django\">django/django</a> (850), <a href=\"https://github.com/sympy/sympy\">sympy/sympy</a> (386), <a href=\"https://github.com/scikit-learn/scikit-learn\">scikit-learn/scikit-learn</a> (229), <a href=\"https://github.com/sphinx-doc/sphinx\">sphinx-doc/sphinx</a> (187), <a href=\"https://github.com/matplotlib/matplotlib\">matplotlib/matplotlib</a> (184), <a href=\"https://github.com/pytest-dev/pytest\">pytest-dev/pytest</a> (119), <a href=\"https://github.com/pydata/xarray\">pydata/xarray</a> (110), <a href=\"https://github.com/astropy/astropy\">astropy/astropy</a> (95), <a href=\"https://github.com/pylint-dev/pylint\">pylint-dev/pylint</a> (57), <a href=\"https://github.com/psf/requests\">psf/requests</a> (44), <a href=\"https://github.com/mwaskom/seaborn\">mwaskom/seaborn</a> (22), <a href=\"https://github.com/pallets/flask\">pallets/flask</a> (11).</p>\n<p>Here's how the top ten models performed:</p>\n<p><img alt=\"Bar chart showing &quot;% Resolved&quot; by &quot;Model&quot;. Bars in descending order: Claude 4.5 Opus (high reasoning) 76.8%, Gemini 3 Flash (high reasoning) 75.8%, MiniMax M2.5 (high reasoning) 75.8%, Claude Opus 4.6 75.6%, GLM-5 (high reasoning) 72.8%, GPT-5.2 (high reasoning) 72.8%, Claude 4.5 Sonnet (high reasoning) 72.8%, Kimi K2.5 (high reasoning) 71.4%, DeepSeek V3.2 (high reasoning) 70.8%, Claude 4.5 Haiku (high reasoning) 70.0%, and a partially visible final bar at 66.6%.\" src=\"https://static.simonwillison.net/static/2026/swbench-feb-2026.jpg\" /></p>\n<p>It's interesting to see Claude Opus 4.5 beat Opus 4.6, though only by about a percentage point. 4.5 Opus is top, then Gemini 3 Flash, then MiniMax M2.5 - a 229B model released <a href=\"https://www.minimax.io/news/minimax-m25\">last week</a> by Chinese lab MiniMax. GLM-5, Kimi K2.5 and DeepSeek V3.2 are three more Chinese models that make the top ten as well.</p>\n<p>OpenAI's GPT-5.2 is their highest performing model at position 6, but it's worth noting that their best coding model, GPT-5.3-Codex, is not represented - maybe because it's not yet available in the OpenAI API.</p>\n<p>This benchmark uses the same system prompt for every model, which is important for a fair comparison but does mean that the quality of the different harnesses or optimized prompts is not being measured here.</p>\n<p>The chart above is a screenshot from the SWE-bench website, but their charts don't include the actual percentage values visible on the bars. I successfully used Claude for Chrome to add these - <a href=\"https://claude.ai/share/81a0c519-c727-4caa-b0d4-0d866375d0da\">transcript here</a>. My prompt sequence included:</p>\n<blockquote>\n<p>Use claude in chrome to open https://www.swebench.com/</p>\n<p>Click on \"Compare results\" and then select \"Select top 10\"</p>\n<p>See those bar charts? I want them to display the percentage on each bar so I can take a better screenshot, modify the page like that</p>\n</blockquote>\n<p>I'm impressed at how well this worked - Claude injected custom JavaScript into the page to draw additional labels on top of the existing chart.</p>\n<p><img alt=\"Screenshot of a Claude AI conversation showing browser automation. A thinking step reads &quot;Pivoted strategy to avoid recursion issues with chart labeling &gt;&quot; followed by the message &quot;Good, the chart is back. Now let me carefully add the labels using an inline plugin on the chart instance to avoid the recursion issue.&quot; A collapsed &quot;Browser_evaluate&quot; section shows a browser_evaluate tool call with JavaScript code using Chart.js canvas context to draw percentage labels on bars: meta.data.forEach((bar, index) =&gt; { const value = dataset.data[index]; if (value !== undefined &amp;&amp; value !== null) { ctx.save(); ctx.textAlign = 'center'; ctx.textBaseline = 'bottom'; ctx.fillStyle = '#333'; ctx.font = 'bold 12px sans-serif'; ctx.fillText(value.toFixed(1) + '%', bar.x, bar.y - 5); A pending step reads &quot;Let me take a screenshot to see if it worked.&quot; followed by a completed &quot;Done&quot; step, and the message &quot;Let me take a screenshot to check the result.&quot;\" src=\"https://static.simonwillison.net/static/2026/claude-chrome-draw-on-chart.jpg\" />\n\n    <p><small></small>Via <a href=\"https://twitter.com/KLieret/status/2024176335782826336\">@KLieret</a></small></p>\n\n\n    <p>Tags: <a href=\"https://simonwillison.net/tags/benchmarks\">benchmarks</a>, <a href=\"https://simonwillison.net/tags/django\">django</a>, <a href=\"https://simonwillison.net/tags/ai\">ai</a>, <a href=\"https://simonwillison.net/tags/openai\">openai</a>, <a href=\"https://simonwillison.net/tags/generative-ai\">generative-ai</a>, <a href=\"https://simonwillison.net/tags/llms\">llms</a>, <a href=\"https://simonwillison.net/tags/anthropic\">anthropic</a>, <a href=\"https://simonwillison.net/tags/claude\">claude</a>, <a href=\"https://simonwillison.net/tags/coding-agents\">coding-agents</a>, <a href=\"https://simonwillison.net/tags/ai-in-china\">ai-in-china</a>, <a href=\"https://simonwillison.net/tags/minimax\">minimax</a></p>",
    "image_url": "https://static.simonwillison.net/static/2026/swbench-feb-2026.jpg",
    "published": "2026-02-19T04:48:47+00:00",
    "collected_at": "2026-02-19T11:03:15.968557+00:00",
    "ingest_batch_id": "20260219-110315",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.806,
    "freshness": 0.838,
    "tier1_quick_score": 2.917,
    "v2_slot": "practitioner_analysis",
    "v2_prefilter_score": 2.894,
    "llm_label_source": "llm",
    "llm_category": "research",
    "llm_summary_1line": "SWE-bench Feb 2026 leaderboard shows Claude 4.5 Opus leading at 76.8% on 2,294 real-world OSS tasks; independent third-party benchmark with reproducible harness and dataset.",
    "llm_why_1line": "Third-party benchmark data (not self-reported); concrete coding-agent eval; actionable baseline for SWE-agent harness tuning and model selection.",
    "v2_llm_score": 4.55,
    "v2_source_bias": 0.08,
    "v2_topical_bias": 0.0,
    "v2_final_score": 4.073,
    "summary_1line": "SWE-bench Feb 2026 leaderboard shows Claude 4.5 Opus at 76.8% on 2,294 real OSS tasks; independent benchmark run across current-gen models with transparent methodology.",
    "why_it_matters": "Third-party benchmark data (not self-reported); concrete coding-agent eval; actionable baseline for SWE-agent harness tuning and model selection.",
    "v2_slot_priority": 0.623,
    "v2_global_score": 4.696
  },
  {
    "id": "8af6289d4ecb1da2",
    "source": "simon_willison",
    "source_weight": 1.25,
    "title": "Introducing Claude Sonnet 4.6",
    "url": "https://simonwillison.net/2026/Feb/17/claude-sonnet-46/#atom-everything",
    "summary": "<p><strong><a href=\"https://www.anthropic.com/news/claude-sonnet-4-6\">Introducing Claude Sonnet 4.6</a></strong></p>\nSonnet 4.6 is out today, and Anthropic claim it offers similar performance to <a href=\"https://simonwillison.net/2025/Nov/24/claude-opus/\">November's Opus 4.5</a> while maintaining the Sonnet pricing of $3/million input and $15/million output tokens (the Opus models are $5/$25). Here's <a href=\"https://www-cdn.anthropic.com/78073f739564e986ff3e28522761a7a0b4484f84.pdf\">the system card PDF</a>.</p>\n<p>Sonnet 4.6 has a \"reliable knowledge cutoff\" of August 2025, compared to Opus 4.6's May 2025 and Haiku 4.5's February 2025. Both Opus and Sonnet default to 200,000 max input tokens but can stretch to 1 million in beta and at a higher cost.</p>\n<p>I just released <a href=\"https://github.com/simonw/llm-anthropic/releases/tag/0.24\">llm-anthropic 0.24</a> with support for both Sonnet 4.6 and Opus 4.6. Claude Code <a href=\"https://github.com/simonw/llm-anthropic/pull/65\">did most of the work</a> - the new models had a fiddly amount of extra details around adaptive thinking and no longer supporting prefixes, as described <a href=\"https://platform.claude.com/docs/en/about-claude/models/migration-guide\">in Anthropic's migration guide</a>.</p>\n<p>Here's <a href=\"https://gist.github.com/simonw/b185576a95e9321b441f0a4dfc0e297c\">what I got</a> from:</p>\n<pre><code>uvx --with llm-anthropic llm 'Generate an SVG of a pelican riding a bicycle' -m claude-sonnet-4.6\n</code></pre>\n<p><img alt=\"The pelican has a jaunty top hat with a red band. There is a string between the upper and lower beaks for some reason. The bicycle frame is warped in the wrong way.\" src=\"https://static.simonwillison.net/static/2026/pelican-sonnet-4.6.png\" /></p>\n<p>The SVG comments include:</p>\n<pre><code>&lt;!-- Hat (fun accessory) --&gt;\n</code></pre>\n<p>I tried a second time and also got a top hat. Sonnet 4.6 apparently loves top hats!</p>\n<p>For comparison, here's the pelican Opus 4.5 drew me <a href=\"https://simonwillison.net/atom/everything/(https:/simonwillison.net/2025/Nov/24/claude-opus/)\">in November</a>:</p>\n<p><img alt=\"The pelican is cute and looks pretty good. The bicycle is not great - the frame is wrong and the pelican is facing backwards when the handlebars appear to be forwards.There is also something that looks a bit like an egg on the handlebars.\" src=\"https://static.simonwillison.net/static/2025/claude-opus-4.5-pelican.jpg\" /></p>\n<p>And here's Anthropic's current best pelican, drawn by Opus 4.6 <a href=\"https://simonwillison.net/2026/Feb/5/two-new-models/\">on February 5th</a>:</p>\n<p><img alt=\"Slightly wonky bicycle frame but an excellent pelican, very clear beak and pouch, nice feathers.\" src=\"https://static.simonwillison.net/static/2026/opus-4.6-pelican.png\" /></p>\n<p>Opus 4.6 produces the best pelican beak/pouch. I do think the top hat from Sonnet 4.6 is a nice touch though.\n\n    <p><small></small>Via <a href=\"https://news.ycombinator.com/item?id=47050488\">Hacker News</a></small></p>\n\n\n    <p>Tags: <a href=\"https://simonwillison.net/tags/ai\">ai</a>, <a href=\"https://simonwillison.net/tags/generative-ai\">generative-ai</a>, <a href=\"https://simonwillison.net/tags/llms\">llms</a>, <a href=\"https://simonwillison.net/tags/llm\">llm</a>, <a href=\"https://simonwillison.net/tags/anthropic\">anthropic</a>, <a href=\"https://simonwillison.net/tags/claude\">claude</a>, <a href=\"https://simonwillison.net/tags/llm-pricing\">llm-pricing</a>, <a href=\"https://simonwillison.net/tags/pelican-riding-a-bicycle\">pelican-riding-a-bicycle</a>, <a href=\"https://simonwillison.net/tags/llm-release\">llm-release</a>, <a href=\"https://simonwillison.net/tags/claude-code\">claude-code</a></p>",
    "image_url": "https://static.simonwillison.net/static/2026/pelican-sonnet-4.6.png",
    "published": "2026-02-17T23:58:58+00:00",
    "collected_at": "2026-02-19T11:03:15.968557+00:00",
    "ingest_batch_id": "20260219-110315",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.806,
    "freshness": 0.408,
    "tier1_quick_score": 2.617,
    "v2_slot": "practitioner_analysis",
    "v2_prefilter_score": 2.464,
    "llm_label_source": "llm",
    "llm_category": "release",
    "llm_summary_1line": "Claude Sonnet 4.6 matches Opus 4.5 performance at Sonnet pricing ($3/$15M tokens); 200K context default, 1M beta, August 2025 knowledge cutoff.",
    "llm_why_1line": "Pricing parity with stronger model is actionable for cost optimization, but limited agentic-specific improvements documented; primarily an economics play.",
    "v2_llm_score": 3.05,
    "v2_source_bias": 0.08,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.934,
    "summary_1line": "Claude Sonnet 4.6 matches Opus 4.5 performance at half the cost ($3/$15 vs $5/$25 per million tokens) with August 2025 knowledge cutoff.",
    "why_it_matters": "Pricing parity with stronger model is actionable for cost optimization, but limited agentic-specific improvements documented; primarily an economics play.",
    "v2_slot_priority": 0.623,
    "v2_global_score": 3.557
  },
  {
    "id": "c991b4745e961b3e",
    "source": "latent_space",
    "source_weight": 1.2,
    "title": "[AINews] Anthropic's Agent Autonomy study",
    "url": "https://www.latent.space/p/ainews-anthropics-agent-autonomy",
    "summary": "a quiet day lets us dive deep into Anthropic's own version of the METR data",
    "image_url": "https://substackcdn.com/image/fetch/$s_!c74W!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18a91dee-c7fa-409d-9541-b34e24bba31c_1938x1236.png",
    "published": "Thu, 19 Feb 2026 07:55:36 GMT",
    "collected_at": "2026-02-19T11:03:15.968557+00:00",
    "ingest_batch_id": "20260219-110315",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.806,
    "freshness": 0.906,
    "tier1_quick_score": 2.908,
    "v2_slot": "practitioner_analysis",
    "v2_prefilter_score": 2.912,
    "llm_label_source": "llm",
    "llm_category": "research",
    "llm_summary_1line": "Anthropic publishes agent autonomy research mirroring METR's methodology; early signal on agentic capability benchmarking.",
    "llm_why_1line": "Relevant framing but vague excerpt; needs concrete evals, metrics, and reproducible harness details for platform engineers.",
    "v2_llm_score": 3.0,
    "v2_source_bias": 0.0,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.886,
    "summary_1line": "Anthropic releases agent autonomy benchmarking study mirroring METR's approach to evaluate agentic capability and safety boundaries.",
    "why_it_matters": "Relevant framing but vague excerpt; needs concrete evals, metrics, and reproducible harness details for platform engineers.",
    "v2_slot_priority": 0.623,
    "v2_global_score": 3.509
  },
  {
    "id": "bf60b833f693787c",
    "source": "infoq_ai_ml",
    "source_weight": 1.15,
    "title": "GitHub Agentic Workflows Unleash AI-Driven Repository Automation",
    "url": "https://www.infoq.com/news/2026/02/github-agentic-workflows/?utm_campaign=infoq_content&utm_source=infoq&utm_medium=feed&utm_term=AI%2C+ML+%26+Data+Engineering",
    "summary": "<img src=\"https://res.infoq.com/news/2026/02/github-agentic-workflows/en/headerimage/github-agentic-workflows-1771415135302.jpeg\" /><p>Recently launched in technical preview, GitHub Agentic Workflows introduce a way to automate complex, repetitive repository tasks using coding agents that understand context and intent, GitHub says. This enables workflows such as automatic issue triage and labeling, documentation updates, CI troubleshooting, test improvements, and reporting.</p> <i>By Sergio De Simone</i>",
    "image_url": "https://res.infoq.com/news/2026/02/github-agentic-workflows/en/headerimage/github-agentic-workflows-1771415135302.jpeg",
    "published": "Wed, 18 Feb 2026 12:00:00 GMT",
    "collected_at": "2026-02-19T11:03:15.968557+00:00",
    "ingest_batch_id": "20260219-110315",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.806,
    "freshness": 0.551,
    "tier1_quick_score": 2.628,
    "v2_slot": "practitioner_analysis",
    "v2_prefilter_score": 2.507,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "Recently launched in technical preview, GitHub Agentic Workflows introduce a way to automate complex, repetitive repository tasks using coding agents that understand context and intent, GitHub says. This enables workf...",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.6,
    "v2_source_bias": 0.08,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.573,
    "summary_1line": "Recently launched in technical preview, GitHub Agentic Workflows introduce a way to automate complex, repetitive repository tasks using coding agents that understand context and intent, GitHub says. This enables workf...",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.623,
    "v2_global_score": 3.196
  },
  {
    "id": "8de56f934385a8fc",
    "source": "infoq_ai_ml",
    "source_weight": 1.15,
    "title": "Hugging Face Introduces Community Evals for Transparent Model Benchmarking",
    "url": "https://www.infoq.com/news/2026/02/hugging-face-evals/?utm_campaign=infoq_content&utm_source=infoq&utm_medium=feed&utm_term=AI%2C+ML+%26+Data+Engineering",
    "summary": "<img src=\"https://res.infoq.com/news/2026/02/hugging-face-evals/en/headerimage/generatedHeaderImage-1771448477065.jpg\" /><p>Hugging Face has launched Community Evals, a feature that enables benchmark datasets on the Hub to host their own leaderboards and automatically collect evaluation results from model repositories.</p> <i>By Daniel Dominguez</i>",
    "image_url": "https://res.infoq.com/news/2026/02/hugging-face-evals/en/headerimage/generatedHeaderImage-1771448477065.jpg",
    "published": "Thu, 19 Feb 2026 10:55:00 GMT",
    "collected_at": "2026-02-19T11:03:15.968557+00:00",
    "ingest_batch_id": "20260219-110315",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.806,
    "freshness": 0.976,
    "tier1_quick_score": 2.898,
    "v2_slot": "practitioner_analysis",
    "v2_prefilter_score": 2.932,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "Hugging Face has launched Community Evals, a feature that enables benchmark datasets on the Hub to host their own leaderboards and automatically collect evaluation results from model repositories. By Daniel Dominguez",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.75,
    "v2_source_bias": 0.08,
    "v2_topical_bias": 0.0,
    "v2_final_score": 2.564,
    "summary_1line": "Hugging Face has launched Community Evals, a feature that enables benchmark datasets on the Hub to host their own leaderboards and automatically collect evaluation results from model repositories. By Daniel Dominguez",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.623,
    "v2_global_score": 3.187
  },
  {
    "id": "86624d7aa186ea4d",
    "source": "llamaindex_releases",
    "source_weight": 0.95,
    "title": "v0.14.15",
    "url": "https://github.com/run-llama/llama_index/releases/tag/v0.14.15",
    "summary": "<h1>Release Notes</h1>\n<h2>[2026-02-18]</h2>\n<h3>llama-index-agent-agentmesh [0.1.0]</h3>\n<ul>\n<li>[Integration] AgentMesh: Trust Layer for LlamaIndex Agents (<a href=\"https://github.com/run-llama/llama_index/pull/20644\">#20644</a>)</li>\n</ul>\n<h3>llama-index-core [0.14.15]</h3>\n<ul>\n<li>Support basic operations for multimodal types (<a href=\"https://github.com/run-llama/llama_index/pull/20640\">#20640</a>)</li>\n<li>Feat recursive llm type support (<a href=\"https://github.com/run-llama/llama_index/pull/20642\">#20642</a>)</li>\n<li>fix: remove redundant metadata_seperator field from TextNode (<a href=\"https://github.com/run-llama/llama_index/pull/20649\">#20649</a>)</li>\n<li>fix(tests): update mock prompt type in mock_prompts.py (<a href=\"https://github.com/run-llama/llama_index/pull/20661\">#20661</a>)</li>\n<li>Feat multimodal template var formatting (<a href=\"https://github.com/run-llama/llama_index/pull/20682\">#20682</a>)</li>\n<li>Feat multimodal prompt templates (<a href=\"https://github.com/run-llama/llama_index/pull/20683\">#20683</a>)</li>\n<li>Feat multimodal chat prompt helper (<a href=\"https://github.com/run-llama/llama_index/pull/20684\">#20684</a>)</li>\n<li>Add retry and error handling to BaseExtractor (<a href=\"https://github.com/run-llama/llama_index/pull/20693\">#20693</a>)</li>\n<li>ensure at least one message/content block is returned by the old memory (<a href=\"https://github.com/run-llama/llama_index/pull/20729\">#20729</a>)</li>\n</ul>\n<h3>llama-index-embeddings-ibm [0.6.0.post1]</h3>\n<ul>\n<li>chore: Remove persistent_connection parameter support, update (<a href=\"https://github.com/run-llama/llama_index/pull/20714\">#20714</a>)</li>\n<li>docs: Update IBM docs (<a href=\"https://github.com/run-llama/llama_index/pull/20718\">#20718</a>)</li>\n</ul>\n<h3>llama-index-llms-anthropic [0.10.9]</h3>\n<ul>\n<li>Sonnet 4-6 addition (<a href=\"https://github.com/run-llama/llama_index/pull/20723\">#20723</a>)</li>\n</ul>\n<h3>llama-index-llms-bedrock-converse [0.12.10]</h3>\n<ul>\n<li>fix(bedrock-converse): ensure thinking_delta is populated in all chat modes (<a href=\"https://github.com/run-llama/llama_index/pull/20664\">#20664</a>)</li>\n<li>feat(bedrock-converse): Add support for Claude Sonnet 4.6 (<a href=\"https://github.com/run-llama/llama_index/pull/20726\">#20726</a>)</li>\n</ul>\n<h3>llama-index-llms-ibm [0.7.0.post1]</h3>\n<ul>\n<li>chore: Remove persistent_connection parameter support, update (<a href=\"https://github.com/run-llama/llama_index/pull/20714\">#20714</a>)</li>\n<li>docs: Update IBM docs (<a href=\"https://github.com/run-llama/llama_index/pull/20718\">#20718</a>)</li>\n</ul>\n<h3>llama-index-llms-mistralai [0.10.0]</h3>\n<ul>\n<li>Rrubini/mistral azure sdk (<a href=\"https://github.com/run-llama/llama_index/pull/20668\">#20668</a>)</li>\n</ul>\n<h3>llama-index-llms-oci-data-science [1.0.0]</h3>\n<ul>\n<li>Add support for new OCI DataScience endpoint /predictWithStream for streaming use case (<a href=\"https://github.com/run-llama/llama_index/pull/20545\">#20545</a>)</li>\n</ul>\n<h3>llama-index-observability-otel [0.3.0]</h3>\n<ul>\n<li>improve otel data serialization by flattening dicts (<a href=\"https://github.com/run-llama/llama_index/pull/20719\">#20719</a>)</li>\n<li>feat: support custom span processor; refactor: use llama-index-instrumentation instead of llama-index-core (<a href=\"https://github.com/run-llama/llama_index/pull/20732\">#20732</a>)</li>\n</ul>\n<h3>llama-index-program-evaporate [0.5.2]</h3>\n<ul>\n<li>Sandbox LLM-generated code execution in EvaporateExtractor (<a href=\"https://github.com/run-llama/llama_index/pull/20676\">#20676</a>)</li>\n</ul>\n<h3>llama-index-readers-bitbucket [0.4.2]</h3>\n<ul>\n<li>fix: replace mutable default argument in load_all_file_paths (<a href=\"https://github.com/run-llama/llama_index/pull/20698\">#20698</a>)</li>\n</ul>\n<h3>llama-index-readers-github [0.10.0]</h3>\n<ul>\n<li>feat: Enhance GitHubRepoReader with selective file fetching and deduplication (Issue <a class=\"issue-link js-issue-link\" href=\"https://github.com/run-llama/llama_index/issues/20471\">#20471</a>) (<a href=\"https://github.com/run-llama/llama_index/pull/20550\">#20550</a>)</li>\n</ul>\n<h3>llama-index-readers-layoutir [0.1.1]</h3>\n<ul>\n<li>feat: Add LayoutIR reader integration (<a href=\"https://github.com/run-llama/llama_index/pull/20708\">#20708</a>)</li>\n<li>fix(layoutir): hotfix for output_dir crash and Block extraction (<a class=\"issue-link js-issue-link\" href=\"https://github.com/run-llama/llama_index/pull/20708\">#20708</a> follow-up) (<a href=\"https://github.com/run-llama/llama_index/pull/20715\">#20715</a>)</li>\n<li>fix(layoutir): restrict requires-python to &gt;=3.12 to match layoutir dependency (<a href=\"https://github.com/run-llama/llama_index/pull/20733\">#20733</a>)</li>\n</ul>\n<h3>llama-index-readers-microsoft-sharepoint [0.8.0]</h3>\n<ul>\n<li>Add pagination support for Microsoft Graph API calls in SharePoint reader (<a href=\"https://github.com/run-llama/llama_index/pull/20704\">#20704</a>)</li>\n</ul>\n<h3>llama-index-readers-whatsapp [0.4.2]</h3>\n<ul>\n<li>fix: Update WhatsAppChatLoader to retrieve DataFrame in pandas format (<a href=\"https://github.com/run-llama/llama_index/pull/20722\">#20722</a>)</li>\n</ul>\n<h3>llama-index-tools-mcp [0.4.7]</h3>\n<ul>\n<li>feat: propagate partial_params to get_tools_from_mcp utils (<a href=\"https://github.com/run-llama/llama_index/pull/20669\">#20669</a>)</li>\n</ul>\n<h3>llama-index-vector-stores-faiss [0.5.3]</h3>\n<ul>\n<li>Replace eval() with json.loads in FaissMapVectorStore persistence (<a href=\"https://github.com/run-llama/llama_index/pull/20675\">#20675</a>)</li>\n</ul>\n<h3>llama-index-vector-stores-milvus [1.0.0]</h3>\n<ul>\n<li>Fix: remove ORM Collection mix-usage with MilvusClient in Milvus vector store (<a href=\"https://github.com/run-llama/llama_index/pull/20687\">#20687</a>)</li>\n</ul>",
    "image_url": "",
    "published": "2026-02-18T19:06:42Z",
    "collected_at": "2026-02-19T11:03:15.968557+00:00",
    "ingest_batch_id": "20260219-110315",
    "tier": "tier1",
    "type": "release",
    "source_reliability": 0.806,
    "freshness": 0.741,
    "tier1_quick_score": 2.502,
    "v2_slot": "agent_tooling_releases",
    "v2_prefilter_score": 2.497,
    "llm_label_source": "heuristic",
    "llm_category": "release",
    "llm_summary_1line": "Release Notes [2026-02-18] llama-index-agent-agentmesh [0.1.0] [Integration] AgentMesh: Trust Layer for LlamaIndex Agents ( #20644 ) llama-index-core [0.14.15] Support basic operations for multimodal types ( #20640 )...",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 3.0,
    "v2_source_bias": 0.05,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.572,
    "summary_1line": "Release Notes [2026-02-18] llama-index-agent-agentmesh [0.1.0] [Integration] AgentMesh: Trust Layer for LlamaIndex Agents ( #20644 ) llama-index-core [0.14.15] Support basic operations for multimodal types ( #20640 )...",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.492,
    "v2_global_score": 3.064
  },
  {
    "id": "264752c3b997bcbb",
    "source": "arxiv_cs_cl",
    "source_weight": 0.8,
    "title": "TabAgent: A Framework for Replacing Agentic Generative Components with Tabular-Textual Classifiers",
    "url": "http://arxiv.org/abs/2602.16429v1",
    "summary": "Agentic systems, AI architectures that autonomously execute multi-step workflows to achieve complex goals, are often built using repeated large language model (LLM) calls for closed-set decision tasks such as routing, shortlisting, gating, and verification. While convenient, this design makes deployments slow and expensive due to cumulative latency and token usage. We propose TabAgent, a framework for replacing generative decision components in closed-set selection tasks with a compact textual-tabular classifier trained on execution traces. TabAgent (i) extracts structured schema, state, and dependency features from trajectories (TabSchema), (ii) augments coverage with schema-aligned synthetic supervision (TabSynth), and (iii) scores candidates with a lightweight classifier (TabHead). On the long-horizon AppWorld benchmark, TabAgent maintains task-level success while eliminating shortlist-time LLM calls, reducing latency by approximately 95% and inference cost by 85-91%. Beyond tool shortlisting, TabAgent generalizes to other agentic decision heads, establishing a paradigm for learned discriminative replacements of generative bottlenecks in production agent architectures.",
    "image_url": "",
    "published": "2026-02-18T13:01:17Z",
    "collected_at": "2026-02-19T11:03:15.968557+00:00",
    "ingest_batch_id": "20260219-110315",
    "tier": "tier1",
    "type": "paper",
    "source_reliability": 0.806,
    "freshness": 0.815,
    "tier1_quick_score": 2.288,
    "v2_slot": "research_watch",
    "v2_prefilter_score": 2.421,
    "llm_label_source": "heuristic",
    "llm_category": "research",
    "llm_summary_1line": "Agentic systems, AI architectures that autonomously execute multi-step workflows to achieve complex goals, are often built using repeated large language model (LLM) calls for closed-set decision tasks such as routing,...",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 3.05,
    "v2_source_bias": -0.3,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.615,
    "summary_1line": "Agentic systems, AI architectures that autonomously execute multi-step workflows to achieve complex goals, are often built using repeated large language model (LLM) calls for closed-set decision tasks such as routing,...",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.345,
    "v2_global_score": 2.96
  },
  {
    "id": "e090493a0ff267ce",
    "source": "openai_blog",
    "source_weight": 2.0,
    "title": "Introducing GPT-5.3-Codex-Spark",
    "url": "https://openai.com/index/introducing-gpt-5-3-codex-spark",
    "summary": "Introducing GPT-5.3-Codex-Spark—our first real-time coding model. 15x faster generation, 128k context, now in research preview for ChatGPT Pro users.",
    "image_url": "",
    "published": "Thu, 12 Feb 2026 10:00:00 GMT",
    "collected_at": "2026-02-19T11:03:15.968557+00:00",
    "ingest_batch_id": "20260219-110315",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.806,
    "freshness": 0.12,
    "tier1_quick_score": 2.851,
    "v2_slot": "frontier_official",
    "v2_prefilter_score": 2.926,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "Introducing GPT-5.3-Codex-Spark—our first real-time coding model. 15x faster generation, 128k context, now in research preview for ChatGPT Pro users.",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.2,
    "v2_source_bias": 0.1,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.084,
    "summary_1line": "Introducing GPT-5.3-Codex-Spark—our first real-time coding model. 15x faster generation, 128k context, now in research preview for ChatGPT Pro users.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.684,
    "v2_global_score": 2.768
  },
  {
    "id": "9d95a891a81b27c3",
    "source": "openai_blog",
    "source_weight": 2.0,
    "title": "Beyond rate limits: scaling access to Codex and Sora",
    "url": "https://openai.com/index/beyond-rate-limits",
    "summary": "How OpenAI built a real-time access system combining rate limits, usage tracking, and credits to power continuous access to Sora and Codex.",
    "image_url": "",
    "published": "Fri, 13 Feb 2026 09:00:00 GMT",
    "collected_at": "2026-02-19T11:03:15.968557+00:00",
    "ingest_batch_id": "20260219-110315",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.806,
    "freshness": 0.159,
    "tier1_quick_score": 2.887,
    "v2_slot": "frontier_official",
    "v2_prefilter_score": 2.965,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "How OpenAI built a real-time access system combining rate limits, usage tracking, and credits to power continuous access to Sora and Codex.",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.0,
    "v2_source_bias": 0.1,
    "v2_topical_bias": 0.2,
    "v2_final_score": 1.932,
    "summary_1line": "How OpenAI built a real-time access system combining rate limits, usage tracking, and credits to power continuous access to Sora and Codex.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.684,
    "v2_global_score": 2.616
  },
  {
    "id": "42710d92908034f2",
    "source": "anthropic_newsroom",
    "source_weight": 1.8,
    "title": "Claude Opus 4 6",
    "url": "https://www.anthropic.com/news/claude-opus-4-6",
    "summary": "",
    "image_url": "",
    "published": "2026-02-17T17:46:31.000Z",
    "collected_at": "2026-02-19T11:03:15.968557+00:00",
    "ingest_batch_id": "20260219-110315",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.806,
    "freshness": 0.591,
    "tier1_quick_score": 3.116,
    "v2_slot": "frontier_official",
    "v2_prefilter_score": 3.197,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "Claude Opus 4 6",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.0,
    "v2_source_bias": 0.06,
    "v2_topical_bias": 0.0,
    "v2_final_score": 1.778,
    "summary_1line": "Claude Opus 4 6",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.684,
    "v2_global_score": 2.462
  },
  {
    "id": "4b8cd476c6cfcd11",
    "source": "hackernews_ai",
    "source_weight": 1.1,
    "title": "Evaluating AI agents: Real-world lessons from building agentic systems at Amazon",
    "url": "https://aws.amazon.com/blogs/machine-learning/evaluating-ai-agents-real-world-lessons-from-building-agentic-systems-at-amazon/",
    "summary": "<p>Article URL: <a href=\"https://aws.amazon.com/blogs/machine-learning/evaluating-ai-agents-real-world-lessons-from-building-agentic-systems-at-amazon/\">https://aws.amazon.com/blogs/machine-learning/evaluating-ai-agents-real-world-lessons-from-building-agentic-systems-at-amazon/</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47071653\">https://news.ycombinator.com/item?id=47071653</a></p>\n<p>Points: 2</p>\n<p># Comments: 1</p>",
    "image_url": "",
    "published": "Thu, 19 Feb 2026 09:08:43 +0000",
    "collected_at": "2026-02-19T11:03:15.968557+00:00",
    "ingest_batch_id": "20260219-110315",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.806,
    "freshness": 0.843,
    "tier1_quick_score": 2.824,
    "v2_slot": "community_signal",
    "v2_prefilter_score": 2.749,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "Article URL: https://aws.amazon.com/blogs/machine-learning/evaluating-ai-agents-real-world-lessons-from-building-agentic-systems-at-amazon/ Comments URL: https://news.ycombinator.com/item?id=47071653 Points: 2 # Comme...",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.6,
    "v2_source_bias": 0.0,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.361,
    "summary_1line": "Amazon shares real-world lessons on evaluating AI agents, covering evaluation frameworks and production deployment patterns from their agentic systems work.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.471,
    "v2_global_score": 2.832
  },
  {
    "id": "0f43cce4717b58ca",
    "source": "anthropic_research",
    "source_weight": 1.4,
    "title": "Measuring Agent Autonomy",
    "url": "https://www.anthropic.com/research/measuring-agent-autonomy",
    "summary": "",
    "image_url": "",
    "published": "2026-02-18T20:26:31.000Z",
    "collected_at": "2026-02-19T11:03:15.968557+00:00",
    "ingest_batch_id": "20260219-110315",
    "tier": "tier1",
    "type": "research",
    "source_reliability": 0.806,
    "freshness": 0.871,
    "tier1_quick_score": 2.967,
    "v2_slot": "research_watch",
    "v2_prefilter_score": 3.077,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "Measuring Agent Autonomy",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.0,
    "v2_source_bias": 0.4,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.431,
    "summary_1line": "Measuring Agent Autonomy",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.345,
    "v2_global_score": 2.776
  },
  {
    "id": "5713ae1ccd7185d1",
    "source": "claude_code_releases",
    "source_weight": 2.2,
    "title": "v2.1.47",
    "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.47",
    "summary": "<h2>What's changed</h2>\n<ul>\n<li>Fixed FileWriteTool line counting to preserve intentional trailing blank lines instead of stripping them with <code>trimEnd()</code>.</li>\n<li>Fixed Windows terminal rendering bugs caused by <code>os.EOL</code> (<code>\\r\\n</code>) in display code — line counts now show correct values instead of always showing 1 on Windows.</li>\n<li>Improved VS Code plan preview: auto-updates as Claude iterates, enables commenting only when the plan is ready for review, and keeps the preview open when rejecting so Claude can revise.</li>\n<li>Fixed a bug where bold and colored text in markdown output could shift to the wrong characters on Windows due to <code>\\r\\n</code> line endings.</li>\n<li>Fixed compaction failing when conversation contains many PDF documents by stripping document blocks alongside images before sending to the compaction API (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26188\">#26188</a>)</li>\n<li>Improved memory usage in long-running sessions by releasing API stream buffers, agent context, and skill state after use</li>\n<li>Improved startup performance by deferring SessionStart hook execution, reducing time-to-interactive by ~500ms.</li>\n<li>Fixed an issue where bash tool output was silently discarded on Windows when using MSYS2 or Cygwin shells.</li>\n<li>Improved performance of <code>@</code> file mentions - file suggestions now appear faster by pre-warming the index on startup and using session-based caching with background refresh.</li>\n<li>Improved memory usage by trimming agent task message history after tasks complete</li>\n<li>Improved memory usage during long agent sessions by eliminating O(n²) message accumulation in progress updates</li>\n<li>Fixed the bash permission classifier to validate that returned match descriptions correspond to actual input rules, preventing hallucinated descriptions from incorrectly granting permissions</li>\n<li>Fixed user-defined agents only loading one file on NFS/FUSE filesystems that report zero inodes (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26044\">#26044</a>)</li>\n<li>Fixed plugin agent skills silently failing to load when referenced by bare name instead of fully-qualified plugin name (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25834\">#25834</a>)</li>\n<li>Search patterns in collapsed tool results are now displayed in quotes for clarity</li>\n<li>Windows: Fixed CWD tracking temp files never being cleaned up, causing them to accumulate indefinitely (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/17600\">#17600</a>)</li>\n<li>Use <code>ctrl+f</code> to kill all background agents instead of double-pressing ESC. Background agents now continue running when you press ESC to cancel the main thread, giving you more control over agent lifecycle.</li>\n<li>Fixed API 400 errors (\"thinking blocks cannot be modified\") that occurred in sessions with concurrent agents, caused by interleaved streaming content blocks preventing proper message merging.</li>\n<li>Simplified teammate navigation to use only Shift+Down (with wrapping) instead of both Shift+Up and Shift+Down.</li>\n<li>Fixed an issue where a single file write/edit error would abort all other parallel file write/edit operations. Independent file mutations now complete even when a sibling fails.</li>\n<li>Added <code>last_assistant_message</code> field to Stop and SubagentStop hook inputs, providing the final assistant response text so hooks can access it without parsing transcript files.</li>\n<li>Fixed custom session titles set via <code>/rename</code> being lost after resuming a conversation (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/23610\">#23610</a>)</li>\n<li>Fixed collapsed read/search hint text overflowing on narrow terminals by truncating from the start.</li>\n<li>Fixed an issue where bash commands with backslash-newline continuation lines (e.g., long commands split across multiple lines with <code>\\</code>) would produce spurious empty arguments, potentially breaking command execution.</li>\n<li>Fixed built-in slash commands (<code>/help</code>, <code>/model</code>, <code>/compact</code>, etc.) being hidden from the autocomplete dropdown when many user skills are installed (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/22020\">#22020</a>)</li>\n<li>Fixed MCP servers not appearing in the MCP Management Dialog after deferred loading</li>\n<li>Fixed session name persisting in status bar after <code>/clear</code> command (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26082\">#26082</a>)</li>\n<li>Fixed crash when a skill's <code>name</code> or <code>description</code> in SKILL.md frontmatter is a bare number (e.g., <code>name: 3000</code>) — the value is now properly coerced to a string (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25837\">#25837</a>)</li>\n<li>Fixed /resume silently dropping sessions when the first message exceeds 16KB or uses array-format content (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25721\">#25721</a>)</li>\n<li>Added <code>chat:newline</code> keybinding action for configurable multi-line input (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26075\">#26075</a>)</li>\n<li>Added <code>added_dirs</code> to the statusline JSON <code>workspace</code> section, exposing directories added via <code>/add-dir</code> to external scripts (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26096\">#26096</a>)</li>\n<li>Fixed <code>claude doctor</code> misclassifying mise and asdf-managed installations as native installs (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26033\">#26033</a>)</li>\n<li>Fixed zsh heredoc failing with \"read-only file system\" error in sandboxed commands (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25990\">#25990</a>)</li>\n<li>Fixed agent progress indicator showing inflated tool use count (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26023\">#26023</a>)</li>\n<li>Fixed image pasting not working on WSL2 systems where Windows copies images as BMP format (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25935\">#25935</a>)</li>\n<li>Fixed background agent results returning raw transcript data instead of the agent's final answer (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26012\">#26012</a>)</li>\n<li>Fixed Warp terminal incorrectly prompting for Shift+Enter setup when it supports it natively (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25957\">#25957</a>)</li>\n<li>Fixed CJK wide characters causing misaligned timestamps and layout elements in the TUI (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26084\">#26084</a>)</li>\n<li>Fixed custom agent <code>model</code> field in <code>.claude/agents/*.md</code> being ignored when spawning team teammates (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26064\">#26064</a>)</li>\n<li>Fixed plan mode being lost after context compaction, causing the model to switch from planning to implementation mode (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26061\">#26061</a>)</li>\n<li>Fixed <code>alwaysThinkingEnabled: true</code> in settings.json not enabling thinking mode on Bedrock and Vertex providers (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26074\">#26074</a>)</li>\n<li>Fixed <code>tool_decision</code> OTel telemetry event not being emitted in headless/SDK mode (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26059\">#26059</a>)</li>\n<li>Fixed session name being lost after context compaction — renamed sessions now preserve their custom title through compaction (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26121\">#26121</a>)</li>\n<li>Increased initial session count in resume picker from 10 to 50 for faster session discovery (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26123\">#26123</a>)</li>\n<li>Windows: fixed worktree session matching when drive letter casing differs (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26123\">#26123</a>)</li>\n<li>Fixed <code>/resume &lt;session-id&gt;</code> failing to find sessions whose first message exceeds 16KB (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25920\">#25920</a>)</li>\n<li>Fixed \"Always allow\" on multiline bash commands creating invalid permission patterns that corrupt settings (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25909\">#25909</a>)</li>\n<li>Fixed React crash (error <a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/31\">#31</a>) when a skill's <code>argument-hint</code> in SKILL.md frontmatter uses YAML sequence syntax (e.g., <code>[topic: foo | bar]</code>) — the value is now properly coerced to a string (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25826\">#25826</a>)</li>\n<li>Fixed crash when using <code>/fork</code> on sessions that used web search — null entries in search results from transcript deserialization are now handled gracefully (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25811\">#25811</a>)</li>\n<li>Fixed read-only git commands triggering FSEvents file watcher loops on macOS by adding --no-optional-locks flag (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25750\">#25750</a>)</li>\n<li>Fixed custom agents and skills not being discovered when running from a git worktree — project-level <code>.claude/agents/</code> and <code>.claude/skills/</code> from the main repository are now included (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25816\">#25816</a>)</li>\n<li>Fixed non-interactive subcommands like <code>claude doctor</code> and <code>claude plugin validate</code> being blocked inside nested Claude sessions (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25803\">#25803</a>)</li>\n<li>Windows: Fixed the same CLAUDE.md file being loaded twice when drive letter casing differs between paths (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25756\">#25756</a>)</li>\n<li>Fixed inline code spans in markdown being incorrectly parsed as bash commands (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25792\">#25792</a>)</li>\n<li>Fixed teammate spinners not respecting custom spinnerVerbs from settings (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25748\">#25748</a>)</li>\n<li>Fixed shell commands permanently failing after a command deletes its own working directory (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26136\">#26136</a>)</li>\n<li>Fixed hooks (PreToolUse, PostToolUse) silently failing to execute on Windows by using Git Bash instead of cmd.exe (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25981\">#25981</a>)</li>\n<li>Fixed LSP <code>findReferences</code> and other location-based operations returning results from gitignored files (e.g., <code>node_modules/</code>, <code>venv/</code>) (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26051\">#26051</a>)</li>\n<li>Moved config backup files from home directory root to <code>~/.claude/backups/</code> to reduce home directory clutter (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26130\">#26130</a>)</li>\n<li>Fixed sessions with large first prompts (&gt;16KB) disappearing from the /resume list (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26140\">#26140</a>)</li>\n<li>Fixed shell functions with double-underscore prefixes (e.g., <code>__git_ps1</code>) not being preserved across shell sessions (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25824\">#25824</a>)</li>\n<li>Fixed spinner showing \"0 tokens\" counter before any tokens have been received (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26105\">#26105</a>)</li>\n<li>VSCode: Fixed conversation messages appearing dimmed while the AskUserQuestion dialog is open (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26078\">#26078</a>)</li>\n<li>Fixed background tasks failing in git worktrees due to remote URL resolution reading from worktree-specific gitdir instead of the main repository config (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26065\">#26065</a>)</li>\n<li>Fixed Right Alt key leaving visible <code>[25~</code> escape sequence residue in the input field on Windows/Git Bash terminals (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25943\">#25943</a>)</li>\n<li>The <code>/rename</code> command now updates the terminal tab title by default (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25789\">#25789</a>)</li>\n<li>Fixed Edit tool silently corrupting Unicode curly quotes (\\u201c\\u201d \\u2018\\u2019) by replacing them with straight quotes when making edits (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26141\">#26141</a>)</li>\n<li>Fixed OSC 8 hyperlinks only being clickable on the first line when link text wraps across multiple terminal lines.</li>\n</ul>",
    "image_url": "",
    "published": "2026-02-18T21:38:45Z",
    "collected_at": "2026-02-19T11:03:15.968557+00:00",
    "ingest_batch_id": "20260219-110315",
    "tier": "tier1",
    "type": "release",
    "source_reliability": 0.806,
    "freshness": 0.776,
    "tier1_quick_score": 3.781,
    "v2_slot": "agent_tooling_releases",
    "v2_prefilter_score": 3.782,
    "llm_label_source": "heuristic",
    "llm_category": "release",
    "llm_summary_1line": "What's changed Fixed FileWriteTool line counting to preserve intentional trailing blank lines instead of stripping them with trimEnd() . Fixed Windows terminal rendering bugs caused by os.EOL ( \\r\\n ) in display code...",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.6,
    "v2_source_bias": 0.0,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.253,
    "summary_1line": "What's changed Fixed FileWriteTool line counting to preserve intentional trailing blank lines instead of stripping them with trimEnd() . Fixed Windows terminal rendering bugs caused by os.EOL ( \\r\\n ) in display code...",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.492,
    "v2_global_score": 2.745
  },
  {
    "id": "c58d7596e7e871ef",
    "source": "openai_codex_releases",
    "source_weight": 2.2,
    "title": "0.104.0",
    "url": "https://github.com/openai/codex/releases/tag/rust-v0.104.0",
    "summary": "<h2>New Features</h2>\n<ul>\n<li>Added <code>WS_PROXY</code>/<code>WSS_PROXY</code> environment support (including lowercase variants) for websocket proxying in the network proxy. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11784\">#11784</a>)</li>\n<li>App-server v2 now emits notifications when threads are archived or unarchived, enabling clients to react without polling. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12030\">#12030</a>)</li>\n<li>Protocol/core now carry distinct approval IDs for command approvals to support multiple approvals within a single shell command execution flow. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12051\">#12051</a>)</li>\n</ul>\n<h2>Bug Fixes</h2>\n<ul>\n<li><code>Ctrl+C</code>/<code>Ctrl+D</code> now cleanly exits the cwd-change prompt during resume/fork flows instead of implicitly selecting an option. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12040\">#12040</a>)</li>\n<li>Reduced false-positive safety-check downgrade behavior by relying on the response header model (and websocket top-level events) rather than the response body model slug. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12061\">#12061</a>)</li>\n</ul>\n<h2>Documentation</h2>\n<ul>\n<li>Updated docs and schemas to cover websocket proxy configuration, new thread archive/unarchive notifications, and the command approval ID plumbing. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11784\">#11784</a>, <a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12030\">#12030</a>, <a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12051\">#12051</a>)</li>\n</ul>\n<h2>Chores</h2>\n<ul>\n<li>Made the Rust release workflow resilient to <code>npm publish</code> attempts for an already-published version. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12044\">#12044</a>)</li>\n<li>Standardized remote compaction test mocking and refreshed related snapshots to align with the default production-shaped behavior. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12050\">#12050</a>)</li>\n</ul>\n<h2>Changelog</h2>\n<p>Full Changelog: <a class=\"commit-link\" href=\"https://github.com/openai/codex/compare/rust-v0.103.0...rust-v0.104.0\"><tt>rust-v0.103.0...rust-v0.104.0</tt></a></p>\n<ul>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11784\">#11784</a> feat(network-proxy): add websocket proxy env support <a class=\"user-mention notranslate\" href=\"https://github.com/viyatb-oai\">@viyatb-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12044\">#12044</a> don't fail if an npm publish attempt is for an existing version. <a class=\"user-mention notranslate\" href=\"https://github.com/iceweasel-oai\">@iceweasel-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12040\">#12040</a> tui: exit session on Ctrl+C in cwd change prompt <a class=\"user-mention notranslate\" href=\"https://github.com/charley-oai\">@charley-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12030\">#12030</a> app-server: Emit thread archive/unarchive notifications <a class=\"user-mention notranslate\" href=\"https://github.com/euroelessar\">@euroelessar</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12061\">#12061</a> Chore: remove response model check and rely on header model for downgrade <a class=\"user-mention notranslate\" href=\"https://github.com/shijie-oai\">@shijie-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12051\">#12051</a> feat(core): plumb distinct approval ids for command approvals <a class=\"user-mention notranslate\" href=\"https://github.com/owenlin0\">@owenlin0</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12050\">#12050</a> Unify remote compaction snapshot mocks around default endpoint behavior <a class=\"user-mention notranslate\" href=\"https://github.com/charley-oai\">@charley-oai</a></li>\n</ul>",
    "image_url": "",
    "published": "2026-02-18T07:13:02Z",
    "collected_at": "2026-02-19T11:03:15.968557+00:00",
    "ingest_batch_id": "20260219-110315",
    "tier": "tier1",
    "type": "release",
    "source_reliability": 0.806,
    "freshness": 0.599,
    "tier1_quick_score": 3.631,
    "v2_slot": "agent_tooling_releases",
    "v2_prefilter_score": 3.605,
    "llm_label_source": "heuristic",
    "llm_category": "release",
    "llm_summary_1line": "New Features Added WS_PROXY / WSS_PROXY environment support (including lowercase variants) for websocket proxying in the network proxy. ( #11784 ) App-server v2 now emits notifications when threads are archived or una...",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.6,
    "v2_source_bias": 0.0,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.2,
    "summary_1line": "New Features Added WS_PROXY / WSS_PROXY environment support (including lowercase variants) for websocket proxying in the network proxy. ( #11784 ) App-server v2 now emits notifications when threads are archived or una...",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.492,
    "v2_global_score": 2.692
  },
  {
    "id": "c35812ccca3ce7be",
    "source": "openai_blog",
    "source_weight": 2.0,
    "title": "Harness engineering: leveraging Codex in an agent-first world",
    "url": "https://openai.com/index/harness-engineering",
    "summary": "By Ryan Lopopolo, Member of the Technical Staff",
    "image_url": "",
    "published": "Wed, 11 Feb 2026 09:00:00 GMT",
    "collected_at": "2026-02-19T11:03:15.968557+00:00",
    "ingest_batch_id": "20260219-110315",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.806,
    "freshness": 0.088,
    "tier1_quick_score": 2.823,
    "v2_slot": "frontier_official",
    "v2_prefilter_score": 2.894,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "By Ryan Lopopolo, Member of the Technical Staff",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.0,
    "v2_source_bias": 0.1,
    "v2_topical_bias": 0.2,
    "v2_final_score": 1.918,
    "summary_1line": "By Ryan Lopopolo, Member of the Technical Staff",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.684,
    "v2_global_score": 2.602
  },
  {
    "id": "c16b69a1be247646",
    "source": "openai_blog",
    "source_weight": 2.0,
    "title": "GPT-5.2 derives a new result in theoretical physics",
    "url": "https://openai.com/index/new-result-theoretical-physics",
    "summary": "A new preprint shows GPT-5.2 proposing a new formula for a gluon amplitude, later formally proved and verified by OpenAI and academic collaborators.",
    "image_url": "",
    "published": "Fri, 13 Feb 2026 11:00:00 GMT",
    "collected_at": "2026-02-19T11:03:15.968557+00:00",
    "ingest_batch_id": "20260219-110315",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.806,
    "freshness": 0.164,
    "tier1_quick_score": 2.89,
    "v2_slot": "frontier_official",
    "v2_prefilter_score": 2.97,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "A new preprint shows GPT-5.2 proposing a new formula for a gluon amplitude, later formally proved and verified by OpenAI and academic collaborators.",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.2,
    "v2_source_bias": 0.1,
    "v2_topical_bias": 0.0,
    "v2_final_score": 1.893,
    "summary_1line": "A new preprint shows GPT-5.2 proposing a new formula for a gluon amplitude, later formally proved and verified by OpenAI and academic collaborators.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.684,
    "v2_global_score": 2.577
  },
  {
    "id": "b7dd9d05bcdf917e",
    "source": "claude_agent_sdk_python_releases",
    "source_weight": 1.3,
    "title": "v0.1.38",
    "url": "https://github.com/anthropics/claude-agent-sdk-python/releases/tag/v0.1.38",
    "summary": "<h3>Internal/Other Changes</h3>\n<ul>\n<li>Updated bundled Claude CLI to version 2.1.47</li>\n</ul>\n<hr />\n<p><strong>PyPI:</strong> <a href=\"https://pypi.org/project/claude-agent-sdk/0.1.38/\" rel=\"nofollow\">https://pypi.org/project/claude-agent-sdk/0.1.38/</a></p>\n<div class=\"highlight highlight-source-shell notranslate position-relative overflow-auto\"><pre>pip install claude-agent-sdk==0.1.38</pre></div>",
    "image_url": "",
    "published": "2026-02-18T21:57:56Z",
    "collected_at": "2026-02-19T11:03:15.968557+00:00",
    "ingest_batch_id": "20260219-110315",
    "tier": "tier1",
    "type": "release",
    "source_reliability": 0.806,
    "freshness": 0.78,
    "tier1_quick_score": 2.885,
    "v2_slot": "agent_tooling_releases",
    "v2_prefilter_score": 2.886,
    "llm_label_source": "heuristic",
    "llm_category": "release",
    "llm_summary_1line": "Internal/Other Changes Updated bundled Claude CLI to version 2.1.47 PyPI: https://pypi.org/project/claude-agent-sdk/0.1.38/ pip install claude-agent-sdk==0.1.38",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.25,
    "v2_source_bias": 0.0,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.009,
    "summary_1line": "Internal/Other Changes Updated bundled Claude CLI to version 2.1.47 PyPI: https://pypi.org/project/claude-agent-sdk/0.1.38/ pip install claude-agent-sdk==0.1.38",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.492,
    "v2_global_score": 2.501
  },
  {
    "id": "6ed48b697f4e1625",
    "source": "anthropic_newsroom",
    "source_weight": 1.8,
    "title": "Claude Sonnet 4 6",
    "url": "https://www.anthropic.com/news/claude-sonnet-4-6",
    "summary": "",
    "image_url": "",
    "published": "2026-02-17T17:45:22.000Z",
    "collected_at": "2026-02-19T11:03:15.968557+00:00",
    "ingest_batch_id": "20260219-110315",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.806,
    "freshness": 0.591,
    "tier1_quick_score": 3.116,
    "v2_slot": "frontier_official",
    "v2_prefilter_score": 3.197,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "Claude Sonnet 4 6",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.0,
    "v2_source_bias": 0.06,
    "v2_topical_bias": 0.0,
    "v2_final_score": 1.778,
    "summary_1line": "Claude Sonnet 4 6",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.684,
    "v2_global_score": 2.462
  },
  {
    "id": "f8127c71f0f00b70",
    "source": "claude_blog",
    "source_weight": 1.15,
    "title": "Improved Web Search With Dynamic Filtering",
    "url": "https://claude.com/blog/improved-web-search-with-dynamic-filtering",
    "summary": "",
    "image_url": "",
    "published": "2026-02-17T00:00:00+00:00",
    "collected_at": "2026-02-19T11:03:15.968557+00:00",
    "ingest_batch_id": "20260219-110315",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.806,
    "freshness": 0.473,
    "tier1_quick_score": 2.344,
    "v2_slot": "frontier_official",
    "v2_prefilter_score": 2.429,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "Improved Web Search With Dynamic Filtering",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.0,
    "v2_source_bias": 0.08,
    "v2_topical_bias": 0.0,
    "v2_final_score": 1.775,
    "summary_1line": "Improved Web Search With Dynamic Filtering",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.684,
    "v2_global_score": 2.459
  },
  {
    "id": "5ded8551ab4e9f3f",
    "source": "huggingface_blog",
    "source_weight": 1.1,
    "title": "IBM and UC Berkeley Diagnose Why Enterprise Agents Fail Using IT-Bench and MAST",
    "url": "https://huggingface.co/blog/ibm-research/itbenchandmast",
    "summary": "",
    "image_url": "",
    "published": "Wed, 18 Feb 2026 16:15:45 GMT",
    "collected_at": "2026-02-19T11:03:15.968557+00:00",
    "ingest_batch_id": "20260219-110315",
    "tier": "tier1",
    "type": "research",
    "source_reliability": 0.806,
    "freshness": 0.839,
    "tier1_quick_score": 2.622,
    "v2_slot": "research_watch",
    "v2_prefilter_score": 2.745,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "IBM and UC Berkeley Diagnose Why Enterprise Agents Fail Using IT-Bench and MAST",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.0,
    "v2_source_bias": 0.0,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.026,
    "summary_1line": "IBM and UC Berkeley Diagnose Why Enterprise Agents Fail Using IT-Bench and MAST",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.345,
    "v2_global_score": 2.371
  }
]