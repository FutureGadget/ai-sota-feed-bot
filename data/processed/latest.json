[
  {
    "id": "1801a1e24942383b",
    "source": "simon_willison",
    "source_weight": 1.25,
    "title": "Qwen3.5: Towards Native Multimodal Agents",
    "url": "https://simonwillison.net/2026/Feb/17/qwen35/#atom-everything",
    "summary": "<p><strong><a href=\"https://qwen.ai/blog?id=qwen3.5\">Qwen3.5: Towards Native Multimodal Agents</a></strong></p>\nAlibaba's Qwen just released the first two models in the Qwen 3.5 series - one open weights, one proprietary. Both are multi-modal for vision input.</p>\n<p>The open weight one is a Mixture of Experts model called Qwen3.5-397B-A17B. Interesting to see Qwen call out serving efficiency as a benefit of that architecture:</p>\n<blockquote>\n<p>Built on an innovative hybrid architecture that fuses linear attention (via Gated Delta Networks) with a sparse mixture-of-experts, the model attains remarkable inference efficiency: although it comprises 397 billion total parameters, just 17 billion are activated per forward pass, optimizing both speed and cost without sacrificing capability.</p>\n</blockquote>\n<p>It's <a href=\"https://huggingface.co/Qwen/Qwen3.5-397B-A17B\">807GB on Hugging Face</a>, and Unsloth have a <a href=\"https://huggingface.co/unsloth/Qwen3.5-397B-A17B-GGUF\">collection of smaller GGUFs</a> ranging in size from 94.2GB 1-bit to 462GB Q8_K_XL.</p>\n<p>I got this <a href=\"https://simonwillison.net/tags/pelican-riding-a-bicycle/\">pelican</a> from the <a href=\"https://openrouter.ai/qwen/qwen3.5-397b-a17b\">OpenRouter hosted model</a> (<a href=\"https://gist.github.com/simonw/625546cf6b371f9c0040e64492943b82\">transcript</a>):</p>\n<p><img alt=\"Pelican is quite good although the neck lacks an outline for some reason. Bicycle is very basic with an incomplete frame\" src=\"https://static.simonwillison.net/static/2026/qwen3.5-397b-a17b.png\" /></p>\n<p>The proprietary hosted model is called Qwen3.5 Plus 2026-02-15, and is a little confusing. Qwen researcher <a href=\"https://twitter.com/JustinLin610/status/2023340126479569140\">Junyang Lin  says</a>:</p>\n<blockquote>\n<p>Qwen3-Plus is a hosted API version of 397B. As the model natively supports 256K tokens, Qwen3.5-Plus supports 1M token context length. Additionally it supports search and code interpreter, which you can use on Qwen Chat with Auto mode.</p>\n</blockquote>\n<p>Here's <a href=\"https://gist.github.com/simonw/9507dd47483f78dc1195117735273e20\">its pelican</a>, which is similar in quality to the open weights model:</p>\n<p><img alt=\"Similar quality pelican. The bicycle is taller and has a better frame shape. They are visually quite similar.\" src=\"https://static.simonwillison.net/static/2026/qwen3.5-plus-02-15.png\" />\n\n\n    <p>Tags: <a href=\"https://simonwillison.net/tags/ai\">ai</a>, <a href=\"https://simonwillison.net/tags/generative-ai\">generative-ai</a>, <a href=\"https://simonwillison.net/tags/llms\">llms</a>, <a href=\"https://simonwillison.net/tags/vision-llms\">vision-llms</a>, <a href=\"https://simonwillison.net/tags/qwen\">qwen</a>, <a href=\"https://simonwillison.net/tags/pelican-riding-a-bicycle\">pelican-riding-a-bicycle</a>, <a href=\"https://simonwillison.net/tags/llm-release\">llm-release</a>, <a href=\"https://simonwillison.net/tags/openrouter\">openrouter</a>, <a href=\"https://simonwillison.net/tags/ai-in-china\">ai-in-china</a></p>",
    "image_url": "https://static.simonwillison.net/static/2026/qwen3.5-397b-a17b.png",
    "published": "2026-02-17T04:30:57+00:00",
    "collected_at": "2026-02-17T05:35:12.592840+00:00",
    "v2_slot": "practitioner_analysis",
    "freshness": 0.974,
    "source_reliability": 1.0,
    "v2_prefilter_score": 3.224,
    "type": "news",
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "Qwen3.5: Towards Native Multimodal Agents Alibaba's Qwen just released the first two models in the Qwen 3.5 series - one open weights, one proprietary. Both are multi-modal for vision input. The open weight one is a M...",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.8,
    "v2_source_bias": 0.08,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.806,
    "summary_1line": "Qwen3.5: Towards Native Multimodal Agents Alibaba's Qwen just released the first two models in the Qwen 3.5 series - one open weights, one proprietary. Both are multi-modal for vision input. The open weight one is a M...",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.576,
    "v2_global_score": 3.382
  },
  {
    "id": "0b9784e78fa0f8a8",
    "source": "simon_willison",
    "source_weight": 1.25,
    "title": "Two new Showboat tools: Chartroom and datasette-showboat",
    "url": "https://simonwillison.net/2026/Feb/17/chartroom-and-datasette-showboat/#atom-everything",
    "summary": "<p>I <a href=\"https://simonwillison.net/2026/Feb/10/showboat-and-rodney/\">introduced Showboat</a> a week ago - my CLI tool that helps coding agents create Markdown documents that demonstrate the code that they have created. I've been finding new ways to use it on a daily basis, and I've just released two new tools to help get the best out of the Showboat pattern. <a href=\"https://github.com/simonw/chartroom\">Chartroom</a> is a CLI charting tool that works well with Showboat, and <a href=\"https://github.com/simonw/datasette-showboat\">datasette-showboat</a> lets Showboat's new remote publishing feature incrementally push documents to a Datasette instance.</p>\n\n<ul>\n  <li><a href=\"https://simonwillison.net/2026/Feb/17/chartroom-and-datasette-showboat/#showboat-remote-publishing\">Showboat remote publishing</a></li>\n  <li><a href=\"https://simonwillison.net/2026/Feb/17/chartroom-and-datasette-showboat/#datasette-showboat\">datasette-showboat</a></li>\n  <li><a href=\"https://simonwillison.net/2026/Feb/17/chartroom-and-datasette-showboat/#chartroom\">Chartroom</a></li>\n  <li><a href=\"https://simonwillison.net/2026/Feb/17/chartroom-and-datasette-showboat/#how-i-built-chartroom\">How I built Chartroom</a></li>\n  <li><a href=\"https://simonwillison.net/2026/Feb/17/chartroom-and-datasette-showboat/#the-burgeoning-showboat-ecosystem\">The burgeoning Showboat ecosystem</a></li>\n</ul>\n\n<h4 id=\"showboat-remote-publishing\">Showboat remote publishing</h4>\n<p>I normally use Showboat in Claude Code for web (see <a href=\"https://simonwillison.net/2026/Feb/16/rodney-claude-code/\">note from this morning</a>). I've used it in several different projects in the past few days, each of them with a prompt that looks something like this:</p>\n<blockquote>\n<p><code>Use \"uvx showboat --help\" to perform a very thorough investigation of what happens if you use the Python sqlite-chronicle and sqlite-history-json libraries against the same SQLite database table</code></p>\n</blockquote>\n<p>Here's <a href=\"https://github.com/simonw/research/blob/main/sqlite-chronicle-vs-history-json/demo.md\">the resulting document</a>.</p>\n<p>Just telling Claude Code to run <code>uvx showboat --help</code> is enough for it to learn how to use the tool - the <a href=\"https://github.com/simonw/showboat/blob/main/help.txt\">help text</a> is designed to work as a sort of ad-hoc Skill document.</p>\n<p>The one catch with this approach is that I can't <em>see</em> the new Showboat document until it's finished. I have to wait for Claude to commit the document plus embedded screenshots and push that to a branch in my GitHub repo - then I can view it through the GitHub interface.</p>\n<p>For a while I've been thinking it would be neat to have a remote web server of my own which Claude instances can submit updates to while they are working. Then this morning I realized Showboat might be the ideal mechanism to set that up...</p>\n<p>Showboat <a href=\"https://github.com/simonw/showboat/releases/tag/v0.6.0\">v0.6.0</a> adds a new \"remote\" feature. It's almost invisible to users of the tool itself, instead being configured by an environment variable.</p>\n<p>Set a variable like this:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">export</span> SHOWBOAT_REMOTE_URL=https://www.example.com/submit<span class=\"pl-k\">?</span>token=xyz</pre></div>\n<p>And every time you run a <code>showboat init</code> or <code>showboat note</code> or <code>showboat exec</code> or <code>showboat image</code> command the resulting document fragments will be POSTed to that API endpoint, in addition to the Showboat Markdown file itself being updated.</p>\n<p>There are <a href=\"https://github.com/simonw/showboat/blob/v0.6.0/README.md#remote-document-streaming\">full details in the Showboat README</a> - it's a very simple API format, using regular POST form variables or a multipart form upload for the image attached to <code>showboat image</code>.</p>\n<h4 id=\"datasette-showboat\">datasette-showboat</h4>\n<p>It's simple enough to build a webapp to receive these updates from Showboat, but I needed one that I could easily deploy and would work well with the rest of my personal ecosystem.</p>\n<p>So I had Claude Code write me a Datasette plugin that could act as a Showboat remote endpoint. I actually had this building at the same time as the Showboat remote feature, a neat example of running <a href=\"https://simonwillison.net/2025/Oct/5/parallel-coding-agents/\">parallel agents</a>.</p>\n<p><strong><a href=\"https://github.com/simonw/datasette-showboat\">datasette-showboat</a></strong> is a Datasette plugin that adds a <code>/-/showboat</code> endpoint to Datasette for viewing documents and a <code>/-/showboat/receive</code> endpoint for receiving updates from Showboat.</p>\n<p>Here's a very quick way to try it out:</p>\n<div class=\"highlight highlight-source-shell\"><pre>uvx --with datasette-showboat --prerelease=allow \\\n  datasette showboat.db --create \\\n  -s plugins.datasette-showboat.database showboat \\\n  -s plugins.datasette-showboat.token secret123 \\\n  --root --secret cookie-secret-123</pre></div>\n<p>Click on the sign in as root link that shows up in the console, then navigate to <a href=\"http://127.0.0.1:8001/-/showboat\">http://127.0.0.1:8001/-/showboat</a> to see the interface.</p>\n<p>Now set your environment variable to point to this instance:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">export</span> SHOWBOAT_REMOTE_URL=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>http://127.0.0.1:8001/-/showboat/receive?token=secret123<span class=\"pl-pds\">\"</span></span></pre></div>\n<p>And run Showboat like this:</p>\n<div class=\"highlight highlight-source-shell\"><pre>uvx showboat init demo.md <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Showboat Feature Demo<span class=\"pl-pds\">\"</span></span></pre></div>\n<p>Refresh that page and you should see this:</p>\n<p><img alt=\"Title: Showboat. Remote viewer for Showboat documents. Showboat Feature Demo 2026-02-17 00:06 · 6 chunks, UUID. To send showboat output to this server, set the SHOWBOAT_REMOTE_URL environment variable: export SHOWBOAT_REMOTE_URL=&quot;http://127.0.0.1:8001/-/showboat/receive?token=your-token&quot;\" src=\"https://static.simonwillison.net/static/2026/datasette-showboat-documents.jpg\" /></p>\n<p>Click through to the document, then start Claude Code or Codex or your agent of choice and prompt:</p>\n<blockquote>\n<p><code>Run 'uvx showboat --help' and then use showboat to add to the existing demo.md document with notes and exec and image to demonstrate the tool - fetch a placekitten for the image demo.</code></p>\n</blockquote>\n<p>The <code>init</code> command assigns a UUID and title and sends those up to Datasette.</p>\n<p><img alt=\"Animated demo - in the foreground a terminal window runs Claude Code, which executes various Showboat commands. In the background a Firefox window where the Showboat Feature Demo adds notes then some bash commands, then a placekitten image.\" src=\"https://static.simonwillison.net/static/2026/datasette-showboat.gif\" /></p>\n<p>The best part of this is that it works in Claude Code for web. Run the plugin on a server somewhere (an exercise left up to the reader - I use <a href=\"https://fly.io/\">Fly.io</a> to host mine) and set that <code>SHOWBOAT_REMOTE_URL</code> environment variable in your Claude environment, then any time you tell it to use Showboat the document it creates will be transmitted to your server and viewable in real time.</p>\n<p>I built <a href=\"https://simonwillison.net/2026/Feb/10/showboat-and-rodney/#rodney-cli-browser-automation-designed-to-work-with-showboat\">Rodney</a>, a CLI browser automation tool, specifically to work with Showboat. It makes it easy to have a Showboat document load up web pages, interact with them via clicks or injected JavaScript and captures screenshots to embed in the Showboat document and show the effects.</p>\n<p>This is wildly useful for hacking on web interfaces using Claude Code for web, especially when coupled with the new remote publishing feature. I only got this stuff working this morning and I've already had several sessions where Claude Code has published screenshots of its work in progress, which I've then been able to provide feedback on directly in the Claude session while it's still working.</p>\n<h3 id=\"chartroom\">Chartroom</h3>\n<p>A few days ago I had another idea for a way to extend the Showboat ecosystem: what if Showboat documents could easily include charts?</p>\n<p>I sometimes fire up Claude Code for data analysis tasks, often telling it to download a SQLite database and then run queries against it to figure out interesting things from the data.</p>\n<p>With a simple CLI tool that produced PNG images I could have Claude use Showboat to build a document with embedded charts to help illustrate its findings.</p>\n<p><strong><a href=\"https://github.com/simonw/chartroom\">Chartroom</a></strong> is exactly that. It's effectively a thin wrapper around the excellent <a href=\"https://matplotlib.org/\">matplotlib</a> Python library, designed to be used by coding agents to create charts that can be embedded in Showboat documents.</p>\n<p>Here's how to render a simple bar chart:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c1\">echo</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>name,value</span>\n<span class=\"pl-s\">Alice,42</span>\n<span class=\"pl-s\">Bob,28</span>\n<span class=\"pl-s\">Charlie,35</span>\n<span class=\"pl-s\">Diana,51</span>\n<span class=\"pl-s\">Eve,19<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">|</span> uvx chartroom bar --csv \\\n  --title <span class=\"pl-s\"><span class=\"pl-pds\">'</span>Sales by Person<span class=\"pl-pds\">'</span></span> --ylabel <span class=\"pl-s\"><span class=\"pl-pds\">'</span>Sales<span class=\"pl-pds\">'</span></span></pre></div>\n<p><a href=\"https://raw.githubusercontent.com/simonw/chartroom/8812afc02e1310e9eddbb56508b06005ff2c0ed5/demo/1f6851ec-2026-02-14.png\" rel=\"noopener noreferrer nofollow\" target=\"_blank\"><img alt=\"A chart of those numbers, with a title and y-axis label\" src=\"https://raw.githubusercontent.com/simonw/chartroom/8812afc02e1310e9eddbb56508b06005ff2c0ed5/demo/1f6851ec-2026-02-14.png\" /></a></p>\n<p>It can also do line charts, bar charts, scatter charts, and histograms - as seen in <a href=\"https://github.com/simonw/chartroom/blob/0.2.1/demo/README.md\">this demo document</a> that was built using Showboat.</p>\n<p>Chartroom can also generate alt text. If you add <code>-f alt</code> to the above it will output the alt text for the chart instead of the image:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c1\">echo</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>name,value</span>\n<span class=\"pl-s\">Alice,42</span>\n<span class=\"pl-s\">Bob,28</span>\n<span class=\"pl-s\">Charlie,35</span>\n<span class=\"pl-s\">Diana,51</span>\n<span class=\"pl-s\">Eve,19<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">|</span> uvx chartroom bar --csv \\\n  --title <span class=\"pl-s\"><span class=\"pl-pds\">'</span>Sales by Person<span class=\"pl-pds\">'</span></span> --ylabel <span class=\"pl-s\"><span class=\"pl-pds\">'</span>Sales<span class=\"pl-pds\">'</span></span> -f alt</pre></div>\n<p>Outputs:</p>\n<pre><code>Sales by Person. Bar chart of value by name — Alice: 42, Bob: 28, Charlie: 35, Diana: 51, Eve: 19\n</code></pre>\n<p>Or you can use <code>-f html</code> or <code>-f markdown</code> to get the image tag with alt text directly:</p>\n<div class=\"highlight highlight-text-md\"><pre><span class=\"pl-s\">![</span>Sales by Person. Bar chart of value by name — Alice: 42, Bob: 28, Charlie: 35, Diana: 51, Eve: 19<span class=\"pl-s\">]</span><span class=\"pl-s\">(</span><span class=\"pl-corl\">/Users/simon/chart-7.png</span><span class=\"pl-s\">)</span></pre></div>\n<p>I added support for Markdown images with alt text to Showboat in <a href=\"https://github.com/simonw/showboat/releases/tag/v0.5.0\">v0.5.0</a>, to complement this feature of Chartroom.</p>\n<p>Finally, Chartroom has support for different <a href=\"https://matplotlib.org/stable/gallery/style_sheets/style_sheets_reference.html\">matplotlib styles</a>. I had Claude build a Showboat document to demonstrate these all in one place - you can see that at <a href=\"https://github.com/simonw/chartroom/blob/main/demo/styles.md\">demo/styles.md</a>.</p>\n<h4 id=\"how-i-built-chartroom\">How I built Chartroom</h4>\n<p>I started the Chartroom repository with my <a href=\"https://github.com/simonw/click-app\">click-app</a> cookiecutter template, then told a fresh Claude Code for web session:</p>\n<blockquote>\n<p>We are building a Python CLI tool which uses matplotlib to generate a PNG image containing a chart. It will have multiple sub commands for different chart types, controlled by command line options. Everything you need to know to use it will be available in the single \"chartroom --help\" output.</p>\n<p>It will accept data from files or standard input as CSV or TSV or JSON, similar to how sqlite-utils accepts data - clone simonw/sqlite-utils to /tmp for reference there. Clone matplotlib/matplotlib for reference as well</p>\n<p>It will also accept data from --sql path/to/sqlite.db \"select ...\" which runs in read-only mode</p>\n<p>Start by asking clarifying questions - do not use the ask user tool though it is broken - and generate a spec for me to approve</p>\n<p>Once approved proceed using red/green TDD running tests with \"uv run pytest\"</p>\n<p>Also while building maintain a demo/README.md document using the \"uvx showboat --help\" tool - each time you get a new chart type working commit the tests, implementation, root level\nREADME update and a new version of that demo/README.md document with an inline image demo of the new chart type (which should be a UUID image filename managed by the showboat image command and should be stored in the demo/ folder</p>\n<p>Make sure \"uv build\" runs cleanly without complaining about extra directories but also ensure dist/ and uv.lock are in gitignore</p>\n</blockquote>\n<p>This got most of the work done. You can see the rest <a href=\"https://github.com/simonw/chartroom/pulls?q=is%3Apr+is%3Aclosed\">in the PRs</a> that followed.</p>\n<h4 id=\"the-burgeoning-showboat-ecosystem\">The burgeoning Showboat ecosystem</h4>\n<p>The Showboat family of tools now consists of <a href=\"https://github.com/simonw/showboat\">Showboat</a> itself, <a href=\"https://github.com/simonw/rodney\">Rodney</a> for browser automation, <a href=\"https://github.com/simonw/chartroom\">Chartroom</a> for charting and <a href=\"https://github.com/simonw/datasette-showboat\">datasette-showboat</a> for streaming remote Showboat documents to Datasette.</p>\n<p>I'm enjoying how these tools can operate together based on a very loose set of conventions. If a tool can output a path to an image Showboat can include that image in a document. Any tool that can output text can be used with Showboat.</p>\n<p>I'll almost certainly be building more tools that fit this pattern. They're very quick to knock out!</p>\n<p>The environment variable mechanism for Showboat's remote streaming is a fun hack too - so far I'm just using it to stream documents somewhere else, but it's effectively a webhook extension mechanism that could likely be used for all sorts of things I haven't thought of yet.</p>\n    \n        <p>Tags: <a href=\"https://simonwillison.net/tags/projects\">projects</a>, <a href=\"https://simonwillison.net/tags/ai\">ai</a>, <a href=\"https://simonwillison.net/tags/datasette\">datasette</a>, <a href=\"https://simonwillison.net/tags/generative-ai\">generative-ai</a>, <a href=\"https://simonwillison.net/tags/llms\">llms</a>, <a href=\"https://simonwillison.net/tags/ai-assisted-programming\">ai-assisted-programming</a>, <a href=\"https://simonwillison.net/tags/coding-agents\">coding-agents</a>, <a href=\"https://simonwillison.net/tags/claude-code\">claude-code</a>, <a href=\"https://simonwillison.net/tags/showboat\">showboat</a></p>",
    "image_url": "https://static.simonwillison.net/static/2026/datasette-showboat-documents.jpg",
    "published": "2026-02-17T00:43:45+00:00",
    "collected_at": "2026-02-17T05:35:12.592840+00:00",
    "v2_slot": "practitioner_analysis",
    "freshness": 0.886,
    "source_reliability": 1.0,
    "v2_prefilter_score": 3.136,
    "type": "news",
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "I introduced Showboat a week ago - my CLI tool that helps coding agents create Markdown documents that demonstrate the code that they have created. I've been finding new ways to use it on a daily basis, and I've just...",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.75,
    "v2_source_bias": 0.08,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.75,
    "summary_1line": "Showboat ecosystem expands with Chartroom (agent-friendly charting) and datasette-showboat (real-time remote document streaming for Claude Code workflows).",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.576,
    "v2_global_score": 3.326
  },
  {
    "id": "b4a1f65fd2c36642",
    "source": "infoq_ai_ml",
    "source_weight": 1.15,
    "title": "Google Explores Scaling Principles for Multi-agent Coordination",
    "url": "https://www.infoq.com/news/2026/02/google-agent-scaling-principles/?utm_campaign=infoq_content&utm_source=infoq&utm_medium=feed&utm_term=AI%2C+ML+%26+Data+Engineering",
    "summary": "<img src=\"https://res.infoq.com/news/2026/02/google-agent-scaling-principles/en/headerimage/google-scaling-agents-principles-1771231654834.jpeg\" /><p>Google Research tried to answer the question of how to design agent systems for optimal performance by running a controlled evaluation of 180 agent configurations. From this, the team derived what they call the \"first quantitative scaling principles for AI agent systems\", showing that multi-agent coordination does not reliably improve results and can even reduce performance.</p> <i>By Sergio De Simone</i>",
    "image_url": "https://res.infoq.com/news/2026/02/google-agent-scaling-principles/en/headerimage/google-scaling-agents-principles-1771231654834.jpeg",
    "published": "Mon, 16 Feb 2026 09:00:00 GMT",
    "collected_at": "2026-02-17T05:35:12.592840+00:00",
    "v2_slot": "practitioner_analysis",
    "freshness": 0.598,
    "source_reliability": 1.0,
    "v2_prefilter_score": 2.748,
    "type": "news",
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "Google Research tried to answer the question of how to design agent systems for optimal performance by running a controlled evaluation of 180 agent configurations. From this, the team derived what they call the \"first...",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.6,
    "v2_source_bias": 0.08,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.58,
    "summary_1line": "Google's controlled study of 180 agent configs reveals multi-agent coordination doesn't reliably boost performance, sometimes hurts it—challenges common scaling assumptions.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.576,
    "v2_global_score": 3.156
  },
  {
    "id": "28aeb3b7d9a1e43f",
    "source": "infoq_ai_ml",
    "source_weight": 1.15,
    "title": "Article: Architecting Agentic MLOps: A Layered Protocol Strategy with A2A and MCP",
    "url": "https://www.infoq.com/articles/architecting-agentic-mlops-a2a-mcp/?utm_campaign=infoq_content&utm_source=infoq&utm_medium=feed&utm_term=AI%2C+ML+%26+Data+Engineering",
    "summary": "<img src=\"https://res.infoq.com/articles/architecting-agentic-mlops-a2a-mcp/en/headerimage/architecting-agentic-mlops-a2a-mcp-header-1770303550343.jpg\" /><p>In this article, the authors outline protocols for building extensible multi-agent MLOps systems. The core architecture deliberately decouples orchestration from execution, allowing teams to incrementally add capabilities via discovery and evolve operations from static pipelines toward intelligent, adaptive coordination.</p> <i>By Shashank Kapoor, Sanjay Surendranath Girija, Lakshit Arora</i>",
    "image_url": "https://res.infoq.com/articles/architecting-agentic-mlops-a2a-mcp/en/headerimage/architecting-agentic-mlops-a2a-mcp-header-1770303550343.jpg",
    "published": "Mon, 16 Feb 2026 09:00:00 GMT",
    "collected_at": "2026-02-17T05:35:12.592840+00:00",
    "v2_slot": "practitioner_analysis",
    "freshness": 0.598,
    "source_reliability": 1.0,
    "v2_prefilter_score": 2.748,
    "type": "news",
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "In this article, the authors outline protocols for building extensible multi-agent MLOps systems. The core architecture deliberately decouples orchestration from execution, allowing teams to incrementally add capabili...",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.4,
    "v2_source_bias": 0.08,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.41,
    "summary_1line": "Layered protocol architecture for multi-agent MLOps using A2A and MCP to decouple orchestration from execution and enable incremental capability extension.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.576,
    "v2_global_score": 2.986
  },
  {
    "id": "4a9f636f53197519",
    "source": "claude_code_releases",
    "source_weight": 2.2,
    "title": "v2.1.44",
    "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.44",
    "summary": "<h2>What's changed</h2>\n<ul>\n<li>Fixed auth refresh errors</li>\n</ul>",
    "image_url": "",
    "published": "2026-02-16T21:35:03Z",
    "collected_at": "2026-02-17T05:35:12.592840+00:00",
    "v2_slot": "agent_tooling_releases",
    "freshness": 0.867,
    "source_reliability": 1.0,
    "v2_prefilter_score": 4.067,
    "type": "release",
    "llm_label_source": "llm",
    "llm_category": "release",
    "llm_summary_1line": "Claude Code v2.1.44 patches authentication refresh errors, improving reliability for agentic coding workflows.",
    "llm_why_1line": "Direct fix to auth infrastructure critical for production agent reliability; minimal detail limits immediate actionability.",
    "v2_llm_score": 3.05,
    "v2_source_bias": 0.0,
    "v2_topical_bias": 0.0,
    "v2_final_score": 2.395,
    "summary_1line": "Claude Code v2.1.44 fixes auth refresh errors for improved CLI reliability.",
    "why_it_matters": "Direct fix to auth infrastructure critical for production agent reliability; minimal detail limits immediate actionability.",
    "v2_slot_priority": 0.448,
    "v2_global_score": 2.843
  },
  {
    "id": "a5330106c519e42a",
    "source": "hackernews_ai",
    "source_weight": 1.1,
    "title": "Agent-evals: Overlap, boundary, and metacognitive scoring for coding agents",
    "url": "https://thinkwright.ai/agent-evals",
    "summary": "<p>Article URL: <a href=\"https://thinkwright.ai/agent-evals\">https://thinkwright.ai/agent-evals</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47043129\">https://news.ycombinator.com/item?id=47043129</a></p>\n<p>Points: 1</p>\n<p># Comments: 1</p>",
    "image_url": "",
    "published": "Tue, 17 Feb 2026 02:49:57 +0000",
    "collected_at": "2026-02-17T05:35:12.592840+00:00",
    "v2_slot": "community_signal",
    "freshness": 0.842,
    "source_reliability": 1.0,
    "v2_prefilter_score": 2.942,
    "type": "news",
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "Article URL: https://thinkwright.ai/agent-evals Comments URL: https://news.ycombinator.com/item?id=47043129 Points: 1 # Comments: 1",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.6,
    "v2_source_bias": 0.0,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.361,
    "summary_1line": "Article URL: https://thinkwright.ai/agent-evals Comments URL: https://news.ycombinator.com/item?id=47043129 Points: 1 # Comments: 1",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.471,
    "v2_global_score": 2.832
  },
  {
    "id": "a311197adc8a5fb3",
    "source": "arxiv_cs_ai",
    "source_weight": 0.85,
    "title": "Hunt Globally: Deep Research AI Agents for Drug Asset Scouting in Investing, Business Development, and Search & Evaluation",
    "url": "http://arxiv.org/abs/2602.15019v1",
    "summary": "Bio-pharmaceutical innovation has shifted: many new drug assets now originate outside the United States and are disclosed primarily via regional, non-English channels. Recent data suggests >85% of patent filings originate outside the U.S., with China accounting for nearly half of the global total; a growing share of scholarly output is also non-U.S. Industry estimates put China at ~30% of global drug development, spanning 1,200+ novel candidates. In this high-stakes environment, failing to surface \"under-the-radar\" assets creates multi-billion-dollar risk for investors and business development teams, making asset scouting a coverage-critical competition where speed and completeness drive value. Yet today's Deep Research AI agents still lag human experts in achieving high-recall discovery across heterogeneous, multilingual sources without hallucinations.\n  We propose a benchmarking methodology for drug asset scouting and a tuned, tree-based self-learning Bioptic Agent aimed at complete, non-hallucinated scouting. We construct a challenging completeness benchmark using a multilingual multi-agent pipeline: complex user queries paired with ground-truth assets that are largely outside U.S.-centric radar. To reflect real deal complexity, we collected screening queries from expert investors, BD, and VC professionals and used them as priors to conditionally generate benchmark queries. For grading, we use LLM-as-judge evaluation calibrated to expert opinions. We compare Bioptic Agent against Claude Opus 4.6, OpenAI GPT-5.2 Pro, Perplexity Deep Research, Gemini 3 Pro + Deep Research, and Exa Websets. Bioptic Agent achieves 79.7% F1 versus 56.2% (Claude Opus 4.6), 50.6% (Gemini 3 Pro + Deep Research), 46.6% (GPT-5.2 Pro), 44.2% (Perplexity Deep Research), and 26.9% (Exa Websets). Performance improves steeply with additional compute, supporting the view that more compute yields better results.",
    "image_url": "",
    "published": "2026-02-16T18:57:49Z",
    "collected_at": "2026-02-17T05:35:12.592840+00:00",
    "v2_slot": "research_watch",
    "freshness": 0.909,
    "source_reliability": 1.0,
    "v2_prefilter_score": 2.759,
    "type": "paper",
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "Bio-pharmaceutical innovation has shifted: many new drug assets now originate outside the United States and are disclosed primarily via regional, non-English channels. Recent data suggests >85% of patent filings origi...",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.85,
    "v2_source_bias": -0.35,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.409,
    "summary_1line": "Drug asset discovery agent benchmarks multilingual sources; claims 79.7% F1 vs 56.2% for Claude Opus on specialized pharmaceutical scouting task.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.378,
    "v2_global_score": 2.787
  },
  {
    "id": "fe7dbebc903fef59",
    "source": "anthropic_research",
    "source_weight": 1.4,
    "title": "India Brief Economic Index",
    "url": "https://www.anthropic.com/research/india-brief-economic-index",
    "summary": "",
    "image_url": "",
    "published": "2026-02-16T23:13:32.000Z",
    "collected_at": "2026-02-17T05:35:12.592840+00:00",
    "v2_slot": "research_watch",
    "freshness": 0.945,
    "source_reliability": 1.0,
    "v2_prefilter_score": 3.345,
    "type": "research",
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "India Brief Economic Index",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.0,
    "v2_source_bias": 0.4,
    "v2_topical_bias": 0.0,
    "v2_final_score": 2.242,
    "summary_1line": "Economic index research on India's brief labor market—unrelated to agentic coding, agent harness, or production LLM infrastructure.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.378,
    "v2_global_score": 2.62
  },
  {
    "id": "5983155f3e279e8e",
    "source": "latent_space",
    "source_weight": 1.2,
    "title": "[AINews] Qwen3.5-397B-A17B: the smallest Open-Opus class, very efficient model",
    "url": "https://www.latent.space/p/ainews-qwen35-397b-a17b-the-smallest",
    "summary": "Congrats Qwen team!",
    "image_url": "https://substackcdn.com/image/fetch/$s_!1fDP!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0472c69a-cd07-4bde-8b10-61bc1d0702a7_2444x1704.png",
    "published": "Tue, 17 Feb 2026 04:22:56 GMT",
    "collected_at": "2026-02-17T05:35:12.592840+00:00",
    "v2_slot": "practitioner_analysis",
    "freshness": 0.97,
    "source_reliability": 1.0,
    "v2_prefilter_score": 3.17,
    "type": "news",
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "Congrats Qwen team!",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.2,
    "v2_source_bias": 0.0,
    "v2_topical_bias": 0.0,
    "v2_final_score": 2.016,
    "summary_1line": "Congrats Qwen team!",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.576,
    "v2_global_score": 2.592
  },
  {
    "id": "f75baf298ba21604",
    "source": "anthropic_newsroom",
    "source_weight": 1.8,
    "title": "Bengaluru Office Partnerships Across India",
    "url": "https://www.anthropic.com/news/bengaluru-office-partnerships-across-india",
    "summary": "",
    "image_url": "",
    "published": "2026-02-16T21:31:12.000Z",
    "collected_at": "2026-02-17T05:35:12.592840+00:00",
    "v2_slot": "frontier_official",
    "freshness": 0.714,
    "source_reliability": 1.0,
    "v2_prefilter_score": 3.514,
    "type": "news",
    "llm_label_source": "llm",
    "llm_category": "platform",
    "llm_summary_1line": "Anthropic announces Bengaluru office partnerships across India.",
    "llm_why_1line": "Office/business expansion announcement; zero relevance to agentic coding, platform delivery, or engineering automation.",
    "v2_llm_score": 0.5,
    "v2_source_bias": 0.06,
    "v2_topical_bias": -0.2,
    "v2_final_score": 0.403,
    "summary_1line": "Anthropic opens Bengaluru office and announces regional partnerships across India.",
    "why_it_matters": "Office/business expansion announcement; zero relevance to agentic coding, platform delivery, or engineering automation.",
    "v2_slot_priority": 0.629,
    "v2_global_score": 1.032
  },
  {
    "id": "c91a4996533a3bbb",
    "source": "arxiv_cs_lg",
    "source_weight": 0.85,
    "title": "Use What You Know: Causal Foundation Models with Partial Graphs",
    "url": "http://arxiv.org/abs/2602.14972v1",
    "summary": "Estimating causal quantities traditionally relies on bespoke estimators tailored to specific assumptions. Recently proposed Causal Foundation Models (CFMs) promise a more unified approach by amortising causal discovery and inference in a single step. However, in their current state, they do not allow for the incorporation of any domain knowledge, which can lead to suboptimal predictions. We bridge this gap by introducing methods to condition CFMs on causal information, such as the causal graph or more readily available ancestral information. When access to complete causal graph information is too strict a requirement, our approach also effectively leverages partial causal information. We systematically evaluate conditioning strategies and find that injecting learnable biases into the attention mechanism is the most effective method to utilise full and partial causal information. Our experiments show that this conditioning allows a general-purpose CFM to match the performance of specialised models trained on specific causal structures. Overall, our approach addresses a central hurdle on the path towards all-in-one causal foundation models: the capability to answer causal queries in a data-driven manner while effectively leveraging any amount of domain expertise.",
    "image_url": "",
    "published": "2026-02-16T17:56:37Z",
    "collected_at": "2026-02-17T05:35:12.592840+00:00",
    "v2_slot": "research_watch",
    "freshness": 0.901,
    "source_reliability": 1.0,
    "v2_prefilter_score": 2.751,
    "type": "paper",
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "Estimating causal quantities traditionally relies on bespoke estimators tailored to specific assumptions. Recently proposed Causal Foundation Models (CFMs) promise a more unified approach by amortising causal discover...",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.6,
    "v2_source_bias": -0.35,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.195,
    "summary_1line": "Causal Foundation Models now accept partial graph conditioning via learnable attention biases, matching specialized model performance on causal inference tasks.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.378,
    "v2_global_score": 2.573
  },
  {
    "id": "bef44b20b585b2ba",
    "source": "claude_agent_sdk_python_releases",
    "source_weight": 1.3,
    "title": "v0.1.37",
    "url": "https://github.com/anthropics/claude-agent-sdk-python/releases/tag/v0.1.37",
    "summary": "<h3>Internal/Other Changes</h3>\n<ul>\n<li>Updated bundled Claude CLI to version 2.1.44</li>\n</ul>\n<hr />\n<p><strong>PyPI:</strong> <a href=\"https://pypi.org/project/claude-agent-sdk/0.1.37/\" rel=\"nofollow\">https://pypi.org/project/claude-agent-sdk/0.1.37/</a></p>\n<div class=\"highlight highlight-source-shell notranslate position-relative overflow-auto\"><pre>pip install claude-agent-sdk==0.1.37</pre></div>",
    "image_url": "",
    "published": "2026-02-16T21:51:27Z",
    "collected_at": "2026-02-17T05:35:12.592840+00:00",
    "v2_slot": "agent_tooling_releases",
    "freshness": 0.871,
    "source_reliability": 1.0,
    "v2_prefilter_score": 3.171,
    "type": "release",
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "Internal/Other Changes Updated bundled Claude CLI to version 2.1.44 PyPI: https://pypi.org/project/claude-agent-sdk/0.1.37/ pip install claude-agent-sdk==0.1.37",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.0,
    "v2_source_bias": 0.0,
    "v2_topical_bias": 0.2,
    "v2_final_score": 1.861,
    "summary_1line": "Claude Agent SDK v0.1.37 bumps bundled Claude CLI to 2.1.44 with internal updates.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.448,
    "v2_global_score": 2.309
  },
  {
    "id": "7bdea70aab3e6e06",
    "source": "openai_codex_releases",
    "source_weight": 2.2,
    "title": "0.101.0",
    "url": "https://github.com/openai/codex/releases/tag/rust-v0.101.0",
    "summary": "<h2>Bug Fixes</h2>\n<ul>\n<li>Model resolution now preserves the requested model slug when selecting by prefix, so model references stay stable instead of being rewritten. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11602\">#11602</a>)</li>\n<li>Developer messages are now excluded from phase-1 memory input, reducing noisy or irrelevant content entering memory. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11608\">#11608</a>)</li>\n<li>Memory phase processing concurrency was reduced to make consolidation/staging more stable under load. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11614\">#11614</a>)</li>\n</ul>\n<h2>Chores</h2>\n<ul>\n<li>Cleaned and simplified the phase-1 memory pipeline code paths. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11605\">#11605</a>)</li>\n<li>Minor repository maintenance: formatting and test-suite hygiene updates in remote model tests. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11619\">#11619</a>)</li>\n</ul>\n<h2>Changelog</h2>\n<p>Full Changelog: <a class=\"commit-link\" href=\"https://github.com/openai/codex/compare/rust-v0.100.0...rust-v0.101.0\"><tt>rust-v0.100.0...rust-v0.101.0</tt></a></p>\n<ul>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11605\">#11605</a> chore: drop and clean from phase 1 <a class=\"user-mention notranslate\" href=\"https://github.com/jif-oai\">@jif-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11602\">#11602</a> fix(core) model_info preserves slug <a class=\"user-mention notranslate\" href=\"https://github.com/dylan-hurd-oai\">@dylan-hurd-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11608\">#11608</a> exclude developer messages from phase-1 memory input <a class=\"user-mention notranslate\" href=\"https://github.com/wendyjiao-openai\">@wendyjiao-openai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11591\">#11591</a> Add cwd to memory files <a class=\"user-mention notranslate\" href=\"https://github.com/wendyjiao-openai\">@wendyjiao-openai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11614\">#11614</a> chore: reduce concurrency of memories <a class=\"user-mention notranslate\" href=\"https://github.com/jif-oai\">@jif-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11619\">#11619</a> fix: fmt <a class=\"user-mention notranslate\" href=\"https://github.com/jif-oai\">@jif-oai</a></li>\n</ul>",
    "image_url": "",
    "published": "2026-02-12T21:39:49Z",
    "collected_at": "2026-02-17T05:35:12.592840+00:00",
    "v2_slot": "agent_tooling_releases",
    "freshness": 0.156,
    "source_reliability": 1.0,
    "v2_prefilter_score": 3.356,
    "type": "release",
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "Bug Fixes Model resolution now preserves the requested model slug when selecting by prefix, so model references stay stable instead of being rewritten. ( #11602 ) Developer messages are now excluded from phase-1 memor...",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.15,
    "v2_source_bias": 0.0,
    "v2_topical_bias": 0.2,
    "v2_final_score": 1.752,
    "summary_1line": "OpenAI Codex 0.101.0 stabilizes model resolution, memory processing, and phase-1 pipeline reliability for more consistent agent behavior.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.448,
    "v2_global_score": 2.2
  }
]