[
  {
    "id": "f70833bd2f581c75",
    "source": "claude_code_releases",
    "source_weight": 2.2,
    "title": "v2.1.41",
    "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.41",
    "summary": "<h2>What's changed</h2>\n<ul>\n<li>Fixed AWS auth refresh hanging indefinitely by adding a 3-minute timeout</li>\n<li>Added <code>claude auth login</code>, <code>claude auth status</code>, and <code>claude auth logout</code> CLI subcommands</li>\n<li>Added Windows ARM64 (win32-arm64) native binary support</li>\n<li>Improved <code>/rename</code> to auto-generate session name from conversation context when called without arguments</li>\n<li>Improved narrow terminal layout for prompt footer</li>\n<li>Fixed file resolution failing for @-mentions with anchor fragments (e.g., <code>@README.md#installation</code>)</li>\n<li>Fixed FileReadTool blocking the process on FIFOs, <code>/dev/stdin</code>, and large files</li>\n<li>Fixed background task notifications not being delivered in streaming Agent SDK mode</li>\n<li>Fixed cursor jumping to end on each keystroke in classifier rule input</li>\n<li>Fixed markdown link display text being dropped for raw URL</li>\n<li>Fixed auto-compact failure error notifications being shown to users</li>\n<li>Fixed permission wait time being included in subagent elapsed time display</li>\n<li>Fixed proactive ticks firing while in plan mode</li>\n<li>Fixed clear stale permission rules when settings change on disk</li>\n<li>Fixed hook blocking errors showing stderr content in UI</li>\n</ul>",
    "published": "2026-02-13T06:08:49Z",
    "collected_at": "2026-02-15T09:41:00.428542+00:00",
    "type": "release",
    "score": 3.917,
    "source_reliability": 1.0,
    "freshness": 0.117,
    "platform_hits": 1,
    "hype_hits": 0,
    "maturity": "research",
    "tags": [
      "agent"
    ],
    "why_it_matters": "Likely impact on agent workflows and platform decisions.",
    "llm_platform_relevant": true,
    "llm_novelty": 3,
    "llm_practicality": 3,
    "llm_hype": 2,
    "llm_why_1line": "",
    "llm_label_source": "heuristic"
  },
  {
    "id": "7bdea70aab3e6e06",
    "source": "openai_codex_releases",
    "source_weight": 2.2,
    "title": "0.101.0",
    "url": "https://github.com/openai/codex/releases/tag/rust-v0.101.0",
    "summary": "<h2>Bug Fixes</h2>\n<ul>\n<li>Model resolution now preserves the requested model slug when selecting by prefix, so model references stay stable instead of being rewritten. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11602\">#11602</a>)</li>\n<li>Developer messages are now excluded from phase-1 memory input, reducing noisy or irrelevant content entering memory. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11608\">#11608</a>)</li>\n<li>Memory phase processing concurrency was reduced to make consolidation/staging more stable under load. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11614\">#11614</a>)</li>\n</ul>\n<h2>Chores</h2>\n<ul>\n<li>Cleaned and simplified the phase-1 memory pipeline code paths. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11605\">#11605</a>)</li>\n<li>Minor repository maintenance: formatting and test-suite hygiene updates in remote model tests. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11619\">#11619</a>)</li>\n</ul>\n<h2>Changelog</h2>\n<p>Full Changelog: <a class=\"commit-link\" href=\"https://github.com/openai/codex/compare/rust-v0.100.0...rust-v0.101.0\"><tt>rust-v0.100.0...rust-v0.101.0</tt></a></p>\n<ul>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11605\">#11605</a> chore: drop and clean from phase 1 <a class=\"user-mention notranslate\" href=\"https://github.com/jif-oai\">@jif-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11602\">#11602</a> fix(core) model_info preserves slug <a class=\"user-mention notranslate\" href=\"https://github.com/dylan-hurd-oai\">@dylan-hurd-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11608\">#11608</a> exclude developer messages from phase-1 memory input <a class=\"user-mention notranslate\" href=\"https://github.com/wendyjiao-openai\">@wendyjiao-openai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11591\">#11591</a> Add cwd to memory files <a class=\"user-mention notranslate\" href=\"https://github.com/wendyjiao-openai\">@wendyjiao-openai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11614\">#11614</a> chore: reduce concurrency of memories <a class=\"user-mention notranslate\" href=\"https://github.com/jif-oai\">@jif-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11619\">#11619</a> fix: fmt <a class=\"user-mention notranslate\" href=\"https://github.com/jif-oai\">@jif-oai</a></li>\n</ul>",
    "published": "2026-02-12T21:39:49Z",
    "collected_at": "2026-02-15T09:41:00.428542+00:00",
    "type": "release",
    "score": 3.882,
    "source_reliability": 1.0,
    "freshness": 0.082,
    "platform_hits": 0,
    "hype_hits": 0,
    "maturity": "production-ready",
    "tags": [],
    "why_it_matters": "Potential relevance to AI platform stack; review for downstream impact.",
    "llm_platform_relevant": true,
    "llm_novelty": 3,
    "llm_practicality": 3,
    "llm_hype": 2,
    "llm_why_1line": "",
    "llm_label_source": "heuristic"
  },
  {
    "id": "c16b69a1be247646",
    "source": "openai_blog",
    "source_weight": 2.0,
    "title": "GPT-5.2 derives a new result in theoretical physics",
    "url": "https://openai.com/index/new-result-theoretical-physics",
    "summary": "A new preprint shows GPT-5.2 proposing a new formula for a gluon amplitude, later formally proved and verified by OpenAI and academic collaborators.",
    "published": "Fri, 13 Feb 2026 11:00:00 GMT",
    "collected_at": "2026-02-15T09:41:00.428542+00:00",
    "type": "news",
    "score": 3.743,
    "source_reliability": 1.0,
    "freshness": 0.143,
    "platform_hits": 0,
    "hype_hits": 0,
    "maturity": "research",
    "tags": [],
    "why_it_matters": "Potential relevance to AI platform stack; review for downstream impact.",
    "llm_platform_relevant": true,
    "llm_novelty": 3,
    "llm_practicality": 3,
    "llm_hype": 2,
    "llm_why_1line": "",
    "llm_label_source": "heuristic"
  },
  {
    "id": "39332e39a86a893d",
    "source": "hackernews_ai",
    "source_weight": 1.1,
    "title": "Show HN: I built a leaderboard ranking AI products by Stripe payment traffic",
    "url": "https://aiboom.tools/ranking",
    "summary": "<p>Article URL: <a href=\"https://aiboom.tools/ranking\">https://aiboom.tools/ranking</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47022389\">https://news.ycombinator.com/item?id=47022389</a></p>\n<p>Points: 1</p>\n<p># Comments: 1</p>",
    "published": "Sun, 15 Feb 2026 09:37:00 +0000",
    "collected_at": "2026-02-15T09:41:00.428542+00:00",
    "type": "news",
    "score": 3.697,
    "source_reliability": 1.0,
    "freshness": 0.997,
    "platform_hits": 0,
    "hype_hits": 0,
    "maturity": "research",
    "tags": [],
    "why_it_matters": "Potential relevance to AI platform stack; review for downstream impact.",
    "llm_platform_relevant": true,
    "llm_novelty": 3,
    "llm_practicality": 3,
    "llm_hype": 2,
    "llm_why_1line": "",
    "llm_label_source": "heuristic"
  },
  {
    "id": "dd9ffded5689f601",
    "source": "simon_willison",
    "source_weight": 1.25,
    "title": "How Generative and Agentic AI Shift Concern from Technical Debt to Cognitive Debt",
    "url": "https://simonwillison.net/2026/Feb/15/cognitive-debt/#atom-everything",
    "summary": "<p><strong><a href=\"https://margaretstorey.com/blog/2026/02/09/cognitive-debt/\">How Generative and Agentic AI Shift Concern from Technical Debt to Cognitive Debt</a></strong></p>\nThis piece by Margaret-Anne Storey is the best explanation of the term <strong>cognitive debt</strong> I've seen so far.</p>\n<blockquote>\n<p><em>Cognitive debt</em>, a term gaining <a href=\"https://www.media.mit.edu/publications/your-brain-on-chatgpt/\">traction</a> recently, instead communicates the notion that the debt compounded from going fast lives in the brains of the developers and affects their lived experiences and abilities to “go fast” or to make changes. Even if AI agents produce code that could be easy to understand, the humans involved may have simply lost the plot and may not understand what the program is supposed to do, how their intentions were implemented, or how to possibly change it.</p>\n</blockquote>\n<p>Margaret-Anne expands on this further with an anecdote about a student team she coached:</p>\n<blockquote>\n<p>But by weeks 7 or 8, one team hit a wall. They could no longer make even simple changes without breaking something unexpected. When I met with them, the team initially blamed technical debt: messy code, poor architecture, hurried implementations. But as we dug deeper, the real problem emerged: no one on the team could explain why certain design decisions had been made or how different parts of the system were supposed to work together. The code might have been messy, but the bigger issue was that the theory of the system, their shared understanding, had fragmented or disappeared entirely. They had accumulated cognitive debt faster than technical debt, and it paralyzed them.</p>\n</blockquote>\n<p>I've experienced this myself on some of my more ambitious vibe-code-adjacent projects. I've been experimenting with prompting entire new features into existence without reviewing their implementations and, while it works surprisingly well, I've found myself getting lost in my own projects.</p>\n<p>I no longer have a firm mental model of what they can do and how they work, which means each additional feature becomes harder to reason about, eventually leading me to lose the ability to make confident decisions about where to go next.\n\n    <p><small></small>Via <a href=\"https://martinfowler.com/fragments/2026-02-13.html\">Martin Fowler</a></small></p>\n\n\n    <p>Tags: <a href=\"https://simonwillison.net/tags/definitions\">definitions</a>, <a href=\"https://simonwillison.net/tags/ai\">ai</a>, <a href=\"https://simonwillison.net/tags/generative-ai\">generative-ai</a>, <a href=\"https://simonwillison.net/tags/llms\">llms</a>, <a href=\"https://simonwillison.net/tags/ai-assisted-programming\">ai-assisted-programming</a>, <a href=\"https://simonwillison.net/tags/vibe-coding\">vibe-coding</a></p>",
    "published": "2026-02-15T05:20:11+00:00",
    "collected_at": "2026-02-15T09:41:00.428542+00:00",
    "type": "news",
    "score": 3.684,
    "source_reliability": 1.0,
    "freshness": 0.834,
    "platform_hits": 0,
    "hype_hits": 0,
    "maturity": "production-ready",
    "tags": [],
    "why_it_matters": "Potential relevance to AI platform stack; review for downstream impact.",
    "llm_platform_relevant": true,
    "llm_novelty": 3,
    "llm_practicality": 3,
    "llm_hype": 2,
    "llm_why_1line": "",
    "llm_label_source": "heuristic"
  },
  {
    "id": "9f6a0346a31359dc",
    "source": "anthropic_engineering",
    "source_weight": 2.0,
    "title": "Building C Compiler",
    "url": "https://www.anthropic.com/engineering/building-c-compiler",
    "summary": "",
    "published": "2026-02-05T19:38:29.000Z",
    "collected_at": "2026-02-15T09:41:00.428542+00:00",
    "type": "news",
    "score": 3.6,
    "source_reliability": 1.0,
    "freshness": 0.0,
    "platform_hits": 0,
    "hype_hits": 0,
    "maturity": "research",
    "tags": [],
    "why_it_matters": "Potential relevance to AI platform stack; review for downstream impact.",
    "llm_platform_relevant": true,
    "llm_novelty": 3,
    "llm_practicality": 3,
    "llm_hype": 2,
    "llm_why_1line": "",
    "llm_label_source": "heuristic"
  },
  {
    "id": "f09c45ee226de24a",
    "source": "anthropic_newsroom",
    "source_weight": 1.8,
    "title": "Chris Liddell Appointed Anthropic Board",
    "url": "https://www.anthropic.com/news/chris-liddell-appointed-anthropic-board",
    "summary": "",
    "published": "2026-02-13T16:21:14.000Z",
    "collected_at": "2026-02-15T09:41:00.428542+00:00",
    "type": "news",
    "score": 3.579,
    "source_reliability": 1.0,
    "freshness": 0.179,
    "platform_hits": 0,
    "hype_hits": 0,
    "maturity": "research",
    "tags": [],
    "why_it_matters": "Potential relevance to AI platform stack; review for downstream impact.",
    "llm_platform_relevant": true,
    "llm_novelty": 3,
    "llm_practicality": 3,
    "llm_hype": 2,
    "llm_why_1line": "",
    "llm_label_source": "heuristic"
  },
  {
    "id": "731b24bba0459a2f",
    "source": "infoq_ai_ml",
    "source_weight": 1.15,
    "title": "Sixteen Claude Agents Built a C Compiler Without Human Intervention... Almost",
    "url": "https://www.infoq.com/news/2026/02/claude-built-c-compiler/?utm_campaign=infoq_content&utm_source=infoq&utm_medium=feed&utm_term=AI%2C+ML+%26+Data+Engineering",
    "summary": "<img src=\"https://res.infoq.com/news/2026/02/claude-built-c-compiler/en/headerimage/claude-built-c-compiler-1771067001094.jpeg\" /><p>In an effort to probe the limits of autonomous software development Anthropic used sixteen Claude Opus 4.6 AI agents to build a Rust-based C compiler from scratch. Working in parallel on a shared repository, the agents coordinated their changes and ultimately produced a compiler capable of building the Linux 6.9 kernel across x86, ARM, and RISC-V, as well as many other open-source projects.</p> <i>By Sergio De Simone</i>",
    "published": "Sat, 14 Feb 2026 12:00:00 GMT",
    "collected_at": "2026-02-15T09:41:00.428542+00:00",
    "type": "news",
    "score": 3.155,
    "source_reliability": 1.0,
    "freshness": 0.405,
    "platform_hits": 0,
    "hype_hits": 0,
    "maturity": "research",
    "tags": [],
    "why_it_matters": "Potential relevance to AI platform stack; review for downstream impact.",
    "llm_platform_relevant": true,
    "llm_novelty": 3,
    "llm_practicality": 3,
    "llm_hype": 2,
    "llm_why_1line": "",
    "llm_label_source": "heuristic"
  },
  {
    "id": "d7c065e7fd03c9f2",
    "source": "latent_space",
    "source_weight": 1.2,
    "title": "[AINews] Why OpenAI Should Build Slack",
    "url": "https://www.latent.space/p/ainews-why-openai-should-build-slack",
    "summary": "a quiet day lets us answer a Sam Altman question: what should he build next?",
    "published": "Sat, 14 Feb 2026 07:48:54 GMT",
    "collected_at": "2026-02-15T09:41:00.428542+00:00",
    "type": "news",
    "score": 3.14,
    "source_reliability": 1.0,
    "freshness": 0.34,
    "platform_hits": 0,
    "hype_hits": 0,
    "maturity": "research",
    "tags": [],
    "why_it_matters": "Potential relevance to AI platform stack; review for downstream impact.",
    "llm_platform_relevant": true,
    "llm_novelty": 3,
    "llm_practicality": 3,
    "llm_hype": 2,
    "llm_why_1line": "",
    "llm_label_source": "heuristic"
  },
  {
    "id": "bc475ac3fcd28ab6",
    "source": "anthropic_research",
    "source_weight": 1.4,
    "title": "Ai Assistance Coding Skills",
    "url": "https://www.anthropic.com/research/AI-assistance-coding-skills",
    "summary": "",
    "published": "2026-02-05T00:34:35.000Z",
    "collected_at": "2026-02-15T09:41:00.428542+00:00",
    "type": "news",
    "score": 3.0,
    "source_reliability": 1.0,
    "freshness": 0.0,
    "platform_hits": 0,
    "hype_hits": 0,
    "maturity": "research",
    "tags": [],
    "why_it_matters": "Potential relevance to AI platform stack; review for downstream impact.",
    "llm_platform_relevant": true,
    "llm_novelty": 3,
    "llm_practicality": 3,
    "llm_hype": 2,
    "llm_why_1line": "",
    "llm_label_source": "heuristic"
  },
  {
    "id": "5eb1dc4c2b27f35b",
    "source": "arxiv_cs_ai",
    "source_weight": 0.85,
    "title": "Scaling Verification Can Be More Effective than Scaling Policy Learning for Vision-Language-Action Alignment",
    "url": "http://arxiv.org/abs/2602.12281v1",
    "summary": "The long-standing vision of general-purpose robots hinges on their ability to understand and act upon natural language instructions. Vision-Language-Action (VLA) models have made remarkable progress toward this goal, yet their generated actions can still misalign with the given instructions. In this paper, we investigate test-time verification as a means to shrink the \"intention-action gap.'' We first characterize the test-time scaling law for embodied instruction following and demonstrate that jointly scaling the number of rephrased instructions and generated actions greatly increases test-time sample diversity, often recovering correct actions more efficiently than scaling each dimension independently. To capitalize on these scaling laws, we present CoVer, a contrastive verifier for vision-language-action alignment, and show that our architecture scales gracefully with additional computational resources and data. We then introduce \"boot-time compute\" and a hierarchical verification inference pipeline for VLAs. At deployment, our framework precomputes a diverse set of rephrased instructions from a Vision-Language-Model (VLM), repeatedly generates action candidates for each instruction, and then uses a verifier to select the optimal high-level prompt and low-level action chunks. Compared to scaling policy pre-training on the same data, our verification approach yields 22% gains in-distribution and 13% out-of-distribution on the SIMPLER benchmark, with a further 45% improvement in real-world experiments. On the PolaRiS benchmark, CoVer achieves 14% gains in task progress and 9% in success rate.",
    "published": "2026-02-12T18:59:59Z",
    "collected_at": "2026-02-15T09:41:00.428542+00:00",
    "type": "paper",
    "score": 2.523,
    "source_reliability": 1.0,
    "freshness": 0.073,
    "platform_hits": 2,
    "hype_hits": 0,
    "maturity": "production-ready",
    "tags": [
      "inference",
      "benchmark"
    ],
    "why_it_matters": "Likely impact on inference, benchmark workflows and platform decisions.",
    "llm_platform_relevant": true,
    "llm_novelty": 3,
    "llm_practicality": 3,
    "llm_hype": 2,
    "llm_why_1line": "",
    "llm_label_source": "heuristic"
  },
  {
    "id": "c5ef81aef2a2ccc1",
    "source": "openai_blog",
    "source_weight": 2.0,
    "title": "Introducing Lockdown Mode and Elevated Risk labels in ChatGPT",
    "url": "https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt",
    "summary": "Introducing Lockdown Mode and Elevated Risk labels in ChatGPT to help organizations defend against prompt injection and AI-driven data exfiltration.",
    "published": "Fri, 13 Feb 2026 10:00:00 GMT",
    "collected_at": "2026-02-15T09:41:00.428542+00:00",
    "type": "news",
    "score": 3.737,
    "source_reliability": 1.0,
    "freshness": 0.137,
    "platform_hits": 0,
    "hype_hits": 0,
    "maturity": "production-ready",
    "tags": [],
    "why_it_matters": "Potential relevance to AI platform stack; review for downstream impact.",
    "llm_platform_relevant": true,
    "llm_novelty": 3,
    "llm_practicality": 3,
    "llm_hype": 2,
    "llm_why_1line": "",
    "llm_label_source": "heuristic"
  }
]