[
  {
    "id": "0196003b904bb5eb",
    "source": "claude_code_releases",
    "source_weight": 2.2,
    "title": "v2.1.50",
    "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.50",
    "summary": "<h2>What's changed</h2>\n<ul>\n<li>Added support for <code>startupTimeout</code> configuration for LSP servers</li>\n<li>Added <code>WorktreeCreate</code> and <code>WorktreeRemove</code> hook events, enabling custom VCS setup and teardown when agent worktree isolation creates or removes worktrees.</li>\n<li>Fixed a bug where resumed sessions could be invisible when the working directory involved symlinks, because the session storage path was resolved at different times during startup. Also fixed session data loss on SSH disconnect by flushing session data before hooks and analytics in the graceful shutdown sequence.</li>\n<li>Linux: Fixed native modules not loading on systems with glibc older than 2.30 (e.g., RHEL 8)</li>\n<li>Fixed memory leak in agent teams where completed teammate tasks were never garbage collected from session state</li>\n<li>Fixed <code>CLAUDE_CODE_SIMPLE</code> to fully strip down skills, session memory, custom agents, and CLAUDE.md token counting</li>\n<li>Fixed <code>/mcp reconnect</code> freezing the CLI when given a server name that doesn't exist</li>\n<li>Fixed memory leak where completed task state objects were never removed from AppState</li>\n<li>Added support for <code>isolation: worktree</code> in agent definitions, allowing agents to declaratively run in isolated git worktrees.</li>\n<li><code>CLAUDE_CODE_SIMPLE</code> mode now also disables MCP tools, attachments, hooks, and CLAUDE.md file loading for a fully minimal experience.</li>\n<li>Fixed bug where MCP tools were not discovered when tool search is enabled and a prompt is passed in as a launch argument</li>\n<li>Improved memory usage during long sessions by clearing internal caches after compaction</li>\n<li>Added <code>claude agents</code> CLI command to list all configured agents</li>\n<li>Improved memory usage during long sessions by clearing large tool results after they have been processed</li>\n<li>Fixed a memory leak where LSP diagnostic data was never cleaned up after delivery, causing unbounded memory growth in long sessions</li>\n<li>Fixed a memory leak where completed task output was not freed from memory, reducing memory usage in long sessions with many tasks</li>\n<li>Improved startup performance for headless mode (<code>-p</code> flag) by deferring Yoga WASM and UI component imports</li>\n<li>Fixed prompt suggestion cache regression that reduced cache hit rates</li>\n<li>Fixed unbounded memory growth in long sessions by capping file history snapshots</li>\n<li>Added <code>CLAUDE_CODE_DISABLE_1M_CONTEXT</code> environment variable to disable 1M context window support</li>\n<li>Opus 4.6 (fast mode) now includes the full 1M context window</li>\n<li>VSCode: Added <code>/extra-usage</code> command support in VS Code sessions</li>\n<li>Fixed memory leak where TaskOutput retained recent lines after cleanup</li>\n<li>Fixed memory leak in CircularBuffer where cleared items were retained in the backing array</li>\n<li>Fixed memory leak in shell command execution where ChildProcess and AbortController references were retained after cleanup</li>\n</ul>",
    "image_url": "",
    "published": "2026-02-20T23:48:57Z",
    "collected_at": "2026-02-22T03:00:05.357291+00:00",
    "ingest_batch_id": "20260222-030005",
    "tier": "tier1",
    "type": "release",
    "source_reliability": 0.946,
    "freshness": 0.615,
    "tier1_quick_score": 3.831,
    "v2_slot": "agent_tooling_releases",
    "v2_prefilter_score": 3.761,
    "llm_label_source": "llm",
    "llm_category": "release",
    "llm_summary_1line": "Claude Code v2.1.50 ships worktree isolation for agent sandbox safety, 15+ memory leak fixes for long-running sessions, and LSP startup timeout config for production reliability.",
    "llm_why_1line": "Direct agent harness improvements: isolation primitives, session stability fixes, memory management for continuous delivery automation.",
    "v2_llm_score": 4.8,
    "v2_source_bias": 0.0,
    "v2_topical_bias": 0.2,
    "v2_final_score": 3.744,
    "summary_1line": "Claude Code v2.1.50 ships worktree isolation for agent teams, fixes 15+ memory leaks, and adds startup timeout config for LSP serversâ€”critical stability for long-running autonomous workflows.",
    "why_it_matters": "Direct agent harness improvements: isolation primitives, session stability fixes, memory management for continuous delivery automation.",
    "v2_slot_priority": 0.459,
    "v2_global_score": 4.203
  },
  {
    "id": "1cfde64b68e53a7e",
    "source": "infoq_ai_ml",
    "source_weight": 1.15,
    "title": "OpenAI Introduces Harness Engineering: Codex Agents Power Largeâ€‘Scale Software Development",
    "url": "https://www.infoq.com/news/2026/02/openai-harness-engineering-codex/?utm_campaign=infoq_content&utm_source=infoq&utm_medium=feed&utm_term=AI%2C+ML+%26+Data+Engineering",
    "summary": "<img src=\"https://res.infoq.com/news/2026/02/openai-harness-engineering-codex/en/headerimage/generatedHeaderImage-1771569933195.jpg\" /><p>OpenAI introduces Harness Engineering, an AI-driven methodology where Codex agents generate, test, and deploy a million-line production system. The platform integrates observability, architectural constraints, and structured documentation to automate key software development workflows.</p> <i>By Leela Kumili</i>",
    "image_url": "https://res.infoq.com/news/2026/02/openai-harness-engineering-codex/en/headerimage/generatedHeaderImage-1771569933195.jpg",
    "published": "Sat, 21 Feb 2026 15:14:00 GMT",
    "collected_at": "2026-02-22T03:00:05.357291+00:00",
    "ingest_batch_id": "20260222-030005",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.946,
    "freshness": 0.745,
    "tier1_quick_score": 2.945,
    "v2_slot": "practitioner_analysis",
    "v2_prefilter_score": 2.841,
    "llm_label_source": "llm",
    "llm_category": "research",
    "llm_summary_1line": "OpenAI's Harness Engineering uses Codex agents to generate, test, and deploy million-line production systems with integrated observability and architectural constraints.",
    "llm_why_1line": "Core agentic coding + delivery automation; lacks concrete patterns, benchmarks, and reproducible methodology details needed for immediate implementation.",
    "v2_llm_score": 3.85,
    "v2_source_bias": 0.08,
    "v2_topical_bias": 0.2,
    "v2_final_score": 3.664,
    "summary_1line": "OpenAI's Harness Engineering uses Codex agents to generate, test, and deploy million-line production systems with integrated observability and architectural constraints.",
    "why_it_matters": "Core agentic coding + delivery automation; lacks concrete patterns, benchmarks, and reproducible methodology details needed for immediate implementation.",
    "v2_slot_priority": 0.527,
    "v2_global_score": 4.191
  },
  {
    "id": "6ed48b697f4e1625",
    "source": "anthropic_newsroom",
    "source_weight": 1.8,
    "title": "Claude Sonnet 4 6",
    "url": "https://www.anthropic.com/news/claude-sonnet-4-6",
    "summary": "",
    "image_url": "",
    "published": "2026-02-17T18:00:00+00:00",
    "collected_at": "2026-02-22T03:00:05.357291+00:00",
    "ingest_batch_id": "20260222-030005",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.946,
    "freshness": 0.269,
    "tier1_quick_score": 2.979,
    "v2_slot": "frontier_official",
    "v2_prefilter_score": 3.015,
    "llm_label_source": "llm",
    "llm_category": "release",
    "llm_summary_1line": "Claude Sonnet 4.6 update from Anthropic; check release notes for coding capability improvements and inference changes.",
    "llm_why_1line": "Model release relevant to agent platform, but newsroom source lacks technical depth; need detailed benchmarks and capability breakdowns.",
    "v2_llm_score": 3.05,
    "v2_source_bias": 0.06,
    "v2_topical_bias": 0.0,
    "v2_final_score": 2.554,
    "summary_1line": "Claude Sonnet 4.6 announced; model details and performance benchmarks not yet available in public newsroom.",
    "why_it_matters": "Model release relevant to agent platform, but newsroom source lacks technical depth; need detailed benchmarks and capability breakdowns.",
    "v2_slot_priority": 0.659,
    "v2_global_score": 3.213
  },
  {
    "id": "92f88ae028e36d3e",
    "source": "hackernews_ai",
    "source_weight": 1.1,
    "title": "Show HN: Agentic Gatekeeper â€“ AI pre-commit hook to auto-patch logic errors",
    "url": "https://github.com/revanthpobala/agentic-gatekeeper",
    "summary": "<p>Hey HN,<p>I built Agentic Gatekeeper, a headless pre-commit hook baked into the VS Code Source Control panel that autonomously patches code before you commit it.<p>The Problem: Whether I'm writing code manually or letting LLMs (Cursor/Copilot) generate it, keeping logic strictly in pace with local project rules (like CONTRIBUTING.md or custom architecture guidelines) is tedious. Standard linters catch syntax, but they don't catch business logic or state \"You must use the Fetch wrapper for API calls in this folder\".<p>How it works:\nWhen you stage files and trigger the hook, the extension spins up a parallel execution engine using the latest frontier models (Claude 4.6, DeepSeek V4, or local Ollama). It parses your workspace for local routing rules (e.g., .gatekeeper/*.md), evaluates the raw Git diffs, and utilizes the native VS Code WorkspaceEdit API to instantly auto-patch the logic errors directly in your editor.<p>It basically turns plain-English markdown into strict compiler rules that the IDE enforces before a bad commit is made.<p>The biggest challenge was handling multi-file concurrency and preventing race conditions when evaluating massive diffs, so I implemented a batched validation loop with explicit rollback safety checks. It natively supports OpenRouter so you can hot-swap models.<p>It's completely open-source. I'd love for you to try breaking it on a messy branch or poke around the multi-provider abstraction layer in the repo.<p>VS Code Marketplace: <a href=\"https://marketplace.visualstudio.com/items?itemName=revanthpobala.agentic-gatekeeper\" rel=\"nofollow\">https://marketplace.visualstudio.com/items?itemName=revanthp...</a>\nGitHub: <a href=\"https://github.com/revanthpobala/agentic-gatekeeper\" rel=\"nofollow\">https://github.com/revanthpobala/agentic-gatekeeper</a><p>Would love your technical feedback on the prompt orchestration or the VS Code API integration!</p>\n<hr />\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47106754\">https://news.ycombinator.com/item?id=47106754</a></p>\n<p>Points: 2</p>\n<p># Comments: 0</p>",
    "image_url": "",
    "published": "Sun, 22 Feb 2026 00:37:48 +0000",
    "collected_at": "2026-02-22T03:00:05.357291+00:00",
    "ingest_batch_id": "20260222-030005",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.946,
    "freshness": 0.861,
    "tier1_quick_score": 3.013,
    "v2_slot": "community_signal",
    "v2_prefilter_score": 2.907,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "Hey HN, I built Agentic Gatekeeper, a headless pre-commit hook baked into the VS Code Source Control panel that autonomously patches code before you commit it. The Problem: Whether I'm writing code manually or letting...",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 3.0,
    "v2_source_bias": 0.0,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.665,
    "summary_1line": "VS Code pre-commit hook autonomously patches logic errors using frontier models against custom workspace rules (CONTRIBUTING.md, architecture guidelines).",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.515,
    "v2_global_score": 3.18
  },
  {
    "id": "e5a78c667f50fdfa",
    "source": "simon_willison",
    "source_weight": 1.25,
    "title": "Andrej Karpathy talks about \"Claws\"",
    "url": "https://simonwillison.net/2026/Feb/21/claws/#atom-everything",
    "summary": "<p><strong><a href=\"https://twitter.com/karpathy/status/2024987174077432126\">Andrej Karpathy talks about &quot;Claws&quot;</a></strong></p>\nAndrej Karpathy tweeted a mini-essay about buying a Mac Mini (\"The apple store person told me they are selling like hotcakes and everyone is confused\") to tinker with Claws:</p>\n<blockquote>\n<p>I'm definitely a bit sus'd to run OpenClaw specifically [...] But I do love the concept and I think that just like LLM agents were a new layer on top of LLMs, Claws are now a new layer on top of LLM agents, taking the orchestration, scheduling, context, tool calls and a kind of persistence to a next level.</p>\n<p>Looking around, and given that the high level idea is clear, there are a lot of smaller Claws starting to pop out. For example, on a quick skim NanoClaw looks really interesting in that the core engine is ~4000 lines of code (fits into both my head and that of AI agents, so it feels manageable, auditable, flexible, etc.) and runs everything in containers by default. [...]</p>\n<p>Anyway there are many others - e.g. nanobot, zeroclaw, ironclaw, picoclaw (lol @ prefixes). [...]</p>\n<p>Not 100% sure what my setup ends up looking like just yet but Claws are an awesome, exciting new layer of the AI stack.</p>\n</blockquote>\n<p>Andrej has an ear for fresh terminology (see <a href=\"https://simonwillison.net/2025/Mar/19/vibe-coding/\">vibe coding</a>, <a href=\"https://simonwillison.net/2026/Feb/11/glm-5/\">agentic engineering</a>) and I think he's right about this one, too: \"<strong>Claw</strong>\" is becoming a term of art for the entire category of OpenClaw-like agent systems - AI agents that generally run on personal hardware, communicate via messaging protocols and can both act on direct instructions and schedule tasks.</p>\n<p>It even comes with an established emoji ðŸ¦ž\n\n\n    <p>Tags: <a href=\"https://simonwillison.net/tags/definitions\">definitions</a>, <a href=\"https://simonwillison.net/tags/ai\">ai</a>, <a href=\"https://simonwillison.net/tags/andrej-karpathy\">andrej-karpathy</a>, <a href=\"https://simonwillison.net/tags/generative-ai\">generative-ai</a>, <a href=\"https://simonwillison.net/tags/llms\">llms</a>, <a href=\"https://simonwillison.net/tags/ai-agents\">ai-agents</a>, <a href=\"https://simonwillison.net/tags/openclaw\">openclaw</a></p>",
    "image_url": "",
    "published": "2026-02-21T00:37:45+00:00",
    "collected_at": "2026-02-22T03:00:05.357291+00:00",
    "ingest_batch_id": "20260222-030005",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.946,
    "freshness": 0.517,
    "tier1_quick_score": 2.889,
    "v2_slot": "practitioner_analysis",
    "v2_prefilter_score": 2.713,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "Andrej Karpathy talks about \"Claws\" Andrej Karpathy tweeted a mini-essay about buying a Mac Mini (\"The apple store person told me they are selling like hotcakes and everyone is confused\") to tinker with Claws: I'm def...",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.6,
    "v2_source_bias": 0.08,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.568,
    "summary_1line": "Andrej Karpathy discusses \"Claws\"â€”a new layer for LLM agent orchestration with persistence, scheduling, and tool management; multiple implementations emerging.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.527,
    "v2_global_score": 3.095
  },
  {
    "id": "268636a1f771099c",
    "source": "simon_willison",
    "source_weight": 1.25,
    "title": "Adding TILs, releases, museums, tools and research to my blog",
    "url": "https://simonwillison.net/2026/Feb/20/beats/#atom-everything",
    "summary": "<p>I've been wanting to add indications of my various other online activities to my blog for a while now. I just turned on a new feature I'm calling \"beats\" (after story beats, naming this was hard!) which adds five new types of content to my site, all corresponding to activity elsewhere.</p>\n<p>Here's what beats look like:</p>\n<p><img alt=\"Screenshot of a fragment of a page showing three entries from 30th Dec 2025. First: [RELEASE] &quot;datasette-turnstile 0.1a0 â€” Configurable CAPTCHAs for Datasette paths usinâ€¦&quot; at 7:23 pm. Second: [TOOL] &quot;Software Heritage Repository Retriever â€” Download archived Git repositories fâ€¦&quot; at 11:41 pm. Third: [TIL] &quot;Downloading archived Git repositories from archive.softwareheritage.org â€” â€¦&quot; at 11:43 pm.\" src=\"https://static.simonwillison.net/static/2026/three-beats.jpg\" /></p>\n<p>Those three are from <a href=\"https://simonwillison.net/2025/Dec/30/\">the 30th December 2025</a> archive page.</p>\n<p>Beats are little inline links with badges that fit into different content timeline views around my site, including the homepage, search and archive pages.</p>\n<p>There are currently five types of beats:</p>\n<ul>\n<li>\n<a href=\"https://simonwillison.net/elsewhere/release/\">Releases</a> are GitHub releases of my many different open source projects, imported from <a href=\"https://github.com/simonw/simonw/blob/main/releases_cache.json\">this JSON file</a> that was constructed <a href=\"https://simonwillison.net/2020/Jul/10/self-updating-profile-readme/\">by GitHub Actions</a>.</li>\n<li>\n<a href=\"https://simonwillison.net/elsewhere/til/\">TILs</a> are the posts from my <a href=\"https://til.simonwillison.net/\">TIL blog</a>, imported using <a href=\"https://github.com/simonw/simonwillisonblog/blob/f883b92be23892d082de39dbada571e406f5cfbf/blog/views.py#L1169\">a SQL query over JSON and HTTP</a> against the Datasette instance powering that site.</li>\n<li>\n<a href=\"https://simonwillison.net/elsewhere/museum/\">Museums</a> are new posts on my <a href=\"https://www.niche-museums.com/\">niche-museums.com</a> blog, imported from <a href=\"https://github.com/simonw/museums/blob/909bef71cc8d336bf4ac1f13574db67a6e1b3166/plugins/export.py\">this custom JSON feed</a>.</li>\n<li>\n<a href=\"https://simonwillison.net/elsewhere/tool/\">Tools</a> are HTML and JavaScript tools I've vibe-coded on my <a href=\"https://tools.simonwillison.net/\">tools.simonwillison.net</a> site, as described in <a href=\"https://simonwillison.net/2025/Dec/10/html-tools/\">Useful patterns for building HTML tools</a>.</li>\n<li>\n<a href=\"https://simonwillison.net/elsewhere/research/\">Research</a> is for AI-generated research projects, hosted in my <a href=\"https://github.com/simonw/research\">simonw/research repo</a> and described in <a href=\"https://simonwillison.net/2025/Nov/6/async-code-research/\">Code research projects with async coding agents like Claude Code and Codex</a>.</li>\n</ul>\n<p>That's five different custom integrations to pull in all of that data. The good news is that this kind of integration project is the kind of thing that coding agents <em>really</em> excel at. I knocked most of the feature out in a single morning while working in parallel on various other things.</p>\n<p>I didn't have a useful structured feed of my Research projects, and it didn't matter because I gave Claude Code a link to <a href=\"https://raw.githubusercontent.com/simonw/research/refs/heads/main/README.md\">the raw Markdown README</a> that lists them all and it <a href=\"https://github.com/simonw/simonwillisonblog/blob/f883b92be23892d082de39dbada571e406f5cfbf/blog/importers.py#L77-L80\">spun up a parser regex</a>. Since I'm responsible for both the source and the destination I'm fine with a brittle solution that would be too risky against a source that I don't control myself.</p>\n<p>Claude also handled all of the potentially tedious UI integration work with my site, making sure the new content worked on all of my different page types and was handled correctly by my <a href=\"https://simonwillison.net/2017/Oct/5/django-postgresql-faceted-search/\">faceted search engine</a>.</p>\n<h4 id=\"prototyping-with-claude-artifacts\">Prototyping with Claude Artifacts</h4>\n<p>I actually prototyped the initial concept for beats in regular Claude - not Claude Code - taking advantage of the fact that it can clone public repos from GitHub these days. I started with:</p>\n<blockquote>\n<p><code>Clone simonw/simonwillisonblog and tell me about the models and views</code></p>\n</blockquote>\n<p>And then later in the brainstorming session said:</p>\n<blockquote>\n<p><code>use the templates and CSS in this repo to create a new artifact with all HTML and CSS inline that shows me my homepage with some of those inline content types mixed in</code></p>\n</blockquote>\n<p>After some iteration we got to <a href=\"https://gisthost.github.io/?c3f443cc4451cf8ce03a2715a43581a4/preview.html\">this artifact mockup</a>, which was enough to convince me that the concept had legs and was worth handing over to full <a href=\"https://code.claude.com/docs/en/claude-code-on-the-web\">Claude Code for web</a> to implement.</p>\n<p>If you want to see how the rest of the build played out the most interesting PRs are <a href=\"https://github.com/simonw/simonwillisonblog/pull/592\">Beats #592</a> which implemented the core feature and <a href=\"https://github.com/simonw/simonwillisonblog/pull/595/changes\">Add Museums Beat importer #595</a> which added the Museums content type.</p>\n    \n        <p>Tags: <a href=\"https://simonwillison.net/tags/blogging\">blogging</a>, <a href=\"https://simonwillison.net/tags/museums\">museums</a>, <a href=\"https://simonwillison.net/tags/ai\">ai</a>, <a href=\"https://simonwillison.net/tags/til\">til</a>, <a href=\"https://simonwillison.net/tags/generative-ai\">generative-ai</a>, <a href=\"https://simonwillison.net/tags/llms\">llms</a>, <a href=\"https://simonwillison.net/tags/ai-assisted-programming\">ai-assisted-programming</a>, <a href=\"https://simonwillison.net/tags/claude-artifacts\">claude-artifacts</a>, <a href=\"https://simonwillison.net/tags/claude-code\">claude-code</a></p>",
    "image_url": "https://static.simonwillison.net/static/2026/three-beats.jpg",
    "published": "2026-02-20T23:47:10+00:00",
    "collected_at": "2026-02-22T03:00:05.357291+00:00",
    "ingest_batch_id": "20260222-030005",
    "tier": "tier1",
    "type": "release",
    "source_reliability": 0.946,
    "freshness": 0.506,
    "tier1_quick_score": 2.881,
    "v2_slot": "practitioner_analysis",
    "v2_prefilter_score": 2.702,
    "llm_label_source": "heuristic",
    "llm_category": "release",
    "llm_summary_1line": "I've been wanting to add indications of my various other online activities to my blog for a while now. I just turned on a new feature I'm calling \"beats\" (after story beats, naming this was hard!) which adds five new...",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.6,
    "v2_source_bias": 0.08,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.566,
    "summary_1line": "Simon Willison built multi-source content aggregation into his blog using Claude Code for UI integration and data parsingâ€”concrete example of agentic coding for full-stack feature delivery.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.527,
    "v2_global_score": 3.093
  },
  {
    "id": "5d3d50bae1cacac3",
    "source": "infoq_ai_ml",
    "source_weight": 1.15,
    "title": "OpenAI Launches Frontier, a Platform to Build, Deploy, and Manage AI Agents Across the Enterprise",
    "url": "https://www.infoq.com/news/2026/02/openai-frontier-agent-platform/?utm_campaign=infoq_content&utm_source=infoq&utm_medium=feed&utm_term=AI%2C+ML+%26+Data+Engineering",
    "summary": "<img src=\"https://res.infoq.com/news/2026/02/openai-frontier-agent-platform/en/headerimage/openai-frontier-platform-1771606906402.jpg\" /><p>OpenAI Frontier is an enterprise platform for building, deploying, and managing AI agents, designed to make AI agents reliable, scalable, and integrated into real company systems and workflows.</p> <i>By Sergio De Simone</i>",
    "image_url": "https://res.infoq.com/news/2026/02/openai-frontier-agent-platform/en/headerimage/openai-frontier-platform-1771606906402.jpg",
    "published": "Fri, 20 Feb 2026 18:00:00 GMT",
    "collected_at": "2026-02-22T03:00:05.357291+00:00",
    "ingest_batch_id": "20260222-030005",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.946,
    "freshness": 0.438,
    "tier1_quick_score": 2.728,
    "v2_slot": "practitioner_analysis",
    "v2_prefilter_score": 2.534,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "OpenAI Frontier is an enterprise platform for building, deploying, and managing AI agents, designed to make AI agents reliable, scalable, and integrated into real company systems and workflows. By Sergio De Simone",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.2,
    "v2_source_bias": 0.08,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.216,
    "summary_1line": "OpenAI launches Frontier, an enterprise agent platform for building, deploying, and managing AI agents at scale.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.527,
    "v2_global_score": 2.743
  },
  {
    "id": "e090493a0ff267ce",
    "source": "openai_blog",
    "source_weight": 2.0,
    "title": "Introducing GPT-5.3-Codex-Spark",
    "url": "https://openai.com/index/introducing-gpt-5-3-codex-spark",
    "summary": "Introducing GPT-5.3-Codex-Sparkâ€”our first real-time coding model. 15x faster generation, 128k context, now in research preview for ChatGPT Pro users.",
    "image_url": "",
    "published": "Thu, 12 Feb 2026 10:00:00 GMT",
    "collected_at": "2026-02-22T03:00:05.357291+00:00",
    "ingest_batch_id": "20260222-030005",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.946,
    "freshness": 0.054,
    "tier1_quick_score": 2.985,
    "v2_slot": "frontier_official",
    "v2_prefilter_score": 3.0,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "Introducing GPT-5.3-Codex-Sparkâ€”our first real-time coding model. 15x faster generation, 128k context, now in research preview for ChatGPT Pro users.",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.2,
    "v2_source_bias": 0.1,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.071,
    "summary_1line": "OpenAI launches GPT-5.3-Codex-Spark with 15x faster code generation and 128k context in research preview.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.659,
    "v2_global_score": 2.73
  },
  {
    "id": "0f43cce4717b58ca",
    "source": "anthropic_research",
    "source_weight": 1.4,
    "title": "Measuring Agent Autonomy",
    "url": "https://www.anthropic.com/research/measuring-agent-autonomy",
    "summary": "",
    "image_url": "",
    "published": "2026-02-18T15:10:00+00:00",
    "collected_at": "2026-02-22T03:00:05.357291+00:00",
    "ingest_batch_id": "20260222-030005",
    "tier": "tier1",
    "type": "research",
    "source_reliability": 0.946,
    "freshness": 0.473,
    "tier1_quick_score": 2.658,
    "v2_slot": "research_watch",
    "v2_prefilter_score": 2.819,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "Measuring Agent Autonomy",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.0,
    "v2_source_bias": 0.4,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.371,
    "summary_1line": "Anthropic research on quantifying agent autonomy levelsâ€”framework for evaluating how independently agents can operate without human intervention.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.274,
    "v2_global_score": 2.645
  },
  {
    "id": "9d95a891a81b27c3",
    "source": "openai_blog",
    "source_weight": 2.0,
    "title": "Beyond rate limits: scaling access to Codex and Sora",
    "url": "https://openai.com/index/beyond-rate-limits",
    "summary": "How OpenAI built a real-time access system combining rate limits, usage tracking, and credits to power continuous access to Sora and Codex.",
    "image_url": "",
    "published": "Fri, 13 Feb 2026 09:00:00 GMT",
    "collected_at": "2026-02-22T03:00:05.357291+00:00",
    "ingest_batch_id": "20260222-030005",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.946,
    "freshness": 0.072,
    "tier1_quick_score": 3.0,
    "v2_slot": "frontier_official",
    "v2_prefilter_score": 3.018,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "How OpenAI built a real-time access system combining rate limits, usage tracking, and credits to power continuous access to Sora and Codex.",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.0,
    "v2_source_bias": 0.1,
    "v2_topical_bias": 0.2,
    "v2_final_score": 1.914,
    "summary_1line": "OpenAI describes rate-limiting and credit-based access architecture for Codex and Sora APIs, addressing scale and fairness.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.659,
    "v2_global_score": 2.573
  },
  {
    "id": "a9556207c2ad7fc6",
    "source": "arxiv_cs_ai",
    "source_weight": 0.85,
    "title": "KLong: Training LLM Agent for Extremely Long-horizon Tasks",
    "url": "http://arxiv.org/abs/2602.17547v1",
    "summary": "This paper introduces KLong, an open-source LLM agent trained to solve extremely long-horizon tasks. The principle is to first cold-start the model via trajectory-splitting SFT, then scale it via progressive RL training. Specifically, we first activate basic agentic abilities of a base model with a comprehensive SFT recipe. Then, we introduce Research-Factory, an automated pipeline that generates high-quality training data by collecting research papers and constructing evaluation rubrics. Using this pipeline, we build thousands of long-horizon trajectories distilled from Claude 4.5 Sonnet (Thinking). To train with these extremely long trajectories, we propose a new trajectory-splitting SFT, which preserves early context, progressively truncates later context, and maintains overlap between sub-trajectories. In addition, to further improve long-horizon task-solving capability, we propose a novel progressive RL, which schedules training into multiple stages with progressively extended timeouts. Experiments demonstrate the superiority and generalization of KLong, as shown in Figure 1. Notably, our proposed KLong (106B) surpasses Kimi K2 Thinking (1T) by 11.28% on PaperBench, and the performance improvement generalizes to other coding benchmarks like SWE-bench Verified and MLE-bench.",
    "image_url": "",
    "published": "2026-02-19T17:01:08Z",
    "collected_at": "2026-02-22T03:00:05.357291+00:00",
    "ingest_batch_id": "20260222-030005",
    "tier": "tier1",
    "type": "paper",
    "source_reliability": 0.946,
    "freshness": 0.596,
    "tier1_quick_score": 2.243,
    "v2_slot": "research_watch",
    "v2_prefilter_score": 2.392,
    "llm_label_source": "heuristic",
    "llm_category": "research",
    "llm_summary_1line": "This paper introduces KLong, an open-source LLM agent trained to solve extremely long-horizon tasks. The principle is to first cold-start the model via trajectory-splitting SFT, then scale it via progressive RL traini...",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.85,
    "v2_source_bias": -0.35,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.362,
    "summary_1line": "KLong: 106B LLM agent trained via trajectory-splitting SFT + progressive RL for long-horizon tasks, outperforms 1T model on PaperBench and coding evals.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.274,
    "v2_global_score": 2.636
  },
  {
    "id": "e976c2f9eeb192f3",
    "source": "latent_space",
    "source_weight": 1.2,
    "title": "[AINews] The Custom ASIC Thesis",
    "url": "https://www.latent.space/p/ainews-the-custom-asic-thesis",
    "summary": "Taalas HC1 runs 16,960 tok/s/user Llama 3.1 8B with custom silicon. Actually fast LLMs are on their way...",
    "image_url": "https://substackcdn.com/image/fetch/$s_!AQKx!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F135eb2d4-a2b3-41db-8d80-3456a144fb84_3092x1430.png",
    "published": "Sat, 21 Feb 2026 02:45:01 GMT",
    "collected_at": "2026-02-22T03:00:05.357291+00:00",
    "ingest_batch_id": "20260222-030005",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.946,
    "freshness": 0.545,
    "tier1_quick_score": 2.86,
    "v2_slot": "practitioner_analysis",
    "v2_prefilter_score": 2.691,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "Taalas HC1 runs 16,960 tok/s/user Llama 3.1 8B with custom silicon. Actually fast LLMs are on their way...",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.2,
    "v2_source_bias": 0.0,
    "v2_topical_bias": 0.0,
    "v2_final_score": 1.952,
    "summary_1line": "Taalas HC1 custom silicon achieves 16,960 tok/s per user on Llama 3.1 8B; inference speed implications for agentic workflows remain unclear.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.527,
    "v2_global_score": 2.479
  },
  {
    "id": "a5b5dd6bb7ab7973",
    "source": "arxiv_cs_lg",
    "source_weight": 0.85,
    "title": "Revisiting Weight Regularization for Low-Rank Continual Learning",
    "url": "http://arxiv.org/abs/2602.17559v1",
    "summary": "Continual Learning (CL) with large-scale pre-trained models (PTMs) has recently gained wide attention, shifting the focus from training from scratch to continually adapting PTMs. This has given rise to a promising paradigm: parameter-efficient continual learning (PECL), where task interference is typically mitigated by assigning a task-specific module during training, such as low-rank adapters. However, weight regularization techniques, such as Elastic Weight Consolidation (EWC)-a key strategy in CL-remain underexplored in this new paradigm. In this paper, we revisit weight regularization in low-rank CL as a new perspective for mitigating task interference in PECL. Unlike existing low-rank CL methods, we mitigate task interference by regularizing a shared low-rank update through EWC, thereby keeping the storage requirement and inference costs constant regardless of the number of tasks. Our proposed method EWC-LoRA leverages a low-rank representation to estimate parameter importance over the full-dimensional space. This design offers a practical, computational- and memory-efficient solution for CL with PTMs, and provides insights that may inform the broader application of regularization techniques within PECL. Extensive experiments on various benchmarks demonstrate the effectiveness of EWC-LoRA, achieving a stability-plasticity trade-off superior to existing low-rank CL approaches. These results indicate that, even under low-rank parameterizations, weight regularization remains an effective mechanism for mitigating task interference. Code is available at: https://github.com/yaoyz96/low-rank-cl.",
    "image_url": "",
    "published": "2026-02-19T17:13:00Z",
    "collected_at": "2026-02-22T03:00:05.357291+00:00",
    "ingest_batch_id": "20260222-030005",
    "tier": "tier1",
    "type": "paper",
    "source_reliability": 0.946,
    "freshness": 0.597,
    "tier1_quick_score": 2.244,
    "v2_slot": "research_watch",
    "v2_prefilter_score": 2.393,
    "llm_label_source": "heuristic",
    "llm_category": "research",
    "llm_summary_1line": "Continual Learning (CL) with large-scale pre-trained models (PTMs) has recently gained wide attention, shifting the focus from training from scratch to continually adapting PTMs. This has given rise to a promising par...",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.75,
    "v2_source_bias": -0.35,
    "v2_topical_bias": 0.0,
    "v2_final_score": 2.077,
    "summary_1line": "EWC-LoRA combines elastic weight consolidation with low-rank adapters for continual learning on pre-trained models, reducing task interference while maintaining constant storage and inference costs.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.274,
    "v2_global_score": 2.351
  },
  {
    "id": "e2fb706f0e744611",
    "source": "anthropic_newsroom",
    "source_weight": 1.8,
    "title": "Donate Public First Action",
    "url": "https://www.anthropic.com/news/donate-public-first-action",
    "summary": "",
    "image_url": "",
    "published": "2026-02-12T11:45:00+00:00",
    "collected_at": "2026-02-22T03:00:05.357291+00:00",
    "ingest_batch_id": "20260222-030005",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.946,
    "freshness": 0.056,
    "tier1_quick_score": 2.786,
    "v2_slot": "frontier_official",
    "v2_prefilter_score": 2.802,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "Donate Public First Action",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.0,
    "v2_source_bias": 0.06,
    "v2_topical_bias": 0.0,
    "v2_final_score": 1.671,
    "summary_1line": "Anthropic announces corporate donation to Public First Action, a nonprofit focused on AI policy advocacy.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.659,
    "v2_global_score": 2.33
  },
  {
    "id": "b7dd9d05bcdf917e",
    "source": "claude_agent_sdk_python_releases",
    "source_weight": 1.3,
    "title": "v0.1.38",
    "url": "https://github.com/anthropics/claude-agent-sdk-python/releases/tag/v0.1.38",
    "summary": "<h3>Internal/Other Changes</h3>\n<ul>\n<li>Updated bundled Claude CLI to version 2.1.47</li>\n</ul>\n<hr />\n<p><strong>PyPI:</strong> <a href=\"https://pypi.org/project/claude-agent-sdk/0.1.38/\" rel=\"nofollow\">https://pypi.org/project/claude-agent-sdk/0.1.38/</a></p>\n<div class=\"highlight highlight-source-shell notranslate position-relative overflow-auto\"><pre>pip install claude-agent-sdk==0.1.38</pre></div>",
    "image_url": "",
    "published": "2026-02-18T21:57:56Z",
    "collected_at": "2026-02-22T03:00:05.357291+00:00",
    "ingest_batch_id": "20260222-030005",
    "tier": "tier1",
    "type": "release",
    "source_reliability": 0.946,
    "freshness": 0.253,
    "tier1_quick_score": 2.589,
    "v2_slot": "agent_tooling_releases",
    "v2_prefilter_score": 2.499,
    "llm_label_source": "heuristic",
    "llm_category": "release",
    "llm_summary_1line": "Internal/Other Changes Updated bundled Claude CLI to version 2.1.47 PyPI: https://pypi.org/project/claude-agent-sdk/0.1.38/ pip install claude-agent-sdk==0.1.38",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.25,
    "v2_source_bias": 0.0,
    "v2_topical_bias": 0.2,
    "v2_final_score": 1.851,
    "summary_1line": "Claude Agent SDK v0.1.38 updates bundled Claude CLI to 2.1.47 with internal/other changes.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.459,
    "v2_global_score": 2.31
  },
  {
    "id": "43cc768aaf808884",
    "source": "openai_blog",
    "source_weight": 2.0,
    "title": "Our First Proof submissions",
    "url": "https://openai.com/index/first-proof-submissions",
    "summary": "We share our AI modelâ€™s proof attempts for the First Proof math challenge, testing research-grade reasoning on expert-level problems.",
    "image_url": "",
    "published": "Fri, 20 Feb 2026 14:30:00 GMT",
    "collected_at": "2026-02-22T03:00:05.357291+00:00",
    "ingest_batch_id": "20260222-030005",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.946,
    "freshness": 0.634,
    "tier1_quick_score": 3.548,
    "v2_slot": "frontier_official",
    "v2_prefilter_score": 3.58,
    "llm_label_source": "llm",
    "llm_category": "research",
    "llm_summary_1line": "OpenAI shares proof-attempt submissions for First Proof math challenge, evaluating reasoning on expert-level problems.",
    "llm_why_1line": "Math reasoning â‰  coding automation; no harness, eval, or delivery-loop insights; minimal actionable engineering signal.",
    "v2_llm_score": 1.75,
    "v2_source_bias": 0.1,
    "v2_topical_bias": 0.0,
    "v2_final_score": 1.627,
    "summary_1line": "OpenAI shares AI proof submissions for First Proof math challenge, showcasing reasoning capabilities on expert-level problems.",
    "why_it_matters": "Math reasoning â‰  coding automation; no harness, eval, or delivery-loop insights; minimal actionable engineering signal.",
    "v2_slot_priority": 0.659,
    "v2_global_score": 2.286
  },
  {
    "id": "5ded8551ab4e9f3f",
    "source": "huggingface_blog",
    "source_weight": 1.1,
    "title": "IBM and UC Berkeley Diagnose Why Enterprise Agents Fail Using IT-Bench and MAST",
    "url": "https://huggingface.co/blog/ibm-research/itbenchandmast",
    "summary": "",
    "image_url": "",
    "published": "Wed, 18 Feb 2026 16:15:45 GMT",
    "collected_at": "2026-02-22T03:00:05.357291+00:00",
    "ingest_batch_id": "20260222-030005",
    "tier": "tier1",
    "type": "research",
    "source_reliability": 0.946,
    "freshness": 0.478,
    "tier1_quick_score": 2.363,
    "v2_slot": "research_watch",
    "v2_prefilter_score": 2.524,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "IBM and UC Berkeley Diagnose Why Enterprise Agents Fail Using IT-Bench and MAST",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.0,
    "v2_source_bias": 0.0,
    "v2_topical_bias": 0.2,
    "v2_final_score": 1.972,
    "summary_1line": "IBM and UC Berkeley introduce IT-Bench and MAST to diagnose enterprise agent failures, focusing on IT operations and enterprise task automation.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.274,
    "v2_global_score": 2.246
  },
  {
    "id": "b91259f7d1a90da4",
    "source": "anthropic_newsroom",
    "source_weight": 1.8,
    "title": "Anthropic Codepath Partnership",
    "url": "https://www.anthropic.com/news/anthropic-codepath-partnership",
    "summary": "",
    "image_url": "",
    "published": "2026-02-13T20:47:00+00:00",
    "collected_at": "2026-02-22T03:00:05.357291+00:00",
    "ingest_batch_id": "20260222-030005",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.946,
    "freshness": 0.084,
    "tier1_quick_score": 2.81,
    "v2_slot": "frontier_official",
    "v2_prefilter_score": 2.83,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "Anthropic Codepath Partnership",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.0,
    "v2_source_bias": 0.06,
    "v2_topical_bias": -0.2,
    "v2_final_score": 1.477,
    "summary_1line": "Anthropic partners with Codepath on education initiatives; no technical details on agentic coding or platform capabilities disclosed.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.659,
    "v2_global_score": 2.136
  },
  {
    "id": "f09c45ee226de24a",
    "source": "anthropic_newsroom",
    "source_weight": 1.8,
    "title": "Chris Liddell Appointed Anthropic Board",
    "url": "https://www.anthropic.com/news/chris-liddell-appointed-anthropic-board",
    "summary": "",
    "image_url": "",
    "published": "2026-02-13T14:57:00+00:00",
    "collected_at": "2026-02-22T03:00:05.357291+00:00",
    "ingest_batch_id": "20260222-030005",
    "tier": "tier1",
    "type": "news",
    "source_reliability": 0.946,
    "freshness": 0.078,
    "tier1_quick_score": 2.805,
    "v2_slot": "frontier_official",
    "v2_prefilter_score": 2.824,
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "Chris Liddell Appointed Anthropic Board",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.0,
    "v2_source_bias": 0.06,
    "v2_topical_bias": -0.2,
    "v2_final_score": 1.476,
    "summary_1line": "Chris Liddell joins Anthropic's board as independent director, bringing operational and financial expertise.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.659,
    "v2_global_score": 2.135
  },
  {
    "id": "061c6d66ccc5e596",
    "source": "openai_codex_releases",
    "source_weight": 2.2,
    "title": "0.105.0-alpha.4",
    "url": "https://github.com/openai/codex/releases/tag/rust-v0.105.0-alpha.4",
    "summary": "<p>Release 0.105.0-alpha.4</p>",
    "image_url": "",
    "published": "2026-02-19T12:01:27Z",
    "collected_at": "2026-02-22T03:00:05.357291+00:00",
    "ingest_batch_id": "20260222-030005",
    "tier": "tier1",
    "type": "release",
    "source_reliability": 0.946,
    "freshness": 0.325,
    "tier1_quick_score": 3.563,
    "v2_slot": "agent_tooling_releases",
    "v2_prefilter_score": 3.471,
    "llm_label_source": "heuristic",
    "llm_category": "release",
    "llm_summary_1line": "Release 0.105.0-alpha.4",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.25,
    "v2_source_bias": 0.0,
    "v2_topical_bias": 0.0,
    "v2_final_score": 1.672,
    "summary_1line": "OpenAI Codex Rust SDK v0.105.0-alpha.4 released with unspecified updates.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.459,
    "v2_global_score": 2.131
  }
]