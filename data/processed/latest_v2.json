[
  {
    "id": "c6e0c1c50f17e587",
    "source": "simon_willison",
    "source_weight": 1.25,
    "title": "Deep Blue",
    "url": "https://simonwillison.net/2026/Feb/15/deep-blue/#atom-everything",
    "summary": "<p>We coined a new term on the <a href=\"https://simonwillison.net/2026/Jan/8/llm-predictions-for-2026/\">Oxide and Friends podcast</a> last month (primary credit to Adam Leventhal) covering the sense of psychological ennui leading into existential dread that many software developers are feeling thanks to the encroachment of generative AI into their field of work.</p>\n<p>We're calling it <strong>Deep Blue</strong>.</p>\n<p>You can listen to it being coined in real time <a href=\"https://www.youtube.com/watch?v=lVDhQMiAbR8&amp;t=2835s\">from 47:15 in the episode</a>. I've included <a href=\"https://simonwillison.net/2026/Feb/15/deep-blue/#transcript\">a transcript below</a>.</p>\n<p>Deep Blue is a very real issue.</p>\n<p>Becoming a professional software engineer is <em>hard</em>. Getting good enough for people to pay you money to write software takes years of dedicated work. The rewards are significant: this is a well compensated career which opens up a lot of great opportunities.</p>\n<p>It's also a career that's mostly free from gatekeepers and expensive prerequisites. You don't need an expensive degree or accreditation. A laptop, an internet connection and a lot of time and curiosity is enough to get you started.</p>\n<p>And it rewards the nerds! Spending your teenage years tinkering with computers turned out to be a very smart investment in your future.</p>\n<p>The idea that this could all be stripped away by a chatbot is <em>deeply</em> upsetting.</p>\n<p>I've seen signs of Deep Blue in most of the online communities I spend time in. I've even faced accusations from my peers that I am actively harming their future careers through my work helping people understand how well AI-assisted programming can work.</p>\n<p>I think this is an issue which is causing genuine mental anguish for a lot of people in our community. Giving it a name makes it easier for us to have conversations about it.</p>\n<h4 id=\"my-experiences-of-deep-blue\">My experiences of Deep Blue</h4>\n<p>I distinctly remember my first experience of Deep Blue. For me it was triggered by ChatGPT Code Interpreter back in early 2023.</p>\n<p>My primary project is <a href=\"https://datasette.io/\">Datasette</a>, an ecosystem of open source tools for telling stories with data. I had dedicated myself to the challenge of helping people (initially focusing on journalists) clean up, analyze and find meaning in data, in all sorts of shapes and sizes.</p>\n<p>I expected I would need to build a lot of software for this! It felt like a challenge that could keep me happily engaged for many years to come.</p>\n<p>Then I tried uploading a CSV file of <a href=\"https://data.sfgov.org/Public-Safety/Police-Department-Incident-Reports-2018-to-Present/wg3w-h783/about_data\">San Francisco Police Department Incident Reports</a> - hundreds of thousands of rows - to ChatGPT Code Interpreter and... it did every piece of data cleanup and analysis I had on my napkin roadmap for the next few years with a couple of prompts.</p>\n<p>It even converted the data into a neatly normalized SQLite database and let me download the result!</p>\n<p>I remember having two competing thoughts in parallel.</p>\n<p>On the one hand, as somebody who wants journalists to be able to do more with data, this felt like a <em>huge</em> breakthrough. Imagine giving every journalist in the world an on-demand analyst who could help them tackle any data question they could think of!</p>\n<p>But on the other hand... <em>what was I even for</em>? My confidence in the value of my own projects took a painful hit. Was the path I'd chosen for myself suddenly a dead end?</p>\n<p>I've had some further pangs of Deep Blue just in the past few weeks, thanks to the Claude Opus 4.5/4.6 and GPT-5.2/5.3 coding agent effect. As many other people are also observing, the latest generation of coding agents, given the right prompts, really can churn away for a few minutes to several hours and produce working, documented and fully tested software that exactly matches the criteria they were given.</p>\n<p>\"The code they write isn't any good\" doesn't really cut it any more.</p>\n<h4 id=\"transcript\">A lightly edited transcript</h4>\n<blockquote>\n<p><strong>Bryan</strong>: I think that we're going to see a real problem with AI induced ennui where software engineers in particular get listless because the AI can do anything. Simon, what do you think about that?</p>\n<p><strong>Simon</strong>: Definitely. Anyone who's paying close attention to coding agents is feeling some of that already. There's an extent where you sort of get over it when you realize that you're still useful, even though your ability to memorize the syntax of program languages is completely irrelevant now.</p>\n<p>Something I see a lot of is people out there who are having existential crises and are very, very unhappy because they're like, \"I dedicated my career to learning this thing and now it just does it. What am I even for?\". I will very happily try and convince those people that they are for a whole bunch of things and that none of that experience they've accumulated has gone to waste, but psychologically it's a difficult time for software engineers.</p>\n<p>[...]</p>\n<p><strong>Bryan</strong>: Okay, so I'm going to predict that we name that. Whatever that is, we have a name for that kind of feeling and that kind of, whether you want to call it a blueness or a loss of purpose, and that we're kind of trying to address it collectively in a directed way.</p>\n<p><strong>Adam</strong>: Okay, this is your big moment. Pick the name. If you call your shot from here, this is you pointing to the stands. You know, I – Like deep blue, you know.</p>\n<p><strong>Bryan</strong>: Yeah, deep blue. I like that. I like deep blue. Deep blue. Oh, did you walk me into that, you bastard? You just blew out the candles on my birthday cake.</p>\n<p>It wasn't my big moment at all. That was your big moment. No, that is, Adam, that is very good. That is deep blue.</p>\n<p><strong>Simon</strong>: All of the chess players and the Go players went through this a decade ago and they have come out stronger.</p>\n</blockquote>\n<p>Turns out it was more than a decade ago: <a href=\"https://en.wikipedia.org/wiki/Deep_Blue_versus_Garry_Kasparov\">Deep Blue defeated Garry Kasparov in 1997</a>.</p>\n    \n        <p>Tags: <a href=\"https://simonwillison.net/tags/definitions\">definitions</a>, <a href=\"https://simonwillison.net/tags/careers\">careers</a>, <a href=\"https://simonwillison.net/tags/ai\">ai</a>, <a href=\"https://simonwillison.net/tags/generative-ai\">generative-ai</a>, <a href=\"https://simonwillison.net/tags/llms\">llms</a>, <a href=\"https://simonwillison.net/tags/ai-assisted-programming\">ai-assisted-programming</a>, <a href=\"https://simonwillison.net/tags/oxide\">oxide</a>, <a href=\"https://simonwillison.net/tags/bryan-cantrill\">bryan-cantrill</a>, <a href=\"https://simonwillison.net/tags/ai-ethics\">ai-ethics</a>, <a href=\"https://simonwillison.net/tags/coding-agents\">coding-agents</a></p>",
    "image_url": "",
    "published": "2026-02-15T21:06:44+00:00",
    "collected_at": "2026-02-16T11:51:03.566250+00:00",
    "v2_slot": "practitioner_analysis",
    "freshness": 0.692,
    "source_reliability": 1.0,
    "v2_prefilter_score": 2.942,
    "type": "news",
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "We coined a new term on the Oxide and Friends podcast last month (primary credit to Adam Leventhal) covering the sense of psychological ennui leading into existential dread that many software developers are feeling th...",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.75,
    "v2_source_bias": 0.08,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.721,
    "summary_1line": "We coined a new term on the Oxide and Friends podcast last month (primary credit to Adam Leventhal) covering the sense of psychological ennui leading into existential dread that many software developers are feeling th...",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.515,
    "v2_global_score": 3.236
  },
  {
    "id": "503bce79ec85a159",
    "source": "simon_willison",
    "source_weight": 1.25,
    "title": "Gemini 3 Deep Think",
    "url": "https://simonwillison.net/2026/Feb/12/gemini-3-deep-think/#atom-everything",
    "summary": "<p><strong><a href=\"https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-deep-think/\">Gemini 3 Deep Think</a></strong></p>\nNew from Google. They say it's \"built to push the frontier of intelligence and solve modern challenges across science, research, and engineering\".</p>\n<p>It drew me a <em>really good</em> <a href=\"https://gist.github.com/simonw/7e317ebb5cf8e75b2fcec4d0694a8199\">SVG of a pelican riding a bicycle</a>! I think this is the best one I've seen so far - here's <a href=\"https://simonwillison.net/tags/pelican-riding-a-bicycle/\">my previous collection</a>.</p>\n<p><img alt=\"This alt text also generated by Gemini 3 Deep Think: A highly detailed, colorful, flat vector illustration with thick dark blue outlines depicting a stylized white pelican riding a bright cyan blue bicycle from left to right across a sandy beige beach with white speed lines indicating forward motion. The pelican features a light blue eye, a pink cheek blush, a massive bill with a vertical gradient from yellow to orange, a backward magenta cap with a cyan brim and a small yellow top button, and a matching magenta scarf blowing backward in the wind. Its white wing, accented with a grey mid-section and dark blue feather tips, reaches forward to grip the handlebars, while its long tan leg and orange foot press down on an orange pedal. Attached to the front handlebars is a white wire basket carrying a bright blue cartoon fish that is pointing upwards and forwards. The bicycle itself has a cyan frame, dark blue tires, striking neon pink inner rims, cyan spokes, a white front chainring, and a dark blue chain. Behind the pelican, a grey trapezoidal pier extends from the sand toward a horizontal band of deep blue ocean water detailed with light cyan wavy lines. A massive, solid yellow-orange semi-circle sun sits on the horizon line, setting directly behind the bicycle frame. The background sky is a smooth vertical gradient transitioning from soft pink at the top to warm golden-yellow at the horizon, decorated with stylized pale peach fluffy clouds, thin white horizontal wind streaks, twinkling four-pointed white stars, and small brown v-shaped silhouettes of distant flying birds.\" src=\"https://static.simonwillison.net/static/2026/gemini-3-deep-think-pelican.png\" /></p>\n<p>(And since it's an FAQ, here's my answer to <a href=\"https://simonwillison.net/2025/Nov/13/training-for-pelicans-riding-bicycles/\">What happens if AI labs train for pelicans riding bicycles?</a>)</p>\n<p>Since it did so well on my basic <code>Generate an SVG of a pelican riding a bicycle</code> I decided to try the <a href=\"https://simonwillison.net/2025/Nov/18/gemini-3/#and-a-new-pelican-benchmark\">more challenging version</a> as well:</p>\n<blockquote>\n<p><code>Generate an SVG of a California brown pelican riding a bicycle. The bicycle must have spokes and a correctly shaped bicycle frame. The pelican must have its characteristic large pouch, and there should be a clear indication of feathers. The pelican must be clearly pedaling the bicycle. The image should show the full breeding plumage of the California brown pelican.</code></p>\n</blockquote>\n<p>Here's <a href=\"https://gist.github.com/simonw/154c0cc7b4daed579f6a5e616250ecc8\">what I got</a>:</p>\n<p><img alt=\"Also described by Gemini 3 Deep Think: A highly detailed, vibrant, and stylized vector illustration of a whimsical bird resembling a mix between a pelican and a frigatebird enthusiastically riding a bright cyan bicycle from left to right across a flat tan and brown surface. The bird leans horizontally over the frame in an aerodynamic racing posture, with thin, dark brown wing-like arms reaching forward to grip the silver handlebars and a single thick brown leg, patterned with white V-shapes, stretching down to press on a black pedal. The bird's most prominent and striking feature is an enormous, vividly bright red, inflated throat pouch hanging beneath a long, straight grey upper beak that ends in a small orange hook. Its head is mostly white with a small pink patch surrounding the eye, a dark brown stripe running down the back of its neck, and a distinctive curly pale yellow crest on the very top. The bird's round, dark brown body shares the same repeating white V-shaped feather pattern as its leg and is accented by a folded wing resting on its side, made up of cleanly layered light blue and grey feathers. A tail composed of four stiff, straight dark brown feathers extends directly backward. Thin white horizontal speed lines trail behind the back wheel and the bird's tail, emphasizing swift forward motion. The bicycle features a classic diamond frame, large wheels with thin black tires, grey rims, and detailed silver spokes, along with a clearly visible front chainring, silver chain, and rear cog. The whimsical scene is set against a clear light blue sky featuring two small, fluffy white clouds on the left and a large, pale yellow sun in the upper right corner that radiates soft, concentric, semi-transparent pastel green and yellow halos. A solid, darker brown shadow is cast directly beneath the bicycle's wheels on the minimalist two-toned brown ground.\" src=\"https://static.simonwillison.net/static/2026/gemini-3-deep-think-complex-pelican.png\" />\n\n    <p><small></small>Via <a href=\"https://news.ycombinator.com/item?id=46991240\">Hacker News</a></small></p>\n\n\n    <p>Tags: <a href=\"https://simonwillison.net/tags/google\">google</a>, <a href=\"https://simonwillison.net/tags/ai\">ai</a>, <a href=\"https://simonwillison.net/tags/generative-ai\">generative-ai</a>, <a href=\"https://simonwillison.net/tags/llms\">llms</a>, <a href=\"https://simonwillison.net/tags/gemini\">gemini</a>, <a href=\"https://simonwillison.net/tags/pelican-riding-a-bicycle\">pelican-riding-a-bicycle</a>, <a href=\"https://simonwillison.net/tags/llm-reasoning\">llm-reasoning</a>, <a href=\"https://simonwillison.net/tags/llm-release\">llm-release</a></p>",
    "image_url": "https://static.simonwillison.net/static/2026/gemini-3-deep-think-pelican.png",
    "published": "2026-02-12T18:12:17+00:00",
    "collected_at": "2026-02-16T11:51:03.566250+00:00",
    "v2_slot": "practitioner_analysis",
    "freshness": 0.106,
    "source_reliability": 1.0,
    "v2_prefilter_score": 2.356,
    "type": "news",
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "Gemini 3 Deep Think New from Google. They say it's \"built to push the frontier of intelligence and solve modern challenges across science, research, and engineering\". It drew me a really good SVG of a pelican riding a...",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.75,
    "v2_source_bias": 0.08,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.633,
    "summary_1line": "Gemini 3 Deep Think New from Google. They say it's \"built to push the frontier of intelligence and solve modern challenges across science, research, and engineering\". It drew me a really good SVG of a pelican riding a...",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.515,
    "v2_global_score": 3.148
  },
  {
    "id": "b4a1f65fd2c36642",
    "source": "infoq_ai_ml",
    "source_weight": 1.15,
    "title": "Google Explores Scaling Principles for Multi-agent Coordination",
    "url": "https://www.infoq.com/news/2026/02/google-agent-scaling-principles/?utm_campaign=infoq_content&utm_source=infoq&utm_medium=feed&utm_term=AI%2C+ML+%26+Data+Engineering",
    "summary": "<img src=\"https://res.infoq.com/news/2026/02/google-agent-scaling-principles/en/headerimage/google-scaling-agents-principles-1771231654834.jpeg\" /><p>Google Research tried to answer the question of how to design agent systems for optimal performance by running a controlled evaluation of 180 agent configurations. From this, the team derived what they call the \"first quantitative scaling principles for AI agent systems\", showing that multi-agent coordination does not reliably improve results and can even reduce performance.</p> <i>By Sergio De Simone</i>",
    "image_url": "https://res.infoq.com/news/2026/02/google-agent-scaling-principles/en/headerimage/google-scaling-agents-principles-1771231654834.jpeg",
    "published": "Mon, 16 Feb 2026 09:00:00 GMT",
    "collected_at": "2026-02-16T11:51:03.566250+00:00",
    "v2_slot": "practitioner_analysis",
    "freshness": 0.931,
    "source_reliability": 1.0,
    "v2_prefilter_score": 3.081,
    "type": "news",
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "Google Research tried to answer the question of how to design agent systems for optimal performance by running a controlled evaluation of 180 agent configurations. From this, the team derived what they call the \"first...",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.6,
    "v2_source_bias": 0.08,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.63,
    "summary_1line": "Google derives quantitative scaling principles for multi-agent systems; finds coordination often degrades performance vs. single agents.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.515,
    "v2_global_score": 3.145
  },
  {
    "id": "28aeb3b7d9a1e43f",
    "source": "infoq_ai_ml",
    "source_weight": 1.15,
    "title": "Article: Architecting Agentic MLOps: A Layered Protocol Strategy with A2A and MCP",
    "url": "https://www.infoq.com/articles/architecting-agentic-mlops-a2a-mcp/?utm_campaign=infoq_content&utm_source=infoq&utm_medium=feed&utm_term=AI%2C+ML+%26+Data+Engineering",
    "summary": "<img src=\"https://res.infoq.com/articles/architecting-agentic-mlops-a2a-mcp/en/headerimage/architecting-agentic-mlops-a2a-mcp-header-1770303550343.jpg\" /><p>In this article, the authors outline protocols for building extensible multi-agent MLOps systems. The core architecture deliberately decouples orchestration from execution, allowing teams to incrementally add capabilities via discovery and evolve operations from static pipelines toward intelligent, adaptive coordination.</p> <i>By Shashank Kapoor, Sanjay Surendranath Girija, Lakshit Arora</i>",
    "image_url": "https://res.infoq.com/articles/architecting-agentic-mlops-a2a-mcp/en/headerimage/architecting-agentic-mlops-a2a-mcp-header-1770303550343.jpg",
    "published": "Mon, 16 Feb 2026 09:00:00 GMT",
    "collected_at": "2026-02-16T11:51:03.566250+00:00",
    "v2_slot": "practitioner_analysis",
    "freshness": 0.931,
    "source_reliability": 1.0,
    "v2_prefilter_score": 3.081,
    "type": "news",
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "In this article, the authors outline protocols for building extensible multi-agent MLOps systems. The core architecture deliberately decouples orchestration from execution, allowing teams to incrementally add capabili...",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.4,
    "v2_source_bias": 0.08,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.46,
    "summary_1line": "Layered protocol architecture for multi-agent MLOps decouples orchestration from execution using A2A and MCP for incremental capability expansion.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.515,
    "v2_global_score": 2.975
  },
  {
    "id": "8fdd8b7d12d6ce56",
    "source": "hackernews_ai",
    "source_weight": 1.1,
    "title": "Show HN: Train AI Agents to Write Better Playwright Tests",
    "url": "https://testdino.com/blog/playwright-skill/",
    "summary": "<p>AI agents often generate inconsistent Playwright tests because they do not understand your application’s specific workflows, UI patterns, or constraints.<p>The Playwright Skill provides more than 70 structured markdown guides that teach patterns for locators, authentication, visual testing, CI configuration, and framework migration so agents can apply consistent solutions instead of guessing.<p>You install it with: npx skills add testdino-hq/playwright-skill.<p>The material is organized into five packs: core testing (46 guides), Playwright CLI usage for token‑efficient automation (10), Page Object Model patterns (2), CI/CD setup for major providers (9), and migrations from Cypress or Selenium (2).<p>Each guide follows the same structure—when to use a pattern, when to avoid it, quick reference code, and complete implementations—so learners can move from concept to reliable tests step by step.<p>The skill works with tools such as Claude Code, GitHub Copilot, Cursor, and any agent that implements the skills protocol, and it is MIT‑licensed so teams can adapt the content to their own standards and practices.<p>For a deeper walkthrough of the guides and structure, see the full article at <a href=\"https://testdino.com/blog/playwright-skill/\" rel=\"nofollow\">https://testdino.com/blog/playwright-skill/</a>.</p>\n<hr />\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47032774\">https://news.ycombinator.com/item?id=47032774</a></p>\n<p>Points: 2</p>\n<p># Comments: 0</p>",
    "image_url": "",
    "published": "Mon, 16 Feb 2026 09:18:10 +0000",
    "collected_at": "2026-02-16T11:51:03.566250+00:00",
    "v2_slot": "community_signal",
    "freshness": 0.852,
    "source_reliability": 1.0,
    "v2_prefilter_score": 2.952,
    "type": "news",
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "AI agents often generate inconsistent Playwright tests because they do not understand your application’s specific workflows, UI patterns, or constraints. The Playwright Skill provides more than 70 structured markdown...",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.75,
    "v2_source_bias": 0.0,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.476,
    "summary_1line": "Playwright Skill teaches AI agents 70+ structured guides for consistent test generation via locators, auth, CI/CD, and migrations—works with Claude Code, Copilot, and Cursor.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.488,
    "v2_global_score": 2.964
  },
  {
    "id": "69224219498a0b50",
    "source": "arxiv_cs_lg",
    "source_weight": 0.85,
    "title": "Quantization-Aware Collaborative Inference for Large Embodied AI Models",
    "url": "http://arxiv.org/abs/2602.13052v1",
    "summary": "Large artificial intelligence models (LAIMs) are increasingly regarded as a core intelligence engine for embodied AI applications. However, the massive parameter scale and computational demands of LAIMs pose significant challenges for resource-limited embodied agents. To address this issue, we investigate quantization-aware collaborative inference (co-inference) for embodied AI systems. First, we develop a tractable approximation for quantization-induced inference distortion. Based on this approximation, we derive lower and upper bounds on the quantization rate-inference distortion function, characterizing its dependence on LAIM statistics, including the quantization bit-width. Next, we formulate a joint quantization bit-width and computation frequency design problem under delay and energy constraints, aiming to minimize the distortion upper bound while ensuring tightness through the corresponding lower bound. Extensive evaluations validate the proposed distortion approximation, the derived rate-distortion bounds, and the effectiveness of the proposed joint design. Particularly, simulations and real-world testbed experiments demonstrate the effectiveness of the proposed joint design in balancing inference quality, latency, and energy consumption in edge embodied AI systems.",
    "image_url": "",
    "published": "2026-02-13T16:08:19Z",
    "collected_at": "2026-02-16T11:51:03.566250+00:00",
    "v2_slot": "research_watch",
    "freshness": 0.546,
    "source_reliability": 1.0,
    "v2_prefilter_score": 2.396,
    "type": "paper",
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "Large artificial intelligence models (LAIMs) are increasingly regarded as a core intelligence engine for embodied AI applications. However, the massive parameter scale and computational demands of LAIMs pose significa...",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 3.05,
    "v2_source_bias": -0.35,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.524,
    "summary_1line": "Quantization-aware inference framework optimizes large embodied AI models for edge devices under latency and energy constraints.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.31,
    "v2_global_score": 2.834
  },
  {
    "id": "aff79ab0a7c0b67d",
    "source": "arxiv_cs_cl",
    "source_weight": 0.8,
    "title": "OpenLID-v3: Improving the Precision of Closely Related Language Identification -- An Experience Report",
    "url": "http://arxiv.org/abs/2602.13139v1",
    "summary": "Language identification (LID) is an essential step in building high-quality multilingual datasets from web data. Existing LID tools (such as OpenLID or GlotLID) often struggle to identify closely related languages and to distinguish valid natural language from noise, which contaminates language-specific subsets, especially for low-resource languages. In this work we extend the OpenLID classifier by adding more training data, merging problematic language variant clusters, and introducing a special label for marking noise. We call this extended system OpenLID-v3 and evaluate it against GlotLID on multiple benchmarks. During development, we focus on three groups of closely related languages (Bosnian, Croatian, and Serbian; Romance varieties of Northern Italy and Southern France; and Scandinavian languages) and contribute new evaluation datasets where existing ones are inadequate. We find that ensemble approaches improve precision but also substantially reduce coverage for low-resource languages. OpenLID-v3 is available on https://huggingface.co/HPLT/OpenLID-v3.",
    "image_url": "",
    "published": "2026-02-13T17:47:08Z",
    "collected_at": "2026-02-16T11:51:03.566250+00:00",
    "v2_slot": "research_watch",
    "freshness": 0.554,
    "source_reliability": 1.0,
    "v2_prefilter_score": 2.354,
    "type": "paper",
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "Language identification (LID) is an essential step in building high-quality multilingual datasets from web data. Existing LID tools (such as OpenLID or GlotLID) often struggle to identify closely related languages and...",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.75,
    "v2_source_bias": -0.3,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.321,
    "summary_1line": "Language identification (LID) is an essential step in building high-quality multilingual datasets from web data. Existing LID tools (such as OpenLID or GlotLID) often struggle to identify closely related languages and...",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.31,
    "v2_global_score": 2.631
  },
  {
    "id": "8e37b924ee8e53d3",
    "source": "latent_space",
    "source_weight": 1.2,
    "title": "[AINews] new Gemini 3 Deep Think, Anthropic $30B @ $380B, GPT-5.3-Codex Spark, MiniMax M2.5",
    "url": "https://www.latent.space/p/ainews-new-gemini-3-deep-think-anthropic",
    "summary": "There's too much going on!",
    "image_url": "https://substackcdn.com/image/youtube/w_728,c_limit/F_1oDPWxpFQ",
    "published": "Fri, 13 Feb 2026 08:29:19 GMT",
    "collected_at": "2026-02-16T11:51:03.566250+00:00",
    "v2_slot": "practitioner_analysis",
    "freshness": 0.152,
    "source_reliability": 1.0,
    "v2_prefilter_score": 2.352,
    "type": "news",
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "There's too much going on!",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.2,
    "v2_source_bias": 0.0,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.093,
    "summary_1line": "There's too much going on!",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.515,
    "v2_global_score": 2.608
  },
  {
    "id": "b91259f7d1a90da4",
    "source": "anthropic_newsroom",
    "source_weight": 1.8,
    "title": "Anthropic Codepath Partnership",
    "url": "https://www.anthropic.com/news/anthropic-codepath-partnership",
    "summary": "",
    "image_url": "",
    "published": "2026-02-13T16:19:50.000Z",
    "collected_at": "2026-02-16T11:51:03.566250+00:00",
    "v2_slot": "frontier_official",
    "freshness": 0.06,
    "source_reliability": 1.0,
    "v2_prefilter_score": 2.86,
    "type": "news",
    "llm_label_source": "llm",
    "llm_category": "platform",
    "llm_summary_1line": "Anthropic partners with CodePath to expand AI coding education and workforce development initiatives.",
    "llm_why_1line": "Partnership announcement lacks technical depth, concrete tooling, or actionable platform integration for engineering workflows.",
    "v2_llm_score": 1.35,
    "v2_source_bias": 0.06,
    "v2_topical_bias": -0.2,
    "v2_final_score": 0.952,
    "summary_1line": "Anthropic partners with CodePath on CS education initiatives, expanding Claude access for underrepresented students in coding bootcamps.",
    "why_it_matters": "Partnership announcement lacks technical depth, concrete tooling, or actionable platform integration for engineering workflows.",
    "v2_slot_priority": 0.53,
    "v2_global_score": 1.482
  },
  {
    "id": "f09c45ee226de24a",
    "source": "anthropic_newsroom",
    "source_weight": 1.8,
    "title": "Chris Liddell Appointed Anthropic Board",
    "url": "https://www.anthropic.com/news/chris-liddell-appointed-anthropic-board",
    "summary": "",
    "image_url": "",
    "published": "2026-02-13T16:21:14.000Z",
    "collected_at": "2026-02-16T11:51:03.566250+00:00",
    "v2_slot": "frontier_official",
    "freshness": 0.06,
    "source_reliability": 1.0,
    "v2_prefilter_score": 2.86,
    "type": "news",
    "llm_label_source": "llm",
    "llm_category": "platform",
    "llm_summary_1line": "Chris Liddell joins Anthropic's board as independent director, bringing finance and tech governance experience.",
    "llm_why_1line": "Corporate governance announcement; zero relevance to coding agents, infra, evals, or delivery automation.",
    "v2_llm_score": 0.95,
    "v2_source_bias": 0.06,
    "v2_topical_bias": -0.2,
    "v2_final_score": 0.632,
    "summary_1line": "Chris Liddell joins Anthropic's board as independent director, bringing corporate governance experience.",
    "why_it_matters": "Corporate governance announcement; zero relevance to coding agents, infra, evals, or delivery automation.",
    "v2_slot_priority": 0.53,
    "v2_global_score": 1.162
  },
  {
    "id": "504929088957b0e2",
    "source": "huggingface_blog",
    "source_weight": 1.1,
    "title": "OpenEnv in Practice: Evaluating Tool-Using Agents in Real-World Environments",
    "url": "https://huggingface.co/blog/openenv-turing",
    "summary": "",
    "image_url": "",
    "published": "Thu, 12 Feb 2026 00:00:00 GMT",
    "collected_at": "2026-02-16T11:51:03.566250+00:00",
    "v2_slot": "research_watch",
    "freshness": 0.382,
    "source_reliability": 1.0,
    "v2_prefilter_score": 2.482,
    "type": "research",
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "OpenEnv in Practice: Evaluating Tool-Using Agents in Real-World Environments",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.4,
    "v2_source_bias": 0.0,
    "v2_topical_bias": 0.2,
    "v2_final_score": 2.297,
    "summary_1line": "OpenEnv framework evaluates tool-using agents in simulated real-world environments; limited details on harness integration or coding-agent specifics.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.31,
    "v2_global_score": 2.607
  },
  {
    "id": "fe7dbebc903fef59",
    "source": "anthropic_research",
    "source_weight": 1.4,
    "title": "India Brief Economic Index",
    "url": "https://www.anthropic.com/research/india-brief-economic-index",
    "summary": "",
    "image_url": "",
    "published": "2026-02-16T11:08:11.000Z",
    "collected_at": "2026-02-16T11:51:03.566250+00:00",
    "v2_slot": "research_watch",
    "freshness": 0.994,
    "source_reliability": 1.0,
    "v2_prefilter_score": 3.394,
    "type": "research",
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "India Brief Economic Index",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.0,
    "v2_source_bias": 0.4,
    "v2_topical_bias": 0.0,
    "v2_final_score": 2.249,
    "summary_1line": "Anthropic releases India Brief Economic Index, a macroeconomic dataset and analysis tool for Indian economy tracking.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.31,
    "v2_global_score": 2.559
  },
  {
    "id": "393019c2d406463f",
    "source": "openai_codex_releases",
    "source_weight": 2.2,
    "title": "0.100.0",
    "url": "https://github.com/openai/codex/releases/tag/rust-v0.100.0",
    "summary": "<h2>New Features</h2>\n<ul>\n<li>Added an experimental, feature-gated JavaScript REPL runtime (<code>js_repl</code>) that can persist state across tool calls, with optional runtime path overrides. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/10674\">#10674</a>)</li>\n<li>Added support for multiple simultaneous rate limits across the protocol, backend client, and TUI status surfaces. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11260\">#11260</a>)</li>\n<li>Reintroduced app-server websocket transport with a split inbound/outbound architecture, plus connection-aware thread resume subscriptions. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11370\">#11370</a>, <a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11474\">#11474</a>)</li>\n<li>Added memory management slash commands in the TUI (<code>/m_update</code>, <code>/m_drop</code>) and expanded memory-read/metrics plumbing. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11569\">#11569</a>, <a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11459\">#11459</a>, <a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11593\">#11593</a>)</li>\n<li>Enabled Apps SDK apps in ChatGPT connector handling. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11486\">#11486</a>)</li>\n<li>Promoted sandbox capabilities on both Linux and Windows, and introduced a new <code>ReadOnlyAccess</code> policy shape for configurable read access. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11381\">#11381</a>, <a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11341\">#11341</a>, <a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11387\">#11387</a>)</li>\n</ul>\n<h2>Bug Fixes</h2>\n<ul>\n<li>Fixed websocket incremental output duplication, prevented appends after <code>response.completed</code>, and treated <code>response.incomplete</code> as an error path. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11383\">#11383</a>, <a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11402\">#11402</a>, <a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11558\">#11558</a>)</li>\n<li>Improved websocket session stability by continuing ping handling when idle and suppressing noisy first-retry errors during quick reconnects. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11413\">#11413</a>, <a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11548\">#11548</a>)</li>\n<li>Fixed stale thread entries by dropping missing rollout files and cleaning stale DB metadata during thread listing. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11572\">#11572</a>)</li>\n<li>Fixed Windows multi-line paste reliability in terminals (especially VS Code integrated terminal) by increasing paste burst timing tolerance. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/9348\">#9348</a>)</li>\n<li>Fixed incorrect inheritance of <code>limit_name</code> when merging partial rate-limit updates. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11557\">#11557</a>)</li>\n<li>Reduced repeated skill parse-error spam during active edits by increasing file-watcher debounce from 1s to 10s. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11494\">#11494</a>)</li>\n</ul>\n<h2>Documentation</h2>\n<ul>\n<li>Added JS REPL documentation and config/schema guidance for enabling and configuring the feature. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/10674\">#10674</a>)</li>\n<li>Updated app-server websocket transport documentation in the app-server README. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11370\">#11370</a>)</li>\n</ul>\n<h2>Chores</h2>\n<ul>\n<li>Split <code>codex-common</code> into focused <code>codex-utils-*</code> crates to simplify dependency boundaries across Rust workspace components. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11422\">#11422</a>)</li>\n<li>Improved Rust release pipeline throughput and reliability for Windows and musl targets, including parallel Windows builds and musl link fixes. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11488\">#11488</a>, <a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11500\">#11500</a>, <a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11556\">#11556</a>)</li>\n<li>Prevented GitHub release asset upload collisions by excluding duplicate <code>cargo-timing.html</code> artifacts. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11564\">#11564</a>)</li>\n</ul>\n<h2>Changelog</h2>\n<p>Full Changelog: <a class=\"commit-link\" href=\"https://github.com/openai/codex/compare/rust-v0.99.0...rust-v0.100.0\"><tt>rust-v0.99.0...rust-v0.100.0</tt></a></p>\n<ul>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11383\">#11383</a> Do not resend output items in incremental websockets connections <a class=\"user-mention notranslate\" href=\"https://github.com/pakrym-oai\">@pakrym-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11246\">#11246</a> chore: persist turn_id in rollout session and make turn_id uuid based <a class=\"user-mention notranslate\" href=\"https://github.com/celia-oai\">@celia-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11260\">#11260</a> feat: support multiple rate limits <a class=\"user-mention notranslate\" href=\"https://github.com/xl-openai\">@xl-openai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11412\">#11412</a> tui: show non-file layer content in /debug-config <a class=\"user-mention notranslate\" href=\"https://github.com/bolinfest\">@bolinfest</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11405\">#11405</a> Remove <code>test-support</code> feature from <code>codex-core</code> and replace it with explicit test toggles <a class=\"user-mention notranslate\" href=\"https://github.com/bolinfest\">@bolinfest</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11428\">#11428</a> fix: flaky test <a class=\"user-mention notranslate\" href=\"https://github.com/jif-oai\">@jif-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11429\">#11429</a> feat: improve thread listing <a class=\"user-mention notranslate\" href=\"https://github.com/jif-oai\">@jif-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11422\">#11422</a> feat: split codex-common into smaller utils crates <a class=\"user-mention notranslate\" href=\"https://github.com/bolinfest\">@bolinfest</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11439\">#11439</a> feat: new memory prompts <a class=\"user-mention notranslate\" href=\"https://github.com/jif-oai\">@jif-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11305\">#11305</a> Cache cloud requirements <a class=\"user-mention notranslate\" href=\"https://github.com/gt-oai\">@gt-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11452\">#11452</a> nit: increase max raw memories <a class=\"user-mention notranslate\" href=\"https://github.com/jif-oai\">@jif-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11455\">#11455</a> feat: close mem agent after consolidation <a class=\"user-mention notranslate\" href=\"https://github.com/jif-oai\">@jif-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11454\">#11454</a> fix: optional schema of memories <a class=\"user-mention notranslate\" href=\"https://github.com/jif-oai\">@jif-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11449\">#11449</a> feat: set policy for phase 2 memory <a class=\"user-mention notranslate\" href=\"https://github.com/jif-oai\">@jif-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11420\">#11420</a> chore: rename disable_websockets -&gt; websockets_disabled <a class=\"user-mention notranslate\" href=\"https://github.com/sayan-oai\">@sayan-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11402\">#11402</a> Do not attempt to append after response.completed <a class=\"user-mention notranslate\" href=\"https://github.com/pakrym-oai\">@pakrym-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11462\">#11462</a> clean: memory rollout recorder <a class=\"user-mention notranslate\" href=\"https://github.com/jif-oai\">@jif-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11381\">#11381</a> feat(core): promote Linux bubblewrap sandbox to Experimental <a class=\"user-mention notranslate\" href=\"https://github.com/viyatb-oai\">@viyatb-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11389\">#11389</a> Extract <code>codex-config</code> from <code>codex-core</code> <a class=\"user-mention notranslate\" href=\"https://github.com/bolinfest\">@bolinfest</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11370\">#11370</a> Reapply \"Add app-server transport layer with websocket support\" <a class=\"user-mention notranslate\" href=\"https://github.com/maxj-oai\">@maxj-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11470\">#11470</a> feat: panic if Constrained does not support Disabled <a class=\"user-mention notranslate\" href=\"https://github.com/bolinfest\">@bolinfest</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11475\">#11475</a> feat: remove \"cargo check individual crates\" from CI <a class=\"user-mention notranslate\" href=\"https://github.com/bolinfest\">@bolinfest</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11459\">#11459</a> feat: memory read path <a class=\"user-mention notranslate\" href=\"https://github.com/jif-oai\">@jif-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11471\">#11471</a> chore: clean rollout extraction in memories <a class=\"user-mention notranslate\" href=\"https://github.com/jif-oai\">@jif-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/9348\">#9348</a> fix(tui): increase paste burst char interval on Windows to 30ms <a class=\"user-mention notranslate\" href=\"https://github.com/yuvrajangadsingh\">@yuvrajangadsingh</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11464\">#11464</a> chore: sub-agent never ask for approval <a class=\"user-mention notranslate\" href=\"https://github.com/jif-oai\">@jif-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11414\">#11414</a> Linkify feedback link <a class=\"user-mention notranslate\" href=\"https://github.com/pakrym-oai\">@pakrym-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11480\">#11480</a> chore: update mem prompt <a class=\"user-mention notranslate\" href=\"https://github.com/jif-oai\">@jif-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11485\">#11485</a> fix: Constrained import <a class=\"user-mention notranslate\" href=\"https://github.com/owenlin0\">@owenlin0</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11341\">#11341</a> Promote Windows Sandbox <a class=\"user-mention notranslate\" href=\"https://github.com/iceweasel-oai\">@iceweasel-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/10674\">#10674</a> Add feature-gated freeform js_repl core runtime <a class=\"user-mention notranslate\" href=\"https://github.com/fjord-oai\">@fjord-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11419\">#11419</a> refactor: codex app-server ThreadState <a class=\"user-mention notranslate\" href=\"https://github.com/maxj-oai\">@maxj-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11413\">#11413</a> Pump pings <a class=\"user-mention notranslate\" href=\"https://github.com/pakrym-oai\">@pakrym-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11488\">#11488</a> feat: use more powerful machines for building Windows releases <a class=\"user-mention notranslate\" href=\"https://github.com/bolinfest\">@bolinfest</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11479\">#11479</a> nit: memory truncation <a class=\"user-mention notranslate\" href=\"https://github.com/jif-oai\">@jif-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11494\">#11494</a> Increased file watcher debounce duration from 1s to 10s <a class=\"user-mention notranslate\" href=\"https://github.com/etraut-openai\">@etraut-openai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11335\">#11335</a> Add AfterToolUse hook <a class=\"user-mention notranslate\" href=\"https://github.com/gt-oai\">@gt-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11500\">#11500</a> feat: build windows support binaries in parallel <a class=\"user-mention notranslate\" href=\"https://github.com/bolinfest\">@bolinfest</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11290\">#11290</a> chore(tui) Simplify /status Permissions <a class=\"user-mention notranslate\" href=\"https://github.com/dylan-hurd-oai\">@dylan-hurd-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11503\">#11503</a> Make codex-sdk depend on openai/codex <a class=\"user-mention notranslate\" href=\"https://github.com/pakrym-oai\">@pakrym-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11474\">#11474</a> app-server: thread resume subscriptions <a class=\"user-mention notranslate\" href=\"https://github.com/maxj-oai\">@maxj-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11277\">#11277</a> Added seatbelt policy rule to allow os.cpus <a class=\"user-mention notranslate\" href=\"https://github.com/etraut-openai\">@etraut-openai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11506\">#11506</a> chore: inject originator/residency headers to ws client <a class=\"user-mention notranslate\" href=\"https://github.com/apanasenko-oai\">@apanasenko-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11497\">#11497</a> Hydrate previous model across resume/fork/rollback/task start <a class=\"user-mention notranslate\" href=\"https://github.com/aibrahim-oai\">@aibrahim-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11513\">#11513</a> feat: try to fix bugs I saw in the wild in the resource parsing logic <a class=\"user-mention notranslate\" href=\"https://github.com/bolinfest\">@bolinfest</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11509\">#11509</a> Consolidate search_tool feature into apps <a class=\"user-mention notranslate\" href=\"https://github.com/apanasenko-oai\">@apanasenko-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11388\">#11388</a> change model cap to server overload <a class=\"user-mention notranslate\" href=\"https://github.com/willwang-openai\">@willwang-openai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11504\">#11504</a> Pre-sampling compact with previous model context <a class=\"user-mention notranslate\" href=\"https://github.com/aibrahim-oai\">@aibrahim-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11516\">#11516</a> Clamp auto-compact limit to context window <a class=\"user-mention notranslate\" href=\"https://github.com/aibrahim-oai\">@aibrahim-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11520\">#11520</a> Update context window after model switch <a class=\"user-mention notranslate\" href=\"https://github.com/aibrahim-oai\">@aibrahim-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11519\">#11519</a> Use slug in tui <a class=\"user-mention notranslate\" href=\"https://github.com/pakrym-oai\">@pakrym-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11522\">#11522</a> fix: add --test_verbose_timeout_warnings to bazel.yml <a class=\"user-mention notranslate\" href=\"https://github.com/bolinfest\">@bolinfest</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11526\">#11526</a> fix: remove errant Cargo.lock files <a class=\"user-mention notranslate\" href=\"https://github.com/bolinfest\">@bolinfest</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11521\">#11521</a> test(app-server): stabilize app/list thread feature-flag test by using file-backed MCP OAuth creds <a class=\"user-mention notranslate\" href=\"https://github.com/bolinfest\">@bolinfest</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11387\">#11387</a> feat: make sandbox read access configurable with <code>ReadOnlyAccess</code> <a class=\"user-mention notranslate\" href=\"https://github.com/bolinfest\">@bolinfest</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11486\">#11486</a> [apps] Allow Apps SDK apps. <a class=\"user-mention notranslate\" href=\"https://github.com/mzeng-openai\">@mzeng-openai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11532\">#11532</a> fix compilation <a class=\"user-mention notranslate\" href=\"https://github.com/sayan-oai\">@sayan-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11531\">#11531</a> Teach codex to test itself <a class=\"user-mention notranslate\" href=\"https://github.com/pakrym-oai\">@pakrym-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11540\">#11540</a> ci: remove actions/cache from rust release workflows <a class=\"user-mention notranslate\" href=\"https://github.com/bolinfest\">@bolinfest</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11542\">#11542</a> ci(windows): use DotSlash for zstd in rust-release-windows <a class=\"user-mention notranslate\" href=\"https://github.com/bolinfest\">@bolinfest</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11498\">#11498</a> build(linux-sandbox): always compile vendored bubblewrap on Linux; remove CODEX_BWRAP_ENABLE_FFI <a class=\"user-mention notranslate\" href=\"https://github.com/viyatb-oai\">@viyatb-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11545\">#11545</a> fix: make project_doc skill-render tests deterministic <a class=\"user-mention notranslate\" href=\"https://github.com/bolinfest\">@bolinfest</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11543\">#11543</a> ci: capture cargo timings in Rust CI and release workflows <a class=\"user-mention notranslate\" href=\"https://github.com/bolinfest\">@bolinfest</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11539\">#11539</a> Bump rmcp to 0.15 <a class=\"user-mention notranslate\" href=\"https://github.com/gpeal\">@gpeal</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11548\">#11548</a> Hide the first websocket retry <a class=\"user-mention notranslate\" href=\"https://github.com/pakrym-oai\">@pakrym-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11551\">#11551</a> Add logs to model cache <a class=\"user-mention notranslate\" href=\"https://github.com/aibrahim-oai\">@aibrahim-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11556\">#11556</a> Fix rust-release failures in musl linking and release asset upload <a class=\"user-mention notranslate\" href=\"https://github.com/bolinfest\">@bolinfest</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11558\">#11558</a> Handle response.incomplete <a class=\"user-mention notranslate\" href=\"https://github.com/pakrym-oai\">@pakrym-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11557\">#11557</a> fix: stop inheriting rate-limit limit_name <a class=\"user-mention notranslate\" href=\"https://github.com/xl-openai\">@xl-openai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11564\">#11564</a> rust-release: exclude cargo-timing.html from release assets <a class=\"user-mention notranslate\" href=\"https://github.com/bolinfest\">@bolinfest</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11546\">#11546</a> fix: update memory writing prompt <a class=\"user-mention notranslate\" href=\"https://github.com/zuxin-oai\">@zuxin-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11448\">#11448</a> Fix test flake <a class=\"user-mention notranslate\" href=\"https://github.com/gt-oai\">@gt-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11569\">#11569</a> feat: mem slash commands <a class=\"user-mention notranslate\" href=\"https://github.com/jif-oai\">@jif-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11573\">#11573</a> Fix flaky pre_sampling_compact switch test <a class=\"user-mention notranslate\" href=\"https://github.com/jif-oai\">@jif-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11571\">#11571</a> feat: mem drop cot <a class=\"user-mention notranslate\" href=\"https://github.com/jif-oai\">@jif-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11572\">#11572</a> Ensure list_threads drops stale rollout files <a class=\"user-mention notranslate\" href=\"https://github.com/jif-oai\">@jif-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11575\">#11575</a> fix: db stuff mem <a class=\"user-mention notranslate\" href=\"https://github.com/jif-oai\">@jif-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11581\">#11581</a> nit: upgrade DB version <a class=\"user-mention notranslate\" href=\"https://github.com/jif-oai\">@jif-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11577\">#11577</a> feat: truncate with model infos <a class=\"user-mention notranslate\" href=\"https://github.com/jif-oai\">@jif-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11590\">#11590</a> chore: clean consts <a class=\"user-mention notranslate\" href=\"https://github.com/jif-oai\">@jif-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11593\">#11593</a> feat: metrics to memories <a class=\"user-mention notranslate\" href=\"https://github.com/jif-oai\">@jif-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11579\">#11579</a> Fix config test on macOS <a class=\"user-mention notranslate\" href=\"https://github.com/gt-oai\">@gt-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11600\">#11600</a> feat: add sanitizer to redact secrets <a class=\"user-mention notranslate\" href=\"https://github.com/jif-oai\">@jif-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11609\">#11609</a> chore: drop mcp validation of dynamic tools <a class=\"user-mention notranslate\" href=\"https://github.com/jif-oai\">@jif-oai</a></li>\n</ul>",
    "image_url": "",
    "published": "2026-02-12T18:30:23Z",
    "collected_at": "2026-02-16T11:51:03.566250+00:00",
    "v2_slot": "agent_tooling_releases",
    "freshness": 0.203,
    "source_reliability": 1.0,
    "v2_prefilter_score": 3.403,
    "type": "release",
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "New Features Added an experimental, feature-gated JavaScript REPL runtime ( js_repl ) that can persist state across tool calls, with optional runtime path overrides. ( #10674 ) Added support for multiple simultaneous...",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.35,
    "v2_source_bias": 0.0,
    "v2_topical_bias": 0.2,
    "v2_final_score": 1.906,
    "summary_1line": "Claude Code 0.100.0 adds JS REPL runtime, multi-rate-limit support, websocket stability fixes, and sandbox promotion for Linux/Windows production deployments.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.34,
    "v2_global_score": 2.246
  },
  {
    "id": "f70833bd2f581c75",
    "source": "claude_code_releases",
    "source_weight": 2.2,
    "title": "v2.1.41",
    "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.41",
    "summary": "<h2>What's changed</h2>\n<ul>\n<li>Fixed AWS auth refresh hanging indefinitely by adding a 3-minute timeout</li>\n<li>Added <code>claude auth login</code>, <code>claude auth status</code>, and <code>claude auth logout</code> CLI subcommands</li>\n<li>Added Windows ARM64 (win32-arm64) native binary support</li>\n<li>Improved <code>/rename</code> to auto-generate session name from conversation context when called without arguments</li>\n<li>Improved narrow terminal layout for prompt footer</li>\n<li>Fixed file resolution failing for @-mentions with anchor fragments (e.g., <code>@README.md#installation</code>)</li>\n<li>Fixed FileReadTool blocking the process on FIFOs, <code>/dev/stdin</code>, and large files</li>\n<li>Fixed background task notifications not being delivered in streaming Agent SDK mode</li>\n<li>Fixed cursor jumping to end on each keystroke in classifier rule input</li>\n<li>Fixed markdown link display text being dropped for raw URL</li>\n<li>Fixed auto-compact failure error notifications being shown to users</li>\n<li>Fixed permission wait time being included in subagent elapsed time display</li>\n<li>Fixed proactive ticks firing while in plan mode</li>\n<li>Fixed clear stale permission rules when settings change on disk</li>\n<li>Fixed hook blocking errors showing stderr content in UI</li>\n</ul>",
    "image_url": "",
    "published": "2026-02-13T06:08:49Z",
    "collected_at": "2026-02-16T11:51:03.566250+00:00",
    "v2_slot": "agent_tooling_releases",
    "freshness": 0.25,
    "source_reliability": 1.0,
    "v2_prefilter_score": 3.45,
    "type": "release",
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "What's changed Fixed AWS auth refresh hanging indefinitely by adding a 3-minute timeout Added claude auth login , claude auth status , and claude auth logout CLI subcommands Added Windows ARM64 (win32-arm64) native bi...",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.0,
    "v2_source_bias": 0.0,
    "v2_topical_bias": 0.2,
    "v2_final_score": 1.675,
    "summary_1line": "Claude Code v2.1.41 ships auth stability fixes, Windows ARM64 support, and Agent SDK streaming improvements for production reliability.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.34,
    "v2_global_score": 2.015
  },
  {
    "id": "df23a683c09c1437",
    "source": "langgraph_releases",
    "source_weight": 0.95,
    "title": "langgraph-sdk==0.3.6",
    "url": "https://github.com/langchain-ai/langgraph/releases/tag/sdk%3D%3D0.3.6",
    "summary": "<p>Changes since sdk==0.3.5</p>\n<ul>\n<li>release(sdk-py): 0.3.6 (<a class=\"issue-link js-issue-link\" href=\"https://github.com/langchain-ai/langgraph/pull/6805\">#6805</a>)</li>\n<li>chore: update to add prune method (<a class=\"issue-link js-issue-link\" href=\"https://github.com/langchain-ai/langgraph/pull/6804\">#6804</a>)</li>\n<li>chore: Re-organize client files. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/langchain-ai/langgraph/pull/6787\">#6787</a>)</li>\n</ul>",
    "image_url": "",
    "published": "2026-02-14T19:46:16Z",
    "collected_at": "2026-02-16T11:51:03.566250+00:00",
    "v2_slot": "agent_tooling_releases",
    "freshness": 0.489,
    "source_reliability": 1.0,
    "v2_prefilter_score": 2.439,
    "type": "release",
    "llm_label_source": "heuristic",
    "llm_category": "platform",
    "llm_summary_1line": "Changes since sdk==0.3.5 release(sdk-py): 0.3.6 ( #6805 ) chore: update to add prune method ( #6804 ) chore: Re-organize client files. ( #6787 )",
    "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_llm_score": 2.0,
    "v2_source_bias": 0.06,
    "v2_topical_bias": 0.0,
    "v2_final_score": 1.607,
    "summary_1line": "LangGraph SDK 0.3.6 adds prune method and reorganizes client files; minimal release notes.",
    "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
    "v2_slot_priority": 0.34,
    "v2_global_score": 1.947
  }
]