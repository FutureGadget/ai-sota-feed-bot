{
  "run_at": "2026-02-17T16:04:36.122304+00:00",
  "item_count": 14,
  "items": [
    {
      "id": "1801a1e24942383b",
      "source": "simon_willison",
      "source_weight": 1.25,
      "title": "Qwen3.5: Towards Native Multimodal Agents",
      "url": "https://simonwillison.net/2026/Feb/17/qwen35/#atom-everything",
      "summary": "<p><strong><a href=\"https://qwen.ai/blog?id=qwen3.5\">Qwen3.5: Towards Native Multimodal Agents</a></strong></p>\nAlibaba's Qwen just released the first two models in the Qwen 3.5 series - one open weights, one proprietary. Both are multi-modal for vision input.</p>\n<p>The open weight one is a Mixture of Experts model called Qwen3.5-397B-A17B. Interesting to see Qwen call out serving efficiency as a benefit of that architecture:</p>\n<blockquote>\n<p>Built on an innovative hybrid architecture that fuses linear attention (via Gated Delta Networks) with a sparse mixture-of-experts, the model attains remarkable inference efficiency: although it comprises 397 billion total parameters, just 17 billion are activated per forward pass, optimizing both speed and cost without sacrificing capability.</p>\n</blockquote>\n<p>It's <a href=\"https://huggingface.co/Qwen/Qwen3.5-397B-A17B\">807GB on Hugging Face</a>, and Unsloth have a <a href=\"https://huggingface.co/unsloth/Qwen3.5-397B-A17B-GGUF\">collection of smaller GGUFs</a> ranging in size from 94.2GB 1-bit to 462GB Q8_K_XL.</p>\n<p>I got this <a href=\"https://simonwillison.net/tags/pelican-riding-a-bicycle/\">pelican</a> from the <a href=\"https://openrouter.ai/qwen/qwen3.5-397b-a17b\">OpenRouter hosted model</a> (<a href=\"https://gist.github.com/simonw/625546cf6b371f9c0040e64492943b82\">transcript</a>):</p>\n<p><img alt=\"Pelican is quite good although the neck lacks an outline for some reason. Bicycle is very basic with an incomplete frame\" src=\"https://static.simonwillison.net/static/2026/qwen3.5-397b-a17b.png\" /></p>\n<p>The proprietary hosted model is called Qwen3.5 Plus 2026-02-15, and is a little confusing. Qwen researcher <a href=\"https://twitter.com/JustinLin610/status/2023340126479569140\">Junyang Lin  says</a>:</p>\n<blockquote>\n<p>Qwen3-Plus is a hosted API version of 397B. As the model natively supports 256K tokens, Qwen3.5-Plus supports 1M token context length. Additionally it supports search and code interpreter, which you can use on Qwen Chat with Auto mode.</p>\n</blockquote>\n<p>Here's <a href=\"https://gist.github.com/simonw/9507dd47483f78dc1195117735273e20\">its pelican</a>, which is similar in quality to the open weights model:</p>\n<p><img alt=\"Similar quality pelican. The bicycle is taller and has a better frame shape. They are visually quite similar.\" src=\"https://static.simonwillison.net/static/2026/qwen3.5-plus-02-15.png\" />\n\n\n    <p>Tags: <a href=\"https://simonwillison.net/tags/ai\">ai</a>, <a href=\"https://simonwillison.net/tags/generative-ai\">generative-ai</a>, <a href=\"https://simonwillison.net/tags/llms\">llms</a>, <a href=\"https://simonwillison.net/tags/vision-llms\">vision-llms</a>, <a href=\"https://simonwillison.net/tags/qwen\">qwen</a>, <a href=\"https://simonwillison.net/tags/pelican-riding-a-bicycle\">pelican-riding-a-bicycle</a>, <a href=\"https://simonwillison.net/tags/llm-release\">llm-release</a>, <a href=\"https://simonwillison.net/tags/openrouter\">openrouter</a>, <a href=\"https://simonwillison.net/tags/ai-in-china\">ai-in-china</a></p>",
      "image_url": "https://static.simonwillison.net/static/2026/qwen3.5-397b-a17b.png",
      "published": "2026-02-17T04:30:57+00:00",
      "collected_at": "2026-02-17T16:04:11.757824+00:00",
      "v2_slot": "practitioner_analysis",
      "freshness": 0.749,
      "source_reliability": 1.0,
      "v2_prefilter_score": 2.999,
      "type": "news",
      "llm_label_source": "heuristic",
      "llm_category": "platform",
      "llm_summary_1line": "Qwen3.5: Towards Native Multimodal Agents Alibaba's Qwen just released the first two models in the Qwen 3.5 series - one open weights, one proprietary. Both are multi-modal for vision input. The open weight one is a M...",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.8,
      "v2_source_bias": 0.08,
      "v2_topical_bias": 0.2,
      "v2_final_score": 2.772,
      "summary_1line": "Qwen3.5: Towards Native Multimodal Agents Alibaba's Qwen just released the first two models in the Qwen 3.5 series - one open weights, one proprietary. Both are multi-modal for vision input. The open weight one is a M...",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.571,
      "v2_global_score": 3.343
    },
    {
      "id": "0b9784e78fa0f8a8",
      "source": "simon_willison",
      "source_weight": 1.25,
      "title": "Two new Showboat tools: Chartroom and datasette-showboat",
      "url": "https://simonwillison.net/2026/Feb/17/chartroom-and-datasette-showboat/#atom-everything",
      "summary": "<p>I <a href=\"https://simonwillison.net/2026/Feb/10/showboat-and-rodney/\">introduced Showboat</a> a week ago - my CLI tool that helps coding agents create Markdown documents that demonstrate the code that they have created. I've been finding new ways to use it on a daily basis, and I've just released two new tools to help get the best out of the Showboat pattern. <a href=\"https://github.com/simonw/chartroom\">Chartroom</a> is a CLI charting tool that works well with Showboat, and <a href=\"https://github.com/simonw/datasette-showboat\">datasette-showboat</a> lets Showboat's new remote publishing feature incrementally push documents to a Datasette instance.</p>\n\n<ul>\n  <li><a href=\"https://simonwillison.net/2026/Feb/17/chartroom-and-datasette-showboat/#showboat-remote-publishing\">Showboat remote publishing</a></li>\n  <li><a href=\"https://simonwillison.net/2026/Feb/17/chartroom-and-datasette-showboat/#datasette-showboat\">datasette-showboat</a></li>\n  <li><a href=\"https://simonwillison.net/2026/Feb/17/chartroom-and-datasette-showboat/#chartroom\">Chartroom</a></li>\n  <li><a href=\"https://simonwillison.net/2026/Feb/17/chartroom-and-datasette-showboat/#how-i-built-chartroom\">How I built Chartroom</a></li>\n  <li><a href=\"https://simonwillison.net/2026/Feb/17/chartroom-and-datasette-showboat/#the-burgeoning-showboat-ecosystem\">The burgeoning Showboat ecosystem</a></li>\n</ul>\n\n<h4 id=\"showboat-remote-publishing\">Showboat remote publishing</h4>\n<p>I normally use Showboat in Claude Code for web (see <a href=\"https://simonwillison.net/2026/Feb/16/rodney-claude-code/\">note from this morning</a>). I've used it in several different projects in the past few days, each of them with a prompt that looks something like this:</p>\n<blockquote>\n<p><code>Use \"uvx showboat --help\" to perform a very thorough investigation of what happens if you use the Python sqlite-chronicle and sqlite-history-json libraries against the same SQLite database table</code></p>\n</blockquote>\n<p>Here's <a href=\"https://github.com/simonw/research/blob/main/sqlite-chronicle-vs-history-json/demo.md\">the resulting document</a>.</p>\n<p>Just telling Claude Code to run <code>uvx showboat --help</code> is enough for it to learn how to use the tool - the <a href=\"https://github.com/simonw/showboat/blob/main/help.txt\">help text</a> is designed to work as a sort of ad-hoc Skill document.</p>\n<p>The one catch with this approach is that I can't <em>see</em> the new Showboat document until it's finished. I have to wait for Claude to commit the document plus embedded screenshots and push that to a branch in my GitHub repo - then I can view it through the GitHub interface.</p>\n<p>For a while I've been thinking it would be neat to have a remote web server of my own which Claude instances can submit updates to while they are working. Then this morning I realized Showboat might be the ideal mechanism to set that up...</p>\n<p>Showboat <a href=\"https://github.com/simonw/showboat/releases/tag/v0.6.0\">v0.6.0</a> adds a new \"remote\" feature. It's almost invisible to users of the tool itself, instead being configured by an environment variable.</p>\n<p>Set a variable like this:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">export</span> SHOWBOAT_REMOTE_URL=https://www.example.com/submit<span class=\"pl-k\">?</span>token=xyz</pre></div>\n<p>And every time you run a <code>showboat init</code> or <code>showboat note</code> or <code>showboat exec</code> or <code>showboat image</code> command the resulting document fragments will be POSTed to that API endpoint, in addition to the Showboat Markdown file itself being updated.</p>\n<p>There are <a href=\"https://github.com/simonw/showboat/blob/v0.6.0/README.md#remote-document-streaming\">full details in the Showboat README</a> - it's a very simple API format, using regular POST form variables or a multipart form upload for the image attached to <code>showboat image</code>.</p>\n<h4 id=\"datasette-showboat\">datasette-showboat</h4>\n<p>It's simple enough to build a webapp to receive these updates from Showboat, but I needed one that I could easily deploy and would work well with the rest of my personal ecosystem.</p>\n<p>So I had Claude Code write me a Datasette plugin that could act as a Showboat remote endpoint. I actually had this building at the same time as the Showboat remote feature, a neat example of running <a href=\"https://simonwillison.net/2025/Oct/5/parallel-coding-agents/\">parallel agents</a>.</p>\n<p><strong><a href=\"https://github.com/simonw/datasette-showboat\">datasette-showboat</a></strong> is a Datasette plugin that adds a <code>/-/showboat</code> endpoint to Datasette for viewing documents and a <code>/-/showboat/receive</code> endpoint for receiving updates from Showboat.</p>\n<p>Here's a very quick way to try it out:</p>\n<div class=\"highlight highlight-source-shell\"><pre>uvx --with datasette-showboat --prerelease=allow \\\n  datasette showboat.db --create \\\n  -s plugins.datasette-showboat.database showboat \\\n  -s plugins.datasette-showboat.token secret123 \\\n  --root --secret cookie-secret-123</pre></div>\n<p>Click on the sign in as root link that shows up in the console, then navigate to <a href=\"http://127.0.0.1:8001/-/showboat\">http://127.0.0.1:8001/-/showboat</a> to see the interface.</p>\n<p>Now set your environment variable to point to this instance:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">export</span> SHOWBOAT_REMOTE_URL=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>http://127.0.0.1:8001/-/showboat/receive?token=secret123<span class=\"pl-pds\">\"</span></span></pre></div>\n<p>And run Showboat like this:</p>\n<div class=\"highlight highlight-source-shell\"><pre>uvx showboat init demo.md <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Showboat Feature Demo<span class=\"pl-pds\">\"</span></span></pre></div>\n<p>Refresh that page and you should see this:</p>\n<p><img alt=\"Title: Showboat. Remote viewer for Showboat documents. Showboat Feature Demo 2026-02-17 00:06 · 6 chunks, UUID. To send showboat output to this server, set the SHOWBOAT_REMOTE_URL environment variable: export SHOWBOAT_REMOTE_URL=&quot;http://127.0.0.1:8001/-/showboat/receive?token=your-token&quot;\" src=\"https://static.simonwillison.net/static/2026/datasette-showboat-documents.jpg\" /></p>\n<p>Click through to the document, then start Claude Code or Codex or your agent of choice and prompt:</p>\n<blockquote>\n<p><code>Run 'uvx showboat --help' and then use showboat to add to the existing demo.md document with notes and exec and image to demonstrate the tool - fetch a placekitten for the image demo.</code></p>\n</blockquote>\n<p>The <code>init</code> command assigns a UUID and title and sends those up to Datasette.</p>\n<p><img alt=\"Animated demo - in the foreground a terminal window runs Claude Code, which executes various Showboat commands. In the background a Firefox window where the Showboat Feature Demo adds notes then some bash commands, then a placekitten image.\" src=\"https://static.simonwillison.net/static/2026/datasette-showboat.gif\" /></p>\n<p>The best part of this is that it works in Claude Code for web. Run the plugin on a server somewhere (an exercise left up to the reader - I use <a href=\"https://fly.io/\">Fly.io</a> to host mine) and set that <code>SHOWBOAT_REMOTE_URL</code> environment variable in your Claude environment, then any time you tell it to use Showboat the document it creates will be transmitted to your server and viewable in real time.</p>\n<p>I built <a href=\"https://simonwillison.net/2026/Feb/10/showboat-and-rodney/#rodney-cli-browser-automation-designed-to-work-with-showboat\">Rodney</a>, a CLI browser automation tool, specifically to work with Showboat. It makes it easy to have a Showboat document load up web pages, interact with them via clicks or injected JavaScript and captures screenshots to embed in the Showboat document and show the effects.</p>\n<p>This is wildly useful for hacking on web interfaces using Claude Code for web, especially when coupled with the new remote publishing feature. I only got this stuff working this morning and I've already had several sessions where Claude Code has published screenshots of its work in progress, which I've then been able to provide feedback on directly in the Claude session while it's still working.</p>\n<h3 id=\"chartroom\">Chartroom</h3>\n<p>A few days ago I had another idea for a way to extend the Showboat ecosystem: what if Showboat documents could easily include charts?</p>\n<p>I sometimes fire up Claude Code for data analysis tasks, often telling it to download a SQLite database and then run queries against it to figure out interesting things from the data.</p>\n<p>With a simple CLI tool that produced PNG images I could have Claude use Showboat to build a document with embedded charts to help illustrate its findings.</p>\n<p><strong><a href=\"https://github.com/simonw/chartroom\">Chartroom</a></strong> is exactly that. It's effectively a thin wrapper around the excellent <a href=\"https://matplotlib.org/\">matplotlib</a> Python library, designed to be used by coding agents to create charts that can be embedded in Showboat documents.</p>\n<p>Here's how to render a simple bar chart:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c1\">echo</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>name,value</span>\n<span class=\"pl-s\">Alice,42</span>\n<span class=\"pl-s\">Bob,28</span>\n<span class=\"pl-s\">Charlie,35</span>\n<span class=\"pl-s\">Diana,51</span>\n<span class=\"pl-s\">Eve,19<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">|</span> uvx chartroom bar --csv \\\n  --title <span class=\"pl-s\"><span class=\"pl-pds\">'</span>Sales by Person<span class=\"pl-pds\">'</span></span> --ylabel <span class=\"pl-s\"><span class=\"pl-pds\">'</span>Sales<span class=\"pl-pds\">'</span></span></pre></div>\n<p><a href=\"https://raw.githubusercontent.com/simonw/chartroom/8812afc02e1310e9eddbb56508b06005ff2c0ed5/demo/1f6851ec-2026-02-14.png\" rel=\"noopener noreferrer nofollow\" target=\"_blank\"><img alt=\"A chart of those numbers, with a title and y-axis label\" src=\"https://raw.githubusercontent.com/simonw/chartroom/8812afc02e1310e9eddbb56508b06005ff2c0ed5/demo/1f6851ec-2026-02-14.png\" /></a></p>\n<p>It can also do line charts, bar charts, scatter charts, and histograms - as seen in <a href=\"https://github.com/simonw/chartroom/blob/0.2.1/demo/README.md\">this demo document</a> that was built using Showboat.</p>\n<p>Chartroom can also generate alt text. If you add <code>-f alt</code> to the above it will output the alt text for the chart instead of the image:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c1\">echo</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>name,value</span>\n<span class=\"pl-s\">Alice,42</span>\n<span class=\"pl-s\">Bob,28</span>\n<span class=\"pl-s\">Charlie,35</span>\n<span class=\"pl-s\">Diana,51</span>\n<span class=\"pl-s\">Eve,19<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">|</span> uvx chartroom bar --csv \\\n  --title <span class=\"pl-s\"><span class=\"pl-pds\">'</span>Sales by Person<span class=\"pl-pds\">'</span></span> --ylabel <span class=\"pl-s\"><span class=\"pl-pds\">'</span>Sales<span class=\"pl-pds\">'</span></span> -f alt</pre></div>\n<p>Outputs:</p>\n<pre><code>Sales by Person. Bar chart of value by name — Alice: 42, Bob: 28, Charlie: 35, Diana: 51, Eve: 19\n</code></pre>\n<p>Or you can use <code>-f html</code> or <code>-f markdown</code> to get the image tag with alt text directly:</p>\n<div class=\"highlight highlight-text-md\"><pre><span class=\"pl-s\">![</span>Sales by Person. Bar chart of value by name — Alice: 42, Bob: 28, Charlie: 35, Diana: 51, Eve: 19<span class=\"pl-s\">]</span><span class=\"pl-s\">(</span><span class=\"pl-corl\">/Users/simon/chart-7.png</span><span class=\"pl-s\">)</span></pre></div>\n<p>I added support for Markdown images with alt text to Showboat in <a href=\"https://github.com/simonw/showboat/releases/tag/v0.5.0\">v0.5.0</a>, to complement this feature of Chartroom.</p>\n<p>Finally, Chartroom has support for different <a href=\"https://matplotlib.org/stable/gallery/style_sheets/style_sheets_reference.html\">matplotlib styles</a>. I had Claude build a Showboat document to demonstrate these all in one place - you can see that at <a href=\"https://github.com/simonw/chartroom/blob/main/demo/styles.md\">demo/styles.md</a>.</p>\n<h4 id=\"how-i-built-chartroom\">How I built Chartroom</h4>\n<p>I started the Chartroom repository with my <a href=\"https://github.com/simonw/click-app\">click-app</a> cookiecutter template, then told a fresh Claude Code for web session:</p>\n<blockquote>\n<p>We are building a Python CLI tool which uses matplotlib to generate a PNG image containing a chart. It will have multiple sub commands for different chart types, controlled by command line options. Everything you need to know to use it will be available in the single \"chartroom --help\" output.</p>\n<p>It will accept data from files or standard input as CSV or TSV or JSON, similar to how sqlite-utils accepts data - clone simonw/sqlite-utils to /tmp for reference there. Clone matplotlib/matplotlib for reference as well</p>\n<p>It will also accept data from --sql path/to/sqlite.db \"select ...\" which runs in read-only mode</p>\n<p>Start by asking clarifying questions - do not use the ask user tool though it is broken - and generate a spec for me to approve</p>\n<p>Once approved proceed using red/green TDD running tests with \"uv run pytest\"</p>\n<p>Also while building maintain a demo/README.md document using the \"uvx showboat --help\" tool - each time you get a new chart type working commit the tests, implementation, root level\nREADME update and a new version of that demo/README.md document with an inline image demo of the new chart type (which should be a UUID image filename managed by the showboat image command and should be stored in the demo/ folder</p>\n<p>Make sure \"uv build\" runs cleanly without complaining about extra directories but also ensure dist/ and uv.lock are in gitignore</p>\n</blockquote>\n<p>This got most of the work done. You can see the rest <a href=\"https://github.com/simonw/chartroom/pulls?q=is%3Apr+is%3Aclosed\">in the PRs</a> that followed.</p>\n<h4 id=\"the-burgeoning-showboat-ecosystem\">The burgeoning Showboat ecosystem</h4>\n<p>The Showboat family of tools now consists of <a href=\"https://github.com/simonw/showboat\">Showboat</a> itself, <a href=\"https://github.com/simonw/rodney\">Rodney</a> for browser automation, <a href=\"https://github.com/simonw/chartroom\">Chartroom</a> for charting and <a href=\"https://github.com/simonw/datasette-showboat\">datasette-showboat</a> for streaming remote Showboat documents to Datasette.</p>\n<p>I'm enjoying how these tools can operate together based on a very loose set of conventions. If a tool can output a path to an image Showboat can include that image in a document. Any tool that can output text can be used with Showboat.</p>\n<p>I'll almost certainly be building more tools that fit this pattern. They're very quick to knock out!</p>\n<p>The environment variable mechanism for Showboat's remote streaming is a fun hack too - so far I'm just using it to stream documents somewhere else, but it's effectively a webhook extension mechanism that could likely be used for all sorts of things I haven't thought of yet.</p>\n    \n        <p>Tags: <a href=\"https://simonwillison.net/tags/charting\">charting</a>, <a href=\"https://simonwillison.net/tags/projects\">projects</a>, <a href=\"https://simonwillison.net/tags/ai\">ai</a>, <a href=\"https://simonwillison.net/tags/datasette\">datasette</a>, <a href=\"https://simonwillison.net/tags/generative-ai\">generative-ai</a>, <a href=\"https://simonwillison.net/tags/llms\">llms</a>, <a href=\"https://simonwillison.net/tags/ai-assisted-programming\">ai-assisted-programming</a>, <a href=\"https://simonwillison.net/tags/coding-agents\">coding-agents</a>, <a href=\"https://simonwillison.net/tags/claude-code\">claude-code</a>, <a href=\"https://simonwillison.net/tags/showboat\">showboat</a></p>",
      "image_url": "https://static.simonwillison.net/static/2026/datasette-showboat-documents.jpg",
      "published": "2026-02-17T00:43:45+00:00",
      "collected_at": "2026-02-17T16:04:11.757824+00:00",
      "v2_slot": "practitioner_analysis",
      "freshness": 0.681,
      "source_reliability": 1.0,
      "v2_prefilter_score": 2.931,
      "type": "news",
      "llm_label_source": "heuristic",
      "llm_category": "platform",
      "llm_summary_1line": "I introduced Showboat a week ago - my CLI tool that helps coding agents create Markdown documents that demonstrate the code that they have created. I've been finding new ways to use it on a daily basis, and I've just...",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.75,
      "v2_source_bias": 0.08,
      "v2_topical_bias": 0.2,
      "v2_final_score": 2.72,
      "summary_1line": "I introduced Showboat a week ago - my CLI tool that helps coding agents create Markdown documents that demonstrate the code that they have created. I've been finding new ways to use it on a daily basis, and I've just...",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.571,
      "v2_global_score": 3.291
    },
    {
      "id": "2cef63a7c25d947d",
      "source": "infoq_ai_ml",
      "source_weight": 1.15,
      "title": "Moonshot AI Releases Open-Weight Kimi K2.5 Model with Vision and Agent Swarm Capabilities",
      "url": "https://www.infoq.com/news/2026/02/kimi-k25-swarm/?utm_campaign=infoq_content&utm_source=infoq&utm_medium=feed&utm_term=AI%2C+ML+%26+Data+Engineering",
      "summary": "<img src=\"https://res.infoq.com/news/2026/02/kimi-k25-swarm/en/headerimage/generatedHeaderImage-1771079384813.jpg\" /><p>Moonshot AI released Kimi K2.5, their latest open-weight multimodal LLM. K2.5 excels at coding tasks, with benchmark scores comparable to frontier models such as GPT-5 and Gemini. It also features an agent swarm mode, which can direct up to 100 sub-agents for attacking problems with parallel workflow.</p> <i>By Anthony Alford</i>",
      "image_url": "https://res.infoq.com/news/2026/02/kimi-k25-swarm/en/headerimage/generatedHeaderImage-1771079384813.jpg",
      "published": "Tue, 17 Feb 2026 14:00:00 GMT",
      "collected_at": "2026-02-17T16:04:11.757824+00:00",
      "v2_slot": "practitioner_analysis",
      "freshness": 0.949,
      "source_reliability": 1.0,
      "v2_prefilter_score": 3.099,
      "type": "release",
      "llm_label_source": "heuristic",
      "llm_category": "platform",
      "llm_summary_1line": "Moonshot AI released Kimi K2.5, their latest open-weight multimodal LLM. K2.5 excels at coding tasks, with benchmark scores comparable to frontier models such as GPT-5 and Gemini. It also features an agent swarm mode,...",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.6,
      "v2_source_bias": 0.08,
      "v2_topical_bias": 0.2,
      "v2_final_score": 2.632,
      "summary_1line": "Moonshot AI released Kimi K2.5, their latest open-weight multimodal LLM. K2.5 excels at coding tasks, with benchmark scores comparable to frontier models such as GPT-5 and Gemini. It also features an agent swarm mode,...",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.571,
      "v2_global_score": 3.203
    },
    {
      "id": "3f5e03016b1baa5d",
      "source": "infoq_ai_ml",
      "source_weight": 1.15,
      "title": "Does AI Make the Agile Manifesto Obsolete?",
      "url": "https://www.infoq.com/news/2026/02/ai-agile-manifesto-debate/?utm_campaign=infoq_content&utm_source=infoq&utm_medium=feed&utm_term=AI%2C+ML+%26+Data+Engineering",
      "summary": "<img src=\"https://res.infoq.com/news/2026/02/ai-agile-manifesto-debate/en/headerimage/generatedHeaderImage-1770724261142.jpg\" /><p>Capgemini's Steve Jones argues AI agents building apps in hours have killed the Agile Manifesto, as its human-centric principles don't fit agentic SDLCs. While Forrester reports 95% still find Agile relevant, Kent Beck proposes \"augmented coding\" and AWS suggests \"Intent Design\" over sprint planning. The debate: Is Agile dead, or evolving for AI collaboration?</p> <i>By Steef-Jan Wiggers</i>",
      "image_url": "https://res.infoq.com/news/2026/02/ai-agile-manifesto-debate/en/headerimage/generatedHeaderImage-1770724261142.jpg",
      "published": "Tue, 17 Feb 2026 10:34:00 GMT",
      "collected_at": "2026-02-17T16:04:11.757824+00:00",
      "v2_slot": "practitioner_analysis",
      "freshness": 0.871,
      "source_reliability": 1.0,
      "v2_prefilter_score": 3.021,
      "type": "news",
      "llm_label_source": "heuristic",
      "llm_category": "platform",
      "llm_summary_1line": "Capgemini's Steve Jones argues AI agents building apps in hours have killed the Agile Manifesto, as its human-centric principles don't fit agentic SDLCs. While Forrester reports 95% still find Agile relevant, Kent Bec...",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.2,
      "v2_source_bias": 0.08,
      "v2_topical_bias": 0.2,
      "v2_final_score": 2.281,
      "summary_1line": "Capgemini's Steve Jones argues AI agents building apps in hours have killed the Agile Manifesto, as its human-centric principles don't fit agentic SDLCs. While Forrester reports 95% still find Agile relevant, Kent Bec...",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.571,
      "v2_global_score": 2.852
    },
    {
      "id": "a311197adc8a5fb3",
      "source": "arxiv_cs_ai",
      "source_weight": 0.85,
      "title": "Hunt Globally: Deep Research AI Agents for Drug Asset Scouting in Investing, Business Development, and Search & Evaluation",
      "url": "http://arxiv.org/abs/2602.15019v1",
      "summary": "Bio-pharmaceutical innovation has shifted: many new drug assets now originate outside the United States and are disclosed primarily via regional, non-English channels. Recent data suggests >85% of patent filings originate outside the U.S., with China accounting for nearly half of the global total; a growing share of scholarly output is also non-U.S. Industry estimates put China at ~30% of global drug development, spanning 1,200+ novel candidates. In this high-stakes environment, failing to surface \"under-the-radar\" assets creates multi-billion-dollar risk for investors and business development teams, making asset scouting a coverage-critical competition where speed and completeness drive value. Yet today's Deep Research AI agents still lag human experts in achieving high-recall discovery across heterogeneous, multilingual sources without hallucinations.\n  We propose a benchmarking methodology for drug asset scouting and a tuned, tree-based self-learning Bioptic Agent aimed at complete, non-hallucinated scouting. We construct a challenging completeness benchmark using a multilingual multi-agent pipeline: complex user queries paired with ground-truth assets that are largely outside U.S.-centric radar. To reflect real deal complexity, we collected screening queries from expert investors, BD, and VC professionals and used them as priors to conditionally generate benchmark queries. For grading, we use LLM-as-judge evaluation calibrated to expert opinions. We compare Bioptic Agent against Claude Opus 4.6, OpenAI GPT-5.2 Pro, Perplexity Deep Research, Gemini 3 Pro + Deep Research, and Exa Websets. Bioptic Agent achieves 79.7% F1 versus 56.2% (Claude Opus 4.6), 50.6% (Gemini 3 Pro + Deep Research), 46.6% (GPT-5.2 Pro), 44.2% (Perplexity Deep Research), and 26.9% (Exa Websets). Performance improves steeply with additional compute, supporting the view that more compute yields better results.",
      "image_url": "",
      "published": "2026-02-16T18:57:49Z",
      "collected_at": "2026-02-17T16:04:11.757824+00:00",
      "v2_slot": "research_watch",
      "freshness": 0.828,
      "source_reliability": 1.0,
      "v2_prefilter_score": 2.678,
      "type": "paper",
      "llm_label_source": "heuristic",
      "llm_category": "platform",
      "llm_summary_1line": "Bio-pharmaceutical innovation has shifted: many new drug assets now originate outside the United States and are disclosed primarily via regional, non-English channels. Recent data suggests >85% of patent filings origi...",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.85,
      "v2_source_bias": -0.35,
      "v2_topical_bias": 0.2,
      "v2_final_score": 2.397,
      "summary_1line": "Bio-pharmaceutical innovation has shifted: many new drug assets now originate outside the United States and are disclosed primarily via regional, non-English channels. Recent data suggests 85% of patent filings origi...",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.357,
      "v2_global_score": 2.754
    },
    {
      "id": "d8406899d0636aaf",
      "source": "hackernews_ai",
      "source_weight": 1.1,
      "title": "Show HN: Broomy – Open-source app for working with many AI agents at once",
      "url": "https://broomy.org/",
      "summary": "<p>Hi HN, I'm Rob. I built Broomy because I got frustrated with the one-thing-at-a-time workflow of existing coding tools.<p>When I work with AI coding agents, I typically have 5-10 tasks going at once across different branches. The agent works on one thing while I review another, merge a third, and kick off a fourth. Existing IDEs aren't built for this — they assume you're doing one thing at a time.<p>Broomy is a desktop app (Electron + React) that lets you:<p>- Run lots of agent sessions simultaneously and see at a glance which are working, idle, or need your attention\n- Work with any terminal-based agent (Claude Code, Aider, Codex, etc.)\n- Review code, manage branches, and handle merges with AI assistance\n- Use built-in IDE features (Monaco editor, file explorer, git integration, inline terminals) — all designed around multi-agent workflows<p>I've been using it daily for a few weeks and my productivity has dramatically improved compared to working in Cursor. The key insight is that most of the time you spend \"coding with AI\" is actually waiting — and Broomy lets you fill that wait time with other tasks.<p>This is a first public release (v0.6.0). Pre-built binaries are available for macOS. It should work on Linux and Windows too — build from source is straightforward (clone, pnpm install, pnpm start:dist).<p>MIT licensed. Built as a personal project, not affiliated with my employer.<p>Repo: <a href=\"https://github.com/Broomy-AI/broomy\" rel=\"nofollow\">https://github.com/Broomy-AI/broomy</a>\nWebsite: <a href=\"https://broomy.org\" rel=\"nofollow\">https://broomy.org</a><p>Happy to answer questions.</p>\n<hr />\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47048886\">https://news.ycombinator.com/item?id=47048886</a></p>\n<p>Points: 1</p>\n<p># Comments: 0</p>",
      "image_url": "",
      "published": "Tue, 17 Feb 2026 15:55:38 +0000",
      "collected_at": "2026-02-17T16:04:11.757824+00:00",
      "v2_slot": "community_signal",
      "freshness": 0.991,
      "source_reliability": 1.0,
      "v2_prefilter_score": 3.091,
      "type": "news",
      "llm_label_source": "heuristic",
      "llm_category": "platform",
      "llm_summary_1line": "Hi HN, I'm Rob. I built Broomy because I got frustrated with the one-thing-at-a-time workflow of existing coding tools. When I work with AI coding agents, I typically have 5-10 tasks going at once across different bra...",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.35,
      "v2_source_bias": 0.0,
      "v2_topical_bias": 0.2,
      "v2_final_score": 2.21,
      "summary_1line": "Hi HN, I'm Rob. I built Broomy because I got frustrated with the one-thing-at-a-time workflow of existing coding tools. When I work with AI coding agents, I typically have 5-10 tasks going at once across different bra...",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.483,
      "v2_global_score": 2.693
    },
    {
      "id": "c8740b36f03df678",
      "source": "anthropic_newsroom",
      "source_weight": 1.8,
      "title": "Anthropic Rwanda Mou",
      "url": "https://www.anthropic.com/news/anthropic-rwanda-mou",
      "summary": "",
      "image_url": "",
      "published": "2026-02-17T10:01:21.000Z",
      "collected_at": "2026-02-17T16:04:11.757824+00:00",
      "v2_slot": "frontier_official",
      "freshness": 0.777,
      "source_reliability": 1.0,
      "v2_prefilter_score": 3.577,
      "type": "news",
      "llm_label_source": "heuristic",
      "llm_category": "platform",
      "llm_summary_1line": "Anthropic Rwanda Mou",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.0,
      "v2_source_bias": 0.06,
      "v2_topical_bias": 0.0,
      "v2_final_score": 1.815,
      "summary_1line": "Anthropic Rwanda Mou",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.792,
      "v2_global_score": 2.607
    },
    {
      "id": "c967be8280f90bed",
      "source": "anthropic_newsroom",
      "source_weight": 1.8,
      "title": "Anthropic Infosys",
      "url": "https://www.anthropic.com/news/anthropic-infosys",
      "summary": "",
      "image_url": "",
      "published": "2026-02-17T09:26:56.000Z",
      "collected_at": "2026-02-17T16:04:11.757824+00:00",
      "v2_slot": "frontier_official",
      "freshness": 0.759,
      "source_reliability": 1.0,
      "v2_prefilter_score": 3.559,
      "type": "news",
      "llm_label_source": "heuristic",
      "llm_category": "platform",
      "llm_summary_1line": "Anthropic Infosys",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.0,
      "v2_source_bias": 0.06,
      "v2_topical_bias": 0.0,
      "v2_final_score": 1.812,
      "summary_1line": "Anthropic Infosys",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.792,
      "v2_global_score": 2.604
    },
    {
      "id": "fe7dbebc903fef59",
      "source": "anthropic_research",
      "source_weight": 1.4,
      "title": "India Brief Economic Index",
      "url": "https://www.anthropic.com/research/india-brief-economic-index",
      "summary": "",
      "image_url": "",
      "published": "2026-02-16T23:13:32.000Z",
      "collected_at": "2026-02-17T16:04:11.757824+00:00",
      "v2_slot": "research_watch",
      "freshness": 0.86,
      "source_reliability": 1.0,
      "v2_prefilter_score": 3.26,
      "type": "research",
      "llm_label_source": "heuristic",
      "llm_category": "platform",
      "llm_summary_1line": "India Brief Economic Index",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.0,
      "v2_source_bias": 0.4,
      "v2_topical_bias": 0.0,
      "v2_final_score": 2.229,
      "summary_1line": "India Brief Economic Index",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.357,
      "v2_global_score": 2.586
    },
    {
      "id": "5983155f3e279e8e",
      "source": "latent_space",
      "source_weight": 1.2,
      "title": "[AINews] Qwen3.5-397B-A17B: the smallest Open-Opus class, very efficient model",
      "url": "https://www.latent.space/p/ainews-qwen35-397b-a17b-the-smallest",
      "summary": "Congrats Qwen team!",
      "image_url": "https://substackcdn.com/image/fetch/$s_!1fDP!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0472c69a-cd07-4bde-8b10-61bc1d0702a7_2444x1704.png",
      "published": "Tue, 17 Feb 2026 04:22:56 GMT",
      "collected_at": "2026-02-17T16:04:11.757824+00:00",
      "v2_slot": "practitioner_analysis",
      "freshness": 0.747,
      "source_reliability": 1.0,
      "v2_prefilter_score": 2.947,
      "type": "news",
      "llm_label_source": "heuristic",
      "llm_category": "platform",
      "llm_summary_1line": "Congrats Qwen team!",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.2,
      "v2_source_bias": 0.0,
      "v2_topical_bias": 0.0,
      "v2_final_score": 1.982,
      "summary_1line": "Congrats Qwen team!",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.571,
      "v2_global_score": 2.553
    },
    {
      "id": "c91a4996533a3bbb",
      "source": "arxiv_cs_lg",
      "source_weight": 0.85,
      "title": "Use What You Know: Causal Foundation Models with Partial Graphs",
      "url": "http://arxiv.org/abs/2602.14972v1",
      "summary": "Estimating causal quantities traditionally relies on bespoke estimators tailored to specific assumptions. Recently proposed Causal Foundation Models (CFMs) promise a more unified approach by amortising causal discovery and inference in a single step. However, in their current state, they do not allow for the incorporation of any domain knowledge, which can lead to suboptimal predictions. We bridge this gap by introducing methods to condition CFMs on causal information, such as the causal graph or more readily available ancestral information. When access to complete causal graph information is too strict a requirement, our approach also effectively leverages partial causal information. We systematically evaluate conditioning strategies and find that injecting learnable biases into the attention mechanism is the most effective method to utilise full and partial causal information. Our experiments show that this conditioning allows a general-purpose CFM to match the performance of specialised models trained on specific causal structures. Overall, our approach addresses a central hurdle on the path towards all-in-one causal foundation models: the capability to answer causal queries in a data-driven manner while effectively leveraging any amount of domain expertise.",
      "image_url": "",
      "published": "2026-02-16T17:56:37Z",
      "collected_at": "2026-02-17T16:04:11.757824+00:00",
      "v2_slot": "research_watch",
      "freshness": 0.821,
      "source_reliability": 1.0,
      "v2_prefilter_score": 2.671,
      "type": "paper",
      "llm_label_source": "heuristic",
      "llm_category": "platform",
      "llm_summary_1line": "Estimating causal quantities traditionally relies on bespoke estimators tailored to specific assumptions. Recently proposed Causal Foundation Models (CFMs) promise a more unified approach by amortising causal discover...",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.6,
      "v2_source_bias": -0.35,
      "v2_topical_bias": 0.2,
      "v2_final_score": 2.183,
      "summary_1line": "Estimating causal quantities traditionally relies on bespoke estimators tailored to specific assumptions. Recently proposed Causal Foundation Models (CFMs) promise a more unified approach by amortising causal discover...",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.357,
      "v2_global_score": 2.54
    },
    {
      "id": "bef44b20b585b2ba",
      "source": "claude_agent_sdk_python_releases",
      "source_weight": 1.3,
      "title": "v0.1.37",
      "url": "https://github.com/anthropics/claude-agent-sdk-python/releases/tag/v0.1.37",
      "summary": "<h3>Internal/Other Changes</h3>\n<ul>\n<li>Updated bundled Claude CLI to version 2.1.44</li>\n</ul>\n<hr />\n<p><strong>PyPI:</strong> <a href=\"https://pypi.org/project/claude-agent-sdk/0.1.37/\" rel=\"nofollow\">https://pypi.org/project/claude-agent-sdk/0.1.37/</a></p>\n<div class=\"highlight highlight-source-shell notranslate position-relative overflow-auto\"><pre>pip install claude-agent-sdk==0.1.37</pre></div>",
      "image_url": "",
      "published": "2026-02-16T21:51:27Z",
      "collected_at": "2026-02-17T16:04:11.757824+00:00",
      "v2_slot": "agent_tooling_releases",
      "freshness": 0.722,
      "source_reliability": 1.0,
      "v2_prefilter_score": 3.022,
      "type": "release",
      "llm_label_source": "heuristic",
      "llm_category": "platform",
      "llm_summary_1line": "Internal/Other Changes Updated bundled Claude CLI to version 2.1.44 PyPI: https://pypi.org/project/claude-agent-sdk/0.1.37/ pip install claude-agent-sdk==0.1.37",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.0,
      "v2_source_bias": 0.0,
      "v2_topical_bias": 0.2,
      "v2_final_score": 1.817,
      "summary_1line": "Internal/Other Changes Updated bundled Claude CLI to version 2.1.44 PyPI: https://pypi.org/project/claude-agent-sdk/0.1.37/ pip install claude-agent-sdk==0.1.37",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.394,
      "v2_global_score": 2.211
    },
    {
      "id": "542eda03bb7cb1bf",
      "source": "openai_codex_releases",
      "source_weight": 2.2,
      "title": "rust-v0.102.0-alpha.10",
      "url": "https://github.com/openai/codex/releases/tag/rust-v0.102.0-alpha.10",
      "summary": "<p>Release 0.102.0-alpha.10</p>",
      "image_url": "",
      "published": "2026-02-17T07:12:08Z",
      "collected_at": "2026-02-17T16:04:11.757824+00:00",
      "v2_slot": "agent_tooling_releases",
      "freshness": 0.853,
      "source_reliability": 1.0,
      "v2_prefilter_score": 4.053,
      "type": "release",
      "llm_label_source": "heuristic",
      "llm_category": "platform",
      "llm_summary_1line": "Release 0.102.0-alpha.10",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.0,
      "v2_source_bias": 0.0,
      "v2_topical_bias": 0.0,
      "v2_final_score": 1.656,
      "summary_1line": "Release 0.102.0-alpha.10",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.394,
      "v2_global_score": 2.05
    },
    {
      "id": "f70833bd2f581c75",
      "source": "claude_code_releases",
      "source_weight": 2.2,
      "title": "v2.1.41",
      "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.41",
      "summary": "<h2>What's changed</h2>\n<ul>\n<li>Fixed AWS auth refresh hanging indefinitely by adding a 3-minute timeout</li>\n<li>Added <code>claude auth login</code>, <code>claude auth status</code>, and <code>claude auth logout</code> CLI subcommands</li>\n<li>Added Windows ARM64 (win32-arm64) native binary support</li>\n<li>Improved <code>/rename</code> to auto-generate session name from conversation context when called without arguments</li>\n<li>Improved narrow terminal layout for prompt footer</li>\n<li>Fixed file resolution failing for @-mentions with anchor fragments (e.g., <code>@README.md#installation</code>)</li>\n<li>Fixed FileReadTool blocking the process on FIFOs, <code>/dev/stdin</code>, and large files</li>\n<li>Fixed background task notifications not being delivered in streaming Agent SDK mode</li>\n<li>Fixed cursor jumping to end on each keystroke in classifier rule input</li>\n<li>Fixed markdown link display text being dropped for raw URL</li>\n<li>Fixed auto-compact failure error notifications being shown to users</li>\n<li>Fixed permission wait time being included in subagent elapsed time display</li>\n<li>Fixed proactive ticks firing while in plan mode</li>\n<li>Fixed clear stale permission rules when settings change on disk</li>\n<li>Fixed hook blocking errors showing stderr content in UI</li>\n</ul>",
      "image_url": "",
      "published": "2026-02-13T06:08:49Z",
      "collected_at": "2026-02-17T16:04:11.757824+00:00",
      "v2_slot": "agent_tooling_releases",
      "freshness": 0.151,
      "source_reliability": 1.0,
      "v2_prefilter_score": 3.351,
      "type": "release",
      "llm_label_source": "heuristic",
      "llm_category": "platform",
      "llm_summary_1line": "What's changed Fixed AWS auth refresh hanging indefinitely by adding a 3-minute timeout Added claude auth login , claude auth status , and claude auth logout CLI subcommands Added Windows ARM64 (win32-arm64) native bi...",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.0,
      "v2_source_bias": 0.0,
      "v2_topical_bias": 0.2,
      "v2_final_score": 1.645,
      "summary_1line": "What's changed Fixed AWS auth refresh hanging indefinitely by adding a 3-minute timeout Added claude auth login , claude auth status , and claude auth logout CLI subcommands Added Windows ARM64 (win32-arm64) native bi...",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.394,
      "v2_global_score": 2.039
    }
  ]
}