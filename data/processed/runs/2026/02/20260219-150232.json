{
  "run_at": "2026-02-19T15:02:32.362734+00:00",
  "item_count": 19,
  "items": [
    {
      "id": "80a9e576f04115fb",
      "source": "simon_willison",
      "source_weight": 1.25,
      "title": "SWE-bench February 2026 leaderboard update",
      "url": "https://simonwillison.net/2026/Feb/19/swe-bench/#atom-everything",
      "summary": "<p><strong><a href=\"https://www.swebench.com/\">SWE-bench February 2026 leaderboard update</a></strong></p>\nSWE-bench is one of the benchmarks that the labs love to list in their model releases. The official leaderboard is infrequently updated but they just did a full run of it against the current generation of models, which is notable because it's always good to see benchmark results like this that <em>weren't</em> self-reported by the labs.</p>\n<p>The fresh results are for their \"Bash Only\" benchmark, which runs their <a href=\"https://github.com/SWE-agent/mini-swe-agent\">mini-swe-bench</a> agent (~9,000 lines of Python, <a href=\"https://github.com/SWE-agent/mini-swe-agent/blob/v2.2.1/src/minisweagent/config/benchmarks/swebench.yaml\">here are the prompts</a> they use) against the <a href=\"https://huggingface.co/datasets/princeton-nlp/SWE-bench\">SWE-bench</a> dataset of coding problems - 2,294 real-world examples pulled from 12 open source repos: <a href=\"https://github.com/django/django\">django/django</a> (850), <a href=\"https://github.com/sympy/sympy\">sympy/sympy</a> (386), <a href=\"https://github.com/scikit-learn/scikit-learn\">scikit-learn/scikit-learn</a> (229), <a href=\"https://github.com/sphinx-doc/sphinx\">sphinx-doc/sphinx</a> (187), <a href=\"https://github.com/matplotlib/matplotlib\">matplotlib/matplotlib</a> (184), <a href=\"https://github.com/pytest-dev/pytest\">pytest-dev/pytest</a> (119), <a href=\"https://github.com/pydata/xarray\">pydata/xarray</a> (110), <a href=\"https://github.com/astropy/astropy\">astropy/astropy</a> (95), <a href=\"https://github.com/pylint-dev/pylint\">pylint-dev/pylint</a> (57), <a href=\"https://github.com/psf/requests\">psf/requests</a> (44), <a href=\"https://github.com/mwaskom/seaborn\">mwaskom/seaborn</a> (22), <a href=\"https://github.com/pallets/flask\">pallets/flask</a> (11).</p>\n<p>Here's how the top ten models performed:</p>\n<p><img alt=\"Bar chart showing &quot;% Resolved&quot; by &quot;Model&quot;. Bars in descending order: Claude 4.5 Opus (high reasoning) 76.8%, Gemini 3 Flash (high reasoning) 75.8%, MiniMax M2.5 (high reasoning) 75.8%, Claude Opus 4.6 75.6%, GLM-5 (high reasoning) 72.8%, GPT-5.2 (high reasoning) 72.8%, Claude 4.5 Sonnet (high reasoning) 72.8%, Kimi K2.5 (high reasoning) 71.4%, DeepSeek V3.2 (high reasoning) 70.8%, Claude 4.5 Haiku (high reasoning) 70.0%, and a partially visible final bar at 66.6%.\" src=\"https://static.simonwillison.net/static/2026/swbench-feb-2026.jpg\" /></p>\n<p>It's interesting to see Claude Opus 4.5 beat Opus 4.6, though only by about a percentage point. 4.5 Opus is top, then Gemini 3 Flash, then MiniMax M2.5 - a 229B model released <a href=\"https://www.minimax.io/news/minimax-m25\">last week</a> by Chinese lab MiniMax. GLM-5, Kimi K2.5 and DeepSeek V3.2 are three more Chinese models that make the top ten as well.</p>\n<p>OpenAI's GPT-5.2 is their highest performing model at position 6, but it's worth noting that their best coding model, GPT-5.3-Codex, is not represented - maybe because it's not yet available in the OpenAI API.</p>\n<p>This benchmark uses the same system prompt for every model, which is important for a fair comparison but does mean that the quality of the different harnesses or optimized prompts is not being measured here.</p>\n<p>The chart above is a screenshot from the SWE-bench website, but their charts don't include the actual percentage values visible on the bars. I successfully used Claude for Chrome to add these - <a href=\"https://claude.ai/share/81a0c519-c727-4caa-b0d4-0d866375d0da\">transcript here</a>. My prompt sequence included:</p>\n<blockquote>\n<p>Use claude in chrome to open https://www.swebench.com/</p>\n<p>Click on \"Compare results\" and then select \"Select top 10\"</p>\n<p>See those bar charts? I want them to display the percentage on each bar so I can take a better screenshot, modify the page like that</p>\n</blockquote>\n<p>I'm impressed at how well this worked - Claude injected custom JavaScript into the page to draw additional labels on top of the existing chart.</p>\n<p><img alt=\"Screenshot of a Claude AI conversation showing browser automation. A thinking step reads &quot;Pivoted strategy to avoid recursion issues with chart labeling &gt;&quot; followed by the message &quot;Good, the chart is back. Now let me carefully add the labels using an inline plugin on the chart instance to avoid the recursion issue.&quot; A collapsed &quot;Browser_evaluate&quot; section shows a browser_evaluate tool call with JavaScript code using Chart.js canvas context to draw percentage labels on bars: meta.data.forEach((bar, index) =&gt; { const value = dataset.data[index]; if (value !== undefined &amp;&amp; value !== null) { ctx.save(); ctx.textAlign = 'center'; ctx.textBaseline = 'bottom'; ctx.fillStyle = '#333'; ctx.font = 'bold 12px sans-serif'; ctx.fillText(value.toFixed(1) + '%', bar.x, bar.y - 5); A pending step reads &quot;Let me take a screenshot to see if it worked.&quot; followed by a completed &quot;Done&quot; step, and the message &quot;Let me take a screenshot to check the result.&quot;\" src=\"https://static.simonwillison.net/static/2026/claude-chrome-draw-on-chart.jpg\" />\n\n    <p><small></small>Via <a href=\"https://twitter.com/KLieret/status/2024176335782826336\">@KLieret</a></small></p>\n\n\n    <p>Tags: <a href=\"https://simonwillison.net/tags/benchmarks\">benchmarks</a>, <a href=\"https://simonwillison.net/tags/django\">django</a>, <a href=\"https://simonwillison.net/tags/ai\">ai</a>, <a href=\"https://simonwillison.net/tags/openai\">openai</a>, <a href=\"https://simonwillison.net/tags/generative-ai\">generative-ai</a>, <a href=\"https://simonwillison.net/tags/llms\">llms</a>, <a href=\"https://simonwillison.net/tags/anthropic\">anthropic</a>, <a href=\"https://simonwillison.net/tags/claude\">claude</a>, <a href=\"https://simonwillison.net/tags/coding-agents\">coding-agents</a>, <a href=\"https://simonwillison.net/tags/ai-in-china\">ai-in-china</a>, <a href=\"https://simonwillison.net/tags/minimax\">minimax</a></p>",
      "image_url": "https://static.simonwillison.net/static/2026/swbench-feb-2026.jpg",
      "published": "2026-02-19T04:48:47+00:00",
      "collected_at": "2026-02-19T11:52:02.322700+00:00",
      "ingest_batch_id": "20260219-115202",
      "tier": "tier1",
      "type": "news",
      "source_reliability": 0.79,
      "freshness": 0.774,
      "tier1_quick_score": 2.895,
      "v2_slot": "practitioner_analysis",
      "v2_prefilter_score": 2.814,
      "llm_label_source": "llm",
      "llm_category": "research",
      "llm_summary_1line": "SWE-bench Feb 2026 leaderboard shows Claude 4.5 Opus leading at 76.8% on 2,294 real-world OSS tasks; independent third-party benchmark with reproducible harness and dataset.",
      "llm_why_1line": "Third-party benchmark data (not self-reported); concrete coding-agent eval; actionable baseline for SWE-agent harness tuning and model selection.",
      "v2_llm_score": 4.55,
      "v2_source_bias": 0.08,
      "v2_topical_bias": 0.0,
      "v2_final_score": 4.064,
      "summary_1line": "SWE-bench Feb 2026 leaderboard shows Claude 4.5 Opus at 76.8% on 2,294 real OSS tasks; independent benchmark run across current-gen models with transparent methodology.",
      "why_it_matters": "Third-party benchmark data (not self-reported); concrete coding-agent eval; actionable baseline for SWE-agent harness tuning and model selection.",
      "v2_slot_priority": 0.636,
      "v2_global_score": 4.7
    },
    {
      "id": "c991b4745e961b3e",
      "source": "latent_space",
      "source_weight": 1.2,
      "title": "[AINews] Anthropic's Agent Autonomy study",
      "url": "https://www.latent.space/p/ainews-anthropics-agent-autonomy",
      "summary": "a quiet day lets us dive deep into Anthropic's own version of the METR data",
      "image_url": "https://substackcdn.com/image/fetch/$s_!c74W!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18a91dee-c7fa-409d-9541-b34e24bba31c_1938x1236.png",
      "published": "Thu, 19 Feb 2026 07:55:36 GMT",
      "collected_at": "2026-02-19T11:52:02.322700+00:00",
      "ingest_batch_id": "20260219-115202",
      "tier": "tier1",
      "type": "news",
      "source_reliability": 0.79,
      "freshness": 0.837,
      "tier1_quick_score": 2.885,
      "v2_slot": "practitioner_analysis",
      "v2_prefilter_score": 2.827,
      "llm_label_source": "llm",
      "llm_category": "research",
      "llm_summary_1line": "Anthropic publishes agent autonomy research mirroring METR's methodology; early signal on agentic capability benchmarking.",
      "llm_why_1line": "Relevant framing but vague excerpt; needs concrete evals, metrics, and reproducible harness details for platform engineers.",
      "v2_llm_score": 3.0,
      "v2_source_bias": 0.0,
      "v2_topical_bias": 0.2,
      "v2_final_score": 2.876,
      "summary_1line": "Anthropic releases agent autonomy benchmarking study mirroring METR's approach to evaluate agentic capability and safety boundaries.",
      "why_it_matters": "Relevant framing but vague excerpt; needs concrete evals, metrics, and reproducible harness details for platform engineers.",
      "v2_slot_priority": 0.636,
      "v2_global_score": 3.512
    },
    {
      "id": "13463e1f08e717b4",
      "source": "simon_willison",
      "source_weight": 1.25,
      "title": "The A.I. Disruption We’ve Been Waiting for Has Arrived",
      "url": "https://simonwillison.net/2026/Feb/18/the-ai-disruption/#atom-everything",
      "summary": "<p><strong><a href=\"https://www.nytimes.com/2026/02/18/opinion/ai-software.html?unlocked_article_code=1.NFA.UkLv.r-XczfzYRdXJ&amp;smid=url-share\">The A.I. Disruption We’ve Been Waiting for Has Arrived</a></strong></p>\nNew opinion piece from Paul Ford in the New York Times. Unsurprisingly for a piece by Paul it's packed with quoteworthy snippets, but a few stood out for me in particular.</p>\n<p>Paul describes the <a href=\"https://simonwillison.net/2026/Jan/4/inflection/\">November moment</a> that so many other programmers have observed, and highlights Claude Code's ability to revive old side projects:</p>\n<blockquote>\n<p>[Claude Code] was always a helpful coding assistant, but in November it suddenly got much better, and ever since I’ve been knocking off side projects that had sat in folders for a decade or longer. It’s fun to see old ideas come to life, so I keep a steady flow. Maybe it adds up to a half-hour a day of my time, and an hour of Claude’s.</p>\n<p>November was, for me and many others in tech, a great surprise. Before, A.I. coding tools were often useful, but halting and clumsy. Now, the bot can run for a full hour and make whole, designed websites and apps that may be flawed, but credible. I spent an entire session of therapy talking about it.</p>\n</blockquote>\n<p>And as the former CEO of a respected consultancy firm (Postlight) he's well positioned to evaluate the potential impact:</p>\n<blockquote>\n<p>When you watch a large language model slice through some horrible, expensive problem — like migrating data from an old platform to a modern one — you feel the earth shifting. I was the chief executive of a software services firm, which made me a professional software cost estimator. When I rebooted my messy personal website a few weeks ago, I realized: I would have paid $25,000 for someone else to do this. When a friend asked me to convert a large, thorny data set, I downloaded it, cleaned it up and made it pretty and easy to explore. In the past I would have charged $350,000.</p>\n<p>That last price is full 2021 retail — it implies a product manager, a designer, two engineers (one senior) and four to six months of design, coding and testing. Plus maintenance. Bespoke software is joltingly expensive. Today, though, when the stars align and my prompts work out, I can do hundreds of thousands of dollars worth of work for fun (fun for me) over weekends and evenings, for the price of the Claude $200-a-month plan.</p>\n</blockquote>\n<p>He also neatly captures the inherent community tension involved in exploring this technology:</p>\n<blockquote>\n<p>All of the people I love hate this stuff, and all the people I hate love it. And yet, likely because of the same personality flaws that drew me to technology in the first place, I am annoyingly excited.</p>\n</blockquote>\n\n\n    <p>Tags: <a href=\"https://simonwillison.net/tags/new-york-times\">new-york-times</a>, <a href=\"https://simonwillison.net/tags/paul-ford\">paul-ford</a>, <a href=\"https://simonwillison.net/tags/careers\">careers</a>, <a href=\"https://simonwillison.net/tags/ai\">ai</a>, <a href=\"https://simonwillison.net/tags/generative-ai\">generative-ai</a>, <a href=\"https://simonwillison.net/tags/llms\">llms</a>, <a href=\"https://simonwillison.net/tags/ai-assisted-programming\">ai-assisted-programming</a>, <a href=\"https://simonwillison.net/tags/ai-ethics\">ai-ethics</a>, <a href=\"https://simonwillison.net/tags/coding-agents\">coding-agents</a>, <a href=\"https://simonwillison.net/tags/claude-code\">claude-code</a></p>",
      "image_url": "",
      "published": "2026-02-18T17:07:31+00:00",
      "collected_at": "2026-02-19T11:52:02.322700+00:00",
      "ingest_batch_id": "20260219-115202",
      "tier": "tier1",
      "type": "news",
      "source_reliability": 0.79,
      "freshness": 0.578,
      "tier1_quick_score": 2.759,
      "v2_slot": "practitioner_analysis",
      "v2_prefilter_score": 2.618,
      "llm_label_source": "heuristic",
      "llm_category": "platform",
      "llm_summary_1line": "The A.I. Disruption We’ve Been Waiting for Has Arrived New opinion piece from Paul Ford in the New York Times. Unsurprisingly for a piece by Paul it's packed with quoteworthy snippets, but a few stood out for me in pa...",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.6,
      "v2_source_bias": 0.08,
      "v2_topical_bias": 0.2,
      "v2_final_score": 2.577,
      "summary_1line": "The A.I. Disruption We’ve Been Waiting for Has Arrived New opinion piece from Paul Ford in the New York Times. Unsurprisingly for a piece by Paul it's packed with quoteworthy snippets, but a few stood out for me in pa...",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.636,
      "v2_global_score": 3.213
    },
    {
      "id": "8de56f934385a8fc",
      "source": "infoq_ai_ml",
      "source_weight": 1.15,
      "title": "Hugging Face Introduces Community Evals for Transparent Model Benchmarking",
      "url": "https://www.infoq.com/news/2026/02/hugging-face-evals/?utm_campaign=infoq_content&utm_source=infoq&utm_medium=feed&utm_term=AI%2C+ML+%26+Data+Engineering",
      "summary": "<img src=\"https://res.infoq.com/news/2026/02/hugging-face-evals/en/headerimage/generatedHeaderImage-1771448477065.jpg\" /><p>Hugging Face has launched Community Evals, a feature that enables benchmark datasets on the Hub to host their own leaderboards and automatically collect evaluation results from model repositories.</p> <i>By Daniel Dominguez</i>",
      "image_url": "https://res.infoq.com/news/2026/02/hugging-face-evals/en/headerimage/generatedHeaderImage-1771448477065.jpg",
      "published": "Thu, 19 Feb 2026 10:55:00 GMT",
      "collected_at": "2026-02-19T11:52:02.322700+00:00",
      "ingest_batch_id": "20260219-115202",
      "tier": "tier1",
      "type": "news",
      "source_reliability": 0.79,
      "freshness": 0.902,
      "tier1_quick_score": 2.875,
      "v2_slot": "practitioner_analysis",
      "v2_prefilter_score": 2.842,
      "llm_label_source": "heuristic",
      "llm_category": "platform",
      "llm_summary_1line": "Hugging Face has launched Community Evals, a feature that enables benchmark datasets on the Hub to host their own leaderboards and automatically collect evaluation results from model repositories. By Daniel Dominguez",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.75,
      "v2_source_bias": 0.08,
      "v2_topical_bias": 0.0,
      "v2_final_score": 2.553,
      "summary_1line": "Hugging Face has launched Community Evals, a feature that enables benchmark datasets on the Hub to host their own leaderboards and automatically collect evaluation results from model repositories. By Daniel Dominguez",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.636,
      "v2_global_score": 3.189
    },
    {
      "id": "bb6312770f114d5f",
      "source": "hackernews_ai",
      "source_weight": 1.1,
      "title": "Show HN: Agorio – TypeScript SDK for Building AI Shopping Agents (UCP/ACP)",
      "url": "https://github.com/Nolpak14/agorio",
      "summary": "<p>I built an open-source TypeScript SDK for building AI agents that can discover merchants, browse products, and complete purchases using the new UCP (Google/Shopify) and ACP (OpenAI/Stripe) commerce protocols.<p>Try it in 2 minutes:<p><pre><code>  npm install @agorio/sdk\n\n  import { ShoppingAgent, GeminiAdapter, MockMerchant } from '@agorio/sdk';\n  const merchant = new MockMerchant();\n  await merchant.start();\n  const agent = new ShoppingAgent({\n    llm: new GeminiAdapter({ apiKey: process.env.GEMINI_API_KEY })\n  });\n  const result = await agent.run(\n    `Go to ${merchant.domain} and buy me wireless headphones`\n  );\n</code></pre>\nWhat it does:<p>- UcpClient: discovers merchants via /.well-known/ucp, parses capabilities, normalizes both array and object formats, calls REST APIs\n- ShoppingAgent: plan-act-observe loop with 12 built-in tools (discover, search, browse, cart, checkout, order tracking)\n- MockMerchant: full UCP-compliant Express server with product catalog, checkout flow, and configurable chaos testing (latency, error rates)\n- LlmAdapter interface: swap LLMs without changing agent code. Gemini ships today, Claude and OpenAI coming in v0.2<p>The agent handles the entire purchase flow autonomously - UCP discovery, product search, cart management, shipping, payment, order confirmation. 37 tests passing.<p>Context: UCP was announced Jan 11 by Google, Shopify, and 25+ partners (Walmart, Target, Visa, Mastercard). ACP is by OpenAI and Stripe, powers ChatGPT Instant Checkout. Both are open standards. But there was no developer SDK for building on top of them - just the raw specs.<p>GitHub: <a href=\"https://github.com/Nolpak14/agorio\" rel=\"nofollow\">https://github.com/Nolpak14/agorio</a>\nnpm: <a href=\"https://www.npmjs.com/package/@agorio/sdk\" rel=\"nofollow\">https://www.npmjs.com/package/@agorio/sdk</a></p>\n<hr />\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47072813\">https://news.ycombinator.com/item?id=47072813</a></p>\n<p>Points: 1</p>\n<p># Comments: 1</p>",
      "image_url": "",
      "published": "Thu, 19 Feb 2026 11:48:07 +0000",
      "collected_at": "2026-02-19T11:52:02.322700+00:00",
      "ingest_batch_id": "20260219-115202",
      "tier": "tier1",
      "type": "news",
      "source_reliability": 0.79,
      "freshness": 0.817,
      "tier1_quick_score": 2.837,
      "v2_slot": "community_signal",
      "v2_prefilter_score": 2.707,
      "llm_label_source": "heuristic",
      "llm_category": "platform",
      "llm_summary_1line": "I built an open-source TypeScript SDK for building AI agents that can discover merchants, browse products, and complete purchases using the new UCP (Google/Shopify) and ACP (OpenAI/Stripe) commerce protocols. Try it i...",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.75,
      "v2_source_bias": 0.0,
      "v2_topical_bias": 0.2,
      "v2_final_score": 2.467,
      "summary_1line": "I built an open-source TypeScript SDK for building AI agents that can discover merchants, browse products, and complete purchases using the new UCP (Google/Shopify) and ACP (OpenAI/Stripe) commerce protocols. Try it i...",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.479,
      "v2_global_score": 2.946
    },
    {
      "id": "e090493a0ff267ce",
      "source": "openai_blog",
      "source_weight": 2.0,
      "title": "Introducing GPT-5.3-Codex-Spark",
      "url": "https://openai.com/index/introducing-gpt-5-3-codex-spark",
      "summary": "Introducing GPT-5.3-Codex-Spark—our first real-time coding model. 15x faster generation, 128k context, now in research preview for ChatGPT Pro users.",
      "image_url": "",
      "published": "Thu, 12 Feb 2026 10:00:00 GMT",
      "collected_at": "2026-02-19T11:52:02.322700+00:00",
      "ingest_batch_id": "20260219-115202",
      "tier": "tier1",
      "type": "news",
      "source_reliability": 0.79,
      "freshness": 0.115,
      "tier1_quick_score": 2.834,
      "v2_slot": "frontier_official",
      "v2_prefilter_score": 2.905,
      "llm_label_source": "heuristic",
      "llm_category": "platform",
      "llm_summary_1line": "Introducing GPT-5.3-Codex-Spark—our first real-time coding model. 15x faster generation, 128k context, now in research preview for ChatGPT Pro users.",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.2,
      "v2_source_bias": 0.1,
      "v2_topical_bias": 0.2,
      "v2_final_score": 2.083,
      "summary_1line": "Introducing GPT-5.3-Codex-Spark—our first real-time coding model. 15x faster generation, 128k context, now in research preview for ChatGPT Pro users.",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.683,
      "v2_global_score": 2.766
    },
    {
      "id": "0f43cce4717b58ca",
      "source": "anthropic_research",
      "source_weight": 1.4,
      "title": "Measuring Agent Autonomy",
      "url": "https://www.anthropic.com/research/measuring-agent-autonomy",
      "summary": "",
      "image_url": "",
      "published": "2026-02-18T20:26:31.000Z",
      "collected_at": "2026-02-19T11:52:02.322700+00:00",
      "ingest_batch_id": "20260219-115202",
      "tier": "tier1",
      "type": "research",
      "source_reliability": 0.79,
      "freshness": 0.847,
      "tier1_quick_score": 2.945,
      "v2_slot": "research_watch",
      "v2_prefilter_score": 3.037,
      "llm_label_source": "heuristic",
      "llm_category": "platform",
      "llm_summary_1line": "Measuring Agent Autonomy",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.0,
      "v2_source_bias": 0.4,
      "v2_topical_bias": 0.2,
      "v2_final_score": 2.427,
      "summary_1line": "Measuring Agent Autonomy",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.339,
      "v2_global_score": 2.766
    },
    {
      "id": "5713ae1ccd7185d1",
      "source": "claude_code_releases",
      "source_weight": 2.2,
      "title": "v2.1.47",
      "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.47",
      "summary": "<h2>What's changed</h2>\n<ul>\n<li>Fixed FileWriteTool line counting to preserve intentional trailing blank lines instead of stripping them with <code>trimEnd()</code>.</li>\n<li>Fixed Windows terminal rendering bugs caused by <code>os.EOL</code> (<code>\\r\\n</code>) in display code — line counts now show correct values instead of always showing 1 on Windows.</li>\n<li>Improved VS Code plan preview: auto-updates as Claude iterates, enables commenting only when the plan is ready for review, and keeps the preview open when rejecting so Claude can revise.</li>\n<li>Fixed a bug where bold and colored text in markdown output could shift to the wrong characters on Windows due to <code>\\r\\n</code> line endings.</li>\n<li>Fixed compaction failing when conversation contains many PDF documents by stripping document blocks alongside images before sending to the compaction API (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26188\">#26188</a>)</li>\n<li>Improved memory usage in long-running sessions by releasing API stream buffers, agent context, and skill state after use</li>\n<li>Improved startup performance by deferring SessionStart hook execution, reducing time-to-interactive by ~500ms.</li>\n<li>Fixed an issue where bash tool output was silently discarded on Windows when using MSYS2 or Cygwin shells.</li>\n<li>Improved performance of <code>@</code> file mentions - file suggestions now appear faster by pre-warming the index on startup and using session-based caching with background refresh.</li>\n<li>Improved memory usage by trimming agent task message history after tasks complete</li>\n<li>Improved memory usage during long agent sessions by eliminating O(n²) message accumulation in progress updates</li>\n<li>Fixed the bash permission classifier to validate that returned match descriptions correspond to actual input rules, preventing hallucinated descriptions from incorrectly granting permissions</li>\n<li>Fixed user-defined agents only loading one file on NFS/FUSE filesystems that report zero inodes (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26044\">#26044</a>)</li>\n<li>Fixed plugin agent skills silently failing to load when referenced by bare name instead of fully-qualified plugin name (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25834\">#25834</a>)</li>\n<li>Search patterns in collapsed tool results are now displayed in quotes for clarity</li>\n<li>Windows: Fixed CWD tracking temp files never being cleaned up, causing them to accumulate indefinitely (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/17600\">#17600</a>)</li>\n<li>Use <code>ctrl+f</code> to kill all background agents instead of double-pressing ESC. Background agents now continue running when you press ESC to cancel the main thread, giving you more control over agent lifecycle.</li>\n<li>Fixed API 400 errors (\"thinking blocks cannot be modified\") that occurred in sessions with concurrent agents, caused by interleaved streaming content blocks preventing proper message merging.</li>\n<li>Simplified teammate navigation to use only Shift+Down (with wrapping) instead of both Shift+Up and Shift+Down.</li>\n<li>Fixed an issue where a single file write/edit error would abort all other parallel file write/edit operations. Independent file mutations now complete even when a sibling fails.</li>\n<li>Added <code>last_assistant_message</code> field to Stop and SubagentStop hook inputs, providing the final assistant response text so hooks can access it without parsing transcript files.</li>\n<li>Fixed custom session titles set via <code>/rename</code> being lost after resuming a conversation (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/23610\">#23610</a>)</li>\n<li>Fixed collapsed read/search hint text overflowing on narrow terminals by truncating from the start.</li>\n<li>Fixed an issue where bash commands with backslash-newline continuation lines (e.g., long commands split across multiple lines with <code>\\</code>) would produce spurious empty arguments, potentially breaking command execution.</li>\n<li>Fixed built-in slash commands (<code>/help</code>, <code>/model</code>, <code>/compact</code>, etc.) being hidden from the autocomplete dropdown when many user skills are installed (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/22020\">#22020</a>)</li>\n<li>Fixed MCP servers not appearing in the MCP Management Dialog after deferred loading</li>\n<li>Fixed session name persisting in status bar after <code>/clear</code> command (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26082\">#26082</a>)</li>\n<li>Fixed crash when a skill's <code>name</code> or <code>description</code> in SKILL.md frontmatter is a bare number (e.g., <code>name: 3000</code>) — the value is now properly coerced to a string (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25837\">#25837</a>)</li>\n<li>Fixed /resume silently dropping sessions when the first message exceeds 16KB or uses array-format content (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25721\">#25721</a>)</li>\n<li>Added <code>chat:newline</code> keybinding action for configurable multi-line input (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26075\">#26075</a>)</li>\n<li>Added <code>added_dirs</code> to the statusline JSON <code>workspace</code> section, exposing directories added via <code>/add-dir</code> to external scripts (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26096\">#26096</a>)</li>\n<li>Fixed <code>claude doctor</code> misclassifying mise and asdf-managed installations as native installs (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26033\">#26033</a>)</li>\n<li>Fixed zsh heredoc failing with \"read-only file system\" error in sandboxed commands (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25990\">#25990</a>)</li>\n<li>Fixed agent progress indicator showing inflated tool use count (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26023\">#26023</a>)</li>\n<li>Fixed image pasting not working on WSL2 systems where Windows copies images as BMP format (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25935\">#25935</a>)</li>\n<li>Fixed background agent results returning raw transcript data instead of the agent's final answer (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26012\">#26012</a>)</li>\n<li>Fixed Warp terminal incorrectly prompting for Shift+Enter setup when it supports it natively (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25957\">#25957</a>)</li>\n<li>Fixed CJK wide characters causing misaligned timestamps and layout elements in the TUI (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26084\">#26084</a>)</li>\n<li>Fixed custom agent <code>model</code> field in <code>.claude/agents/*.md</code> being ignored when spawning team teammates (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26064\">#26064</a>)</li>\n<li>Fixed plan mode being lost after context compaction, causing the model to switch from planning to implementation mode (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26061\">#26061</a>)</li>\n<li>Fixed <code>alwaysThinkingEnabled: true</code> in settings.json not enabling thinking mode on Bedrock and Vertex providers (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26074\">#26074</a>)</li>\n<li>Fixed <code>tool_decision</code> OTel telemetry event not being emitted in headless/SDK mode (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26059\">#26059</a>)</li>\n<li>Fixed session name being lost after context compaction — renamed sessions now preserve their custom title through compaction (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26121\">#26121</a>)</li>\n<li>Increased initial session count in resume picker from 10 to 50 for faster session discovery (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26123\">#26123</a>)</li>\n<li>Windows: fixed worktree session matching when drive letter casing differs (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26123\">#26123</a>)</li>\n<li>Fixed <code>/resume &lt;session-id&gt;</code> failing to find sessions whose first message exceeds 16KB (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25920\">#25920</a>)</li>\n<li>Fixed \"Always allow\" on multiline bash commands creating invalid permission patterns that corrupt settings (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25909\">#25909</a>)</li>\n<li>Fixed React crash (error <a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/31\">#31</a>) when a skill's <code>argument-hint</code> in SKILL.md frontmatter uses YAML sequence syntax (e.g., <code>[topic: foo | bar]</code>) — the value is now properly coerced to a string (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25826\">#25826</a>)</li>\n<li>Fixed crash when using <code>/fork</code> on sessions that used web search — null entries in search results from transcript deserialization are now handled gracefully (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25811\">#25811</a>)</li>\n<li>Fixed read-only git commands triggering FSEvents file watcher loops on macOS by adding --no-optional-locks flag (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25750\">#25750</a>)</li>\n<li>Fixed custom agents and skills not being discovered when running from a git worktree — project-level <code>.claude/agents/</code> and <code>.claude/skills/</code> from the main repository are now included (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25816\">#25816</a>)</li>\n<li>Fixed non-interactive subcommands like <code>claude doctor</code> and <code>claude plugin validate</code> being blocked inside nested Claude sessions (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25803\">#25803</a>)</li>\n<li>Windows: Fixed the same CLAUDE.md file being loaded twice when drive letter casing differs between paths (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25756\">#25756</a>)</li>\n<li>Fixed inline code spans in markdown being incorrectly parsed as bash commands (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25792\">#25792</a>)</li>\n<li>Fixed teammate spinners not respecting custom spinnerVerbs from settings (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25748\">#25748</a>)</li>\n<li>Fixed shell commands permanently failing after a command deletes its own working directory (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26136\">#26136</a>)</li>\n<li>Fixed hooks (PreToolUse, PostToolUse) silently failing to execute on Windows by using Git Bash instead of cmd.exe (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25981\">#25981</a>)</li>\n<li>Fixed LSP <code>findReferences</code> and other location-based operations returning results from gitignored files (e.g., <code>node_modules/</code>, <code>venv/</code>) (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26051\">#26051</a>)</li>\n<li>Moved config backup files from home directory root to <code>~/.claude/backups/</code> to reduce home directory clutter (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26130\">#26130</a>)</li>\n<li>Fixed sessions with large first prompts (&gt;16KB) disappearing from the /resume list (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26140\">#26140</a>)</li>\n<li>Fixed shell functions with double-underscore prefixes (e.g., <code>__git_ps1</code>) not being preserved across shell sessions (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25824\">#25824</a>)</li>\n<li>Fixed spinner showing \"0 tokens\" counter before any tokens have been received (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26105\">#26105</a>)</li>\n<li>VSCode: Fixed conversation messages appearing dimmed while the AskUserQuestion dialog is open (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26078\">#26078</a>)</li>\n<li>Fixed background tasks failing in git worktrees due to remote URL resolution reading from worktree-specific gitdir instead of the main repository config (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26065\">#26065</a>)</li>\n<li>Fixed Right Alt key leaving visible <code>[25~</code> escape sequence residue in the input field on Windows/Git Bash terminals (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25943\">#25943</a>)</li>\n<li>The <code>/rename</code> command now updates the terminal tab title by default (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/25789\">#25789</a>)</li>\n<li>Fixed Edit tool silently corrupting Unicode curly quotes (\\u201c\\u201d \\u2018\\u2019) by replacing them with straight quotes when making edits (<a class=\"issue-link js-issue-link\" href=\"https://github.com/anthropics/claude-code/issues/26141\">#26141</a>)</li>\n<li>Fixed OSC 8 hyperlinks only being clickable on the first line when link text wraps across multiple terminal lines.</li>\n</ul>",
      "image_url": "",
      "published": "2026-02-18T21:38:45Z",
      "collected_at": "2026-02-19T11:52:02.322700+00:00",
      "ingest_batch_id": "20260219-115202",
      "tier": "tier1",
      "type": "release",
      "source_reliability": 0.79,
      "freshness": 0.733,
      "tier1_quick_score": 3.759,
      "v2_slot": "agent_tooling_releases",
      "v2_prefilter_score": 3.723,
      "llm_label_source": "heuristic",
      "llm_category": "release",
      "llm_summary_1line": "What's changed Fixed FileWriteTool line counting to preserve intentional trailing blank lines instead of stripping them with trimEnd() . Fixed Windows terminal rendering bugs caused by os.EOL ( \\r\\n ) in display code...",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.6,
      "v2_source_bias": 0.0,
      "v2_topical_bias": 0.2,
      "v2_final_score": 2.24,
      "summary_1line": "What's changed Fixed FileWriteTool line counting to preserve intentional trailing blank lines instead of stripping them with trimEnd() . Fixed Windows terminal rendering bugs caused by os.EOL ( \\r\\n ) in display code...",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.468,
      "v2_global_score": 2.708
    },
    {
      "id": "9d95a891a81b27c3",
      "source": "openai_blog",
      "source_weight": 2.0,
      "title": "Beyond rate limits: scaling access to Codex and Sora",
      "url": "https://openai.com/index/beyond-rate-limits",
      "summary": "How OpenAI built a real-time access system combining rate limits, usage tracking, and credits to power continuous access to Sora and Codex.",
      "image_url": "",
      "published": "Fri, 13 Feb 2026 09:00:00 GMT",
      "collected_at": "2026-02-19T11:52:02.322700+00:00",
      "ingest_batch_id": "20260219-115202",
      "tier": "tier1",
      "type": "news",
      "source_reliability": 0.79,
      "freshness": 0.153,
      "tier1_quick_score": 2.87,
      "v2_slot": "frontier_official",
      "v2_prefilter_score": 2.943,
      "llm_label_source": "heuristic",
      "llm_category": "platform",
      "llm_summary_1line": "How OpenAI built a real-time access system combining rate limits, usage tracking, and credits to power continuous access to Sora and Codex.",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.0,
      "v2_source_bias": 0.1,
      "v2_topical_bias": 0.2,
      "v2_final_score": 1.931,
      "summary_1line": "How OpenAI built a real-time access system combining rate limits, usage tracking, and credits to power continuous access to Sora and Codex.",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.683,
      "v2_global_score": 2.614
    },
    {
      "id": "42710d92908034f2",
      "source": "anthropic_newsroom",
      "source_weight": 1.8,
      "title": "Claude Opus 4 6",
      "url": "https://www.anthropic.com/news/claude-opus-4-6",
      "summary": "",
      "image_url": "",
      "published": "2026-02-17T17:46:31.000Z",
      "collected_at": "2026-02-19T11:52:02.322700+00:00",
      "ingest_batch_id": "20260219-115202",
      "tier": "tier1",
      "type": "news",
      "source_reliability": 0.79,
      "freshness": 0.568,
      "tier1_quick_score": 3.096,
      "v2_slot": "frontier_official",
      "v2_prefilter_score": 3.158,
      "llm_label_source": "heuristic",
      "llm_category": "platform",
      "llm_summary_1line": "Claude Opus 4 6",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.0,
      "v2_source_bias": 0.06,
      "v2_topical_bias": 0.0,
      "v2_final_score": 1.774,
      "summary_1line": "Claude Opus 4 6",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.683,
      "v2_global_score": 2.457
    },
    {
      "id": "c58d7596e7e871ef",
      "source": "openai_codex_releases",
      "source_weight": 2.2,
      "title": "0.104.0",
      "url": "https://github.com/openai/codex/releases/tag/rust-v0.104.0",
      "summary": "<h2>New Features</h2>\n<ul>\n<li>Added <code>WS_PROXY</code>/<code>WSS_PROXY</code> environment support (including lowercase variants) for websocket proxying in the network proxy. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11784\">#11784</a>)</li>\n<li>App-server v2 now emits notifications when threads are archived or unarchived, enabling clients to react without polling. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12030\">#12030</a>)</li>\n<li>Protocol/core now carry distinct approval IDs for command approvals to support multiple approvals within a single shell command execution flow. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12051\">#12051</a>)</li>\n</ul>\n<h2>Bug Fixes</h2>\n<ul>\n<li><code>Ctrl+C</code>/<code>Ctrl+D</code> now cleanly exits the cwd-change prompt during resume/fork flows instead of implicitly selecting an option. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12040\">#12040</a>)</li>\n<li>Reduced false-positive safety-check downgrade behavior by relying on the response header model (and websocket top-level events) rather than the response body model slug. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12061\">#12061</a>)</li>\n</ul>\n<h2>Documentation</h2>\n<ul>\n<li>Updated docs and schemas to cover websocket proxy configuration, new thread archive/unarchive notifications, and the command approval ID plumbing. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11784\">#11784</a>, <a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12030\">#12030</a>, <a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12051\">#12051</a>)</li>\n</ul>\n<h2>Chores</h2>\n<ul>\n<li>Made the Rust release workflow resilient to <code>npm publish</code> attempts for an already-published version. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12044\">#12044</a>)</li>\n<li>Standardized remote compaction test mocking and refreshed related snapshots to align with the default production-shaped behavior. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12050\">#12050</a>)</li>\n</ul>\n<h2>Changelog</h2>\n<p>Full Changelog: <a class=\"commit-link\" href=\"https://github.com/openai/codex/compare/rust-v0.103.0...rust-v0.104.0\"><tt>rust-v0.103.0...rust-v0.104.0</tt></a></p>\n<ul>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11784\">#11784</a> feat(network-proxy): add websocket proxy env support <a class=\"user-mention notranslate\" href=\"https://github.com/viyatb-oai\">@viyatb-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12044\">#12044</a> don't fail if an npm publish attempt is for an existing version. <a class=\"user-mention notranslate\" href=\"https://github.com/iceweasel-oai\">@iceweasel-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12040\">#12040</a> tui: exit session on Ctrl+C in cwd change prompt <a class=\"user-mention notranslate\" href=\"https://github.com/charley-oai\">@charley-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12030\">#12030</a> app-server: Emit thread archive/unarchive notifications <a class=\"user-mention notranslate\" href=\"https://github.com/euroelessar\">@euroelessar</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12061\">#12061</a> Chore: remove response model check and rely on header model for downgrade <a class=\"user-mention notranslate\" href=\"https://github.com/shijie-oai\">@shijie-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12051\">#12051</a> feat(core): plumb distinct approval ids for command approvals <a class=\"user-mention notranslate\" href=\"https://github.com/owenlin0\">@owenlin0</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/12050\">#12050</a> Unify remote compaction snapshot mocks around default endpoint behavior <a class=\"user-mention notranslate\" href=\"https://github.com/charley-oai\">@charley-oai</a></li>\n</ul>",
      "image_url": "",
      "published": "2026-02-18T07:13:02Z",
      "collected_at": "2026-02-19T11:52:02.322700+00:00",
      "ingest_batch_id": "20260219-115202",
      "tier": "tier1",
      "type": "release",
      "source_reliability": 0.79,
      "freshness": 0.566,
      "tier1_quick_score": 3.61,
      "v2_slot": "agent_tooling_releases",
      "v2_prefilter_score": 3.556,
      "llm_label_source": "heuristic",
      "llm_category": "release",
      "llm_summary_1line": "New Features Added WS_PROXY / WSS_PROXY environment support (including lowercase variants) for websocket proxying in the network proxy. ( #11784 ) App-server v2 now emits notifications when threads are archived or una...",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.6,
      "v2_source_bias": 0.0,
      "v2_topical_bias": 0.2,
      "v2_final_score": 2.19,
      "summary_1line": "New Features Added WS_PROXY / WSS_PROXY environment support (including lowercase variants) for websocket proxying in the network proxy. ( #11784 ) App-server v2 now emits notifications when threads are archived or una...",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.468,
      "v2_global_score": 2.658
    },
    {
      "id": "c35812ccca3ce7be",
      "source": "openai_blog",
      "source_weight": 2.0,
      "title": "Harness engineering: leveraging Codex in an agent-first world",
      "url": "https://openai.com/index/harness-engineering",
      "summary": "By Ryan Lopopolo, Member of the Technical Staff",
      "image_url": "",
      "published": "Wed, 11 Feb 2026 09:00:00 GMT",
      "collected_at": "2026-02-19T11:52:02.322700+00:00",
      "ingest_batch_id": "20260219-115202",
      "tier": "tier1",
      "type": "news",
      "source_reliability": 0.79,
      "freshness": 0.084,
      "tier1_quick_score": 2.807,
      "v2_slot": "frontier_official",
      "v2_prefilter_score": 2.874,
      "llm_label_source": "heuristic",
      "llm_category": "platform",
      "llm_summary_1line": "By Ryan Lopopolo, Member of the Technical Staff",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.0,
      "v2_source_bias": 0.1,
      "v2_topical_bias": 0.2,
      "v2_final_score": 1.917,
      "summary_1line": "By Ryan Lopopolo, Member of the Technical Staff",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.683,
      "v2_global_score": 2.6
    },
    {
      "id": "c16b69a1be247646",
      "source": "openai_blog",
      "source_weight": 2.0,
      "title": "GPT-5.2 derives a new result in theoretical physics",
      "url": "https://openai.com/index/new-result-theoretical-physics",
      "summary": "A new preprint shows GPT-5.2 proposing a new formula for a gluon amplitude, later formally proved and verified by OpenAI and academic collaborators.",
      "image_url": "",
      "published": "Fri, 13 Feb 2026 11:00:00 GMT",
      "collected_at": "2026-02-19T11:52:02.322700+00:00",
      "ingest_batch_id": "20260219-115202",
      "tier": "tier1",
      "type": "news",
      "source_reliability": 0.79,
      "freshness": 0.157,
      "tier1_quick_score": 2.873,
      "v2_slot": "frontier_official",
      "v2_prefilter_score": 2.947,
      "llm_label_source": "heuristic",
      "llm_category": "platform",
      "llm_summary_1line": "A new preprint shows GPT-5.2 proposing a new formula for a gluon amplitude, later formally proved and verified by OpenAI and academic collaborators.",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.2,
      "v2_source_bias": 0.1,
      "v2_topical_bias": 0.0,
      "v2_final_score": 1.891,
      "summary_1line": "A new preprint shows GPT-5.2 proposing a new formula for a gluon amplitude, later formally proved and verified by OpenAI and academic collaborators.",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.683,
      "v2_global_score": 2.574
    },
    {
      "id": "a424c079248a48dd",
      "source": "arxiv_cs_ai",
      "source_weight": 0.85,
      "title": "Towards a Science of AI Agent Reliability",
      "url": "http://arxiv.org/abs/2602.16666v1",
      "summary": "AI agents are increasingly deployed to execute important tasks. While rising accuracy scores on standard benchmarks suggest rapid progress, many agents still continue to fail in practice. This discrepancy highlights a fundamental limitation of current evaluations: compressing agent behavior into a single success metric obscures critical operational flaws. Notably, it ignores whether agents behave consistently across runs, withstand perturbations, fail predictably, or have bounded error severity. Grounded in safety-critical engineering, we provide a holistic performance profile by proposing twelve concrete metrics that decompose agent reliability along four key dimensions: consistency, robustness, predictability, and safety. Evaluating 14 agentic models across two complementary benchmarks, we find that recent capability gains have only yielded small improvements in reliability. By exposing these persistent limitations, our metrics complement traditional evaluations while offering tools for reasoning about how agents perform, degrade, and fail.",
      "image_url": "",
      "published": "2026-02-18T18:05:44Z",
      "collected_at": "2026-02-19T11:52:02.322700+00:00",
      "ingest_batch_id": "20260219-115202",
      "tier": "tier1",
      "type": "paper",
      "source_reliability": 0.79,
      "freshness": 0.829,
      "tier1_quick_score": 2.37,
      "v2_slot": "research_watch",
      "v2_prefilter_score": 2.469,
      "llm_label_source": "heuristic",
      "llm_category": "research",
      "llm_summary_1line": "AI agents are increasingly deployed to execute important tasks. While rising accuracy scores on standard benchmarks suggest rapid progress, many agents still continue to fail in practice. This discrepancy highlights a...",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.65,
      "v2_source_bias": -0.35,
      "v2_topical_bias": 0.2,
      "v2_final_score": 2.227,
      "summary_1line": "New framework decomposes AI agent reliability into 12 metrics across consistency, robustness, predictability, and safety—revealing capability gains don't translate to production stability.",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.339,
      "v2_global_score": 2.566
    },
    {
      "id": "79bdc4c952b1d60e",
      "source": "arxiv_cs_lg",
      "source_weight": 0.85,
      "title": "A Scalable Approach to Solving Simulation-Based Network Security Games",
      "url": "http://arxiv.org/abs/2602.16564v1",
      "summary": "We introduce MetaDOAR, a lightweight meta-controller that augments the Double Oracle / PSRO paradigm with a learned, partition-aware filtering layer and Q-value caching to enable scalable multi-agent reinforcement learning on very large cyber-network environments. MetaDOAR learns a compact state projection from per node structural embeddings to rapidly score and select a small subset of devices (a top-k partition) on which a conventional low-level actor performs focused beam search utilizing a critic agent. Selected candidate actions are evaluated with batched critic forwards and stored in an LRU cache keyed by a quantized state projection and local action identifiers, dramatically reducing redundant critic computation while preserving decision quality via conservative k-hop cache invalidation. Empirically, MetaDOAR attains higher player payoffs than SOTA baselines on large network topologies, without significant scaling issues in terms of memory usage or training time. This contribution provide a practical, theoretically motivated path to efficient hierarchical policy learning for large-scale networked decision problems.",
      "image_url": "",
      "published": "2026-02-18T16:07:01Z",
      "collected_at": "2026-02-19T11:52:02.322700+00:00",
      "ingest_batch_id": "20260219-115202",
      "tier": "tier1",
      "type": "paper",
      "source_reliability": 0.79,
      "freshness": 0.815,
      "tier1_quick_score": 2.348,
      "v2_slot": "research_watch",
      "v2_prefilter_score": 2.455,
      "llm_label_source": "heuristic",
      "llm_category": "research",
      "llm_summary_1line": "We introduce MetaDOAR, a lightweight meta-controller that augments the Double Oracle / PSRO paradigm with a learned, partition-aware filtering layer and Q-value caching to enable scalable multi-agent reinforcement lea...",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.65,
      "v2_source_bias": -0.35,
      "v2_topical_bias": 0.2,
      "v2_final_score": 2.225,
      "summary_1line": "MetaDOAR applies hierarchical RL with state partitioning and Q-value caching to scale multi-agent game solving on large network topologies.",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.339,
      "v2_global_score": 2.564
    },
    {
      "id": "b7dd9d05bcdf917e",
      "source": "claude_agent_sdk_python_releases",
      "source_weight": 1.3,
      "title": "v0.1.38",
      "url": "https://github.com/anthropics/claude-agent-sdk-python/releases/tag/v0.1.38",
      "summary": "<h3>Internal/Other Changes</h3>\n<ul>\n<li>Updated bundled Claude CLI to version 2.1.47</li>\n</ul>\n<hr />\n<p><strong>PyPI:</strong> <a href=\"https://pypi.org/project/claude-agent-sdk/0.1.38/\" rel=\"nofollow\">https://pypi.org/project/claude-agent-sdk/0.1.38/</a></p>\n<div class=\"highlight highlight-source-shell notranslate position-relative overflow-auto\"><pre>pip install claude-agent-sdk==0.1.38</pre></div>",
      "image_url": "",
      "published": "2026-02-18T21:57:56Z",
      "collected_at": "2026-02-19T11:52:02.322700+00:00",
      "ingest_batch_id": "20260219-115202",
      "tier": "tier1",
      "type": "release",
      "source_reliability": 0.79,
      "freshness": 0.737,
      "tier1_quick_score": 2.863,
      "v2_slot": "agent_tooling_releases",
      "v2_prefilter_score": 2.827,
      "llm_label_source": "heuristic",
      "llm_category": "release",
      "llm_summary_1line": "Internal/Other Changes Updated bundled Claude CLI to version 2.1.47 PyPI: https://pypi.org/project/claude-agent-sdk/0.1.38/ pip install claude-agent-sdk==0.1.38",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.25,
      "v2_source_bias": 0.0,
      "v2_topical_bias": 0.2,
      "v2_final_score": 1.996,
      "summary_1line": "Internal/Other Changes Updated bundled Claude CLI to version 2.1.47 PyPI: https://pypi.org/project/claude-agent-sdk/0.1.38/ pip install claude-agent-sdk==0.1.38",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.468,
      "v2_global_score": 2.464
    },
    {
      "id": "6ed48b697f4e1625",
      "source": "anthropic_newsroom",
      "source_weight": 1.8,
      "title": "Claude Sonnet 4 6",
      "url": "https://www.anthropic.com/news/claude-sonnet-4-6",
      "summary": "",
      "image_url": "",
      "published": "2026-02-17T17:45:22.000Z",
      "collected_at": "2026-02-19T11:52:02.322700+00:00",
      "ingest_batch_id": "20260219-115202",
      "tier": "tier1",
      "type": "news",
      "source_reliability": 0.79,
      "freshness": 0.568,
      "tier1_quick_score": 3.096,
      "v2_slot": "frontier_official",
      "v2_prefilter_score": 3.158,
      "llm_label_source": "heuristic",
      "llm_category": "platform",
      "llm_summary_1line": "Claude Sonnet 4 6",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.0,
      "v2_source_bias": 0.06,
      "v2_topical_bias": 0.0,
      "v2_final_score": 1.774,
      "summary_1line": "Claude Sonnet 4 6",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.683,
      "v2_global_score": 2.457
    },
    {
      "id": "c8740b36f03df678",
      "source": "anthropic_newsroom",
      "source_weight": 1.8,
      "title": "Anthropic Rwanda Mou",
      "url": "https://www.anthropic.com/news/anthropic-rwanda-mou",
      "summary": "",
      "image_url": "",
      "published": "2026-02-17T10:01:21.000Z",
      "collected_at": "2026-02-19T11:52:02.322700+00:00",
      "ingest_batch_id": "20260219-115202",
      "tier": "tier1",
      "type": "news",
      "source_reliability": 0.79,
      "freshness": 0.515,
      "tier1_quick_score": 3.039,
      "v2_slot": "frontier_official",
      "v2_prefilter_score": 3.105,
      "llm_label_source": "heuristic",
      "llm_category": "platform",
      "llm_summary_1line": "Anthropic Rwanda Mou",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.0,
      "v2_source_bias": 0.06,
      "v2_topical_bias": 0.0,
      "v2_final_score": 1.763,
      "summary_1line": "Anthropic Rwanda Mou",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.683,
      "v2_global_score": 2.446
    },
    {
      "id": "5ded8551ab4e9f3f",
      "source": "huggingface_blog",
      "source_weight": 1.1,
      "title": "IBM and UC Berkeley Diagnose Why Enterprise Agents Fail Using IT-Bench and MAST",
      "url": "https://huggingface.co/blog/ibm-research/itbenchandmast",
      "summary": "",
      "image_url": "",
      "published": "Wed, 18 Feb 2026 16:15:45 GMT",
      "collected_at": "2026-02-19T11:52:02.322700+00:00",
      "ingest_batch_id": "20260219-115202",
      "tier": "tier1",
      "type": "research",
      "source_reliability": 0.79,
      "freshness": 0.816,
      "tier1_quick_score": 2.6,
      "v2_slot": "research_watch",
      "v2_prefilter_score": 2.706,
      "llm_label_source": "heuristic",
      "llm_category": "platform",
      "llm_summary_1line": "IBM and UC Berkeley Diagnose Why Enterprise Agents Fail Using IT-Bench and MAST",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.0,
      "v2_source_bias": 0.0,
      "v2_topical_bias": 0.2,
      "v2_final_score": 2.022,
      "summary_1line": "IBM and UC Berkeley Diagnose Why Enterprise Agents Fail Using IT-Bench and MAST",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.339,
      "v2_global_score": 2.361
    }
  ]
}