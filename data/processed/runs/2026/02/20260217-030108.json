{
  "run_at": "2026-02-17T03:01:08.742397+00:00",
  "item_count": 13,
  "items": [
    {
      "id": "0b9784e78fa0f8a8",
      "source": "simon_willison",
      "source_weight": 1.25,
      "title": "Two new Showboat tools: Chartroom and datasette-showboat",
      "url": "https://simonwillison.net/2026/Feb/17/chartroom-and-datasette-showboat/#atom-everything",
      "summary": "<p>I <a href=\"https://simonwillison.net/2026/Feb/10/showboat-and-rodney/\">introduced Showboat</a> a week ago - my CLI tool that helps coding agents create Markdown documents that demonstrate the code that they have created. I've been finding new ways to use it on a daily basis, and I've just released two new tools to help get the best out of the Showboat pattern. <a href=\"https://github.com/simonw/chartroom\">Chartroom</a> is a CLI charting tool that works well with Showboat, and <a href=\"https://github.com/simonw/datasette-showboat\">datasette-showboat</a> lets Showboat's new remote publishing feature incrementally push documents to a Datasette instance.</p>\n\n<ul>\n  <li><a href=\"https://simonwillison.net/2026/Feb/17/chartroom-and-datasette-showboat/#showboat-remote-publishing\">Showboat remote publishing</a></li>\n  <li><a href=\"https://simonwillison.net/2026/Feb/17/chartroom-and-datasette-showboat/#datasette-showboat\">datasette-showboat</a></li>\n  <li><a href=\"https://simonwillison.net/2026/Feb/17/chartroom-and-datasette-showboat/#chartroom\">Chartroom</a></li>\n  <li><a href=\"https://simonwillison.net/2026/Feb/17/chartroom-and-datasette-showboat/#how-i-built-chartroom\">How I built Chartroom</a></li>\n  <li><a href=\"https://simonwillison.net/2026/Feb/17/chartroom-and-datasette-showboat/#the-burgeoning-showboat-ecosystem\">The burgeoning Showboat ecosystem</a></li>\n</ul>\n\n<h4 id=\"showboat-remote-publishing\">Showboat remote publishing</h4>\n<p>I normally use Showboat in Claude Code for web (see <a href=\"https://simonwillison.net/2026/Feb/16/rodney-claude-code/\">note from this morning</a>). I've used it in several different projects in the past few days, each of them with a prompt that looks something like this:</p>\n<blockquote>\n<p><code>Use \"uvx showboat --help\" to perform a very thorough investigation of what happens if you use the Python sqlite-chronicle and sqlite-history-json libraries against the same SQLite database table</code></p>\n</blockquote>\n<p>Here's <a href=\"https://github.com/simonw/research/blob/main/sqlite-chronicle-vs-history-json/demo.md\">the resulting document</a>.</p>\n<p>Just telling Claude Code to run <code>uvx showboat --help</code> is enough for it to learn how to use the tool - the <a href=\"https://github.com/simonw/showboat/blob/main/help.txt\">help text</a> is designed to work as a sort of ad-hoc Skill document.</p>\n<p>The one catch with this approach is that I can't <em>see</em> the new Showboat document until it's finished. I have to wait for Claude to commit the document plus embedded screenshots and push that to a branch in my GitHub repo - then I can view it through the GitHub interface.</p>\n<p>For a while I've been thinking it would be neat to have a remote web server of my own which Claude instances can submit updates to while they are working. Then this morning I realized Showboat might be the ideal mechanism to set that up...</p>\n<p>Showboat <a href=\"https://github.com/simonw/showboat/releases/tag/v0.6.0\">v0.6.0</a> adds a new \"remote\" feature. It's almost invisible to users of the tool itself, instead being configured by an environment variable.</p>\n<p>Set a variable like this:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">export</span> SHOWBOAT_REMOTE_URL=https://www.example.com/submit<span class=\"pl-k\">?</span>token=xyz</pre></div>\n<p>And every time you run a <code>showboat init</code> or <code>showboat note</code> or <code>showboat exec</code> or <code>showboat image</code> command the resulting document fragments will be POSTed to that API endpoint, in addition to the Showboat Markdown file itself being updated.</p>\n<p>There are <a href=\"https://github.com/simonw/showboat/blob/v0.6.0/README.md#remote-document-streaming\">full details in the Showboat README</a> - it's a very simple API format, using regular POST form variables or a multipart form upload for the image attached to <code>showboat image</code>.</p>\n<h4 id=\"datasette-showboat\">datasette-showboat</h4>\n<p>It's simple enough to build a webapp to receive these updates from Showboat, but I needed one that I could easily deploy and would work well with the rest of my personal ecosystem.</p>\n<p>So I had Claude Code write me a Datasette plugin that could act as a Showboat remote endpoint. I actually had this building at the same time as the Showboat remote feature, a neat example of running <a href=\"https://simonwillison.net/2025/Oct/5/parallel-coding-agents/\">parallel agents</a>.</p>\n<p><strong><a href=\"https://github.com/simonw/datasette-showboat\">datasette-showboat</a></strong> is a Datasette plugin that adds a <code>/-/showboat</code> endpoint to Datasette for viewing documents and a <code>/-/showboat/receive</code> endpoint for receiving updates from Showboat.</p>\n<p>Here's a very quick way to try it out:</p>\n<div class=\"highlight highlight-source-shell\"><pre>uvx --with datasette-showboat --prerelease=allow \\\n  datasette showboat.db --create \\\n  -s plugins.datasette-showboat.database showboat \\\n  -s plugins.datasette-showboat.token secret123 \\\n  --root --secret cookie-secret-123</pre></div>\n<p>Click on the sign in as root link that shows up in the console, then navigate to <a href=\"http://127.0.0.1:8001/-/showboat\">http://127.0.0.1:8001/-/showboat</a> to see the interface.</p>\n<p>Now set your environment variable to point to this instance:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-k\">export</span> SHOWBOAT_REMOTE_URL=<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>http://127.0.0.1:8001/-/showboat/receive?token=secret123<span class=\"pl-pds\">\"</span></span></pre></div>\n<p>And run Showboat like this:</p>\n<div class=\"highlight highlight-source-shell\"><pre>uvx showboat init demo.md <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Showboat Feature Demo<span class=\"pl-pds\">\"</span></span></pre></div>\n<p>Refresh that page and you should see this:</p>\n<p><img alt=\"Title: Showboat. Remote viewer for Showboat documents. Showboat Feature Demo 2026-02-17 00:06 · 6 chunks, UUID. To send showboat output to this server, set the SHOWBOAT_REMOTE_URL environment variable: export SHOWBOAT_REMOTE_URL=&quot;http://127.0.0.1:8001/-/showboat/receive?token=your-token&quot;\" src=\"https://static.simonwillison.net/static/2026/datasette-showboat-documents.jpg\" /></p>\n<p>Click through to the document, then start Claude Code or Codex or your agent of choice and prompt:</p>\n<blockquote>\n<p><code>Run 'uvx showboat --help' and then use showboat to add to the existing demo.md document with notes and exec and image to demonstrate the tool - fetch a placekitten for the image demo.</code></p>\n</blockquote>\n<p>The <code>init</code> command assigns a UUID and title and sends those up to Datasette.</p>\n<p><img alt=\"Animated demo - in the foreground a terminal window runs Claude Code, which executes various Showboat commands. In the background a Firefox window where the Showboat Feature Demo adds notes then some bash commands, then a placekitten image.\" src=\"https://static.simonwillison.net/static/2026/datasette-showboat.gif\" /></p>\n<p>The best part of this is that it works in Claude Code for web. Run the plugin on a server somewhere (an exercise left up to the reader - I use <a href=\"https://fly.io/\">Fly.io</a> to host mine) and set that <code>SHOWBOAT_REMOTE_URL</code> environment variable in your Claude environment, then any time you tell it to use Showboat the document it creates will be transmitted to your server and viewable in real time.</p>\n<p>I built <a href=\"https://simonwillison.net/2026/Feb/10/showboat-and-rodney/#rodney-cli-browser-automation-designed-to-work-with-showboat\">Rodney</a>, a CLI browser automation tool, specifically to work with Showboat. It makes it easy to have a Showboat document load up web pages, interact with them via clicks or injected JavaScript and captures screenshots to embed in the Showboat document and show the effects.</p>\n<p>This is wildly useful for hacking on web interfaces using Claude Code for web, especially when coupled with the new remote publishing feature. I only got this stuff working this morning and I've already had several sessions where Claude Code has published screenshots of its work in progress, which I've then been able to provide feedback on directly in the Claude session while it's still working.</p>\n<h3 id=\"chartroom\">Chartroom</h3>\n<p>A few days ago I had another idea for a way to extend the Showboat ecosystem: what if Showboat documents could easily include charts?</p>\n<p>I sometimes fire up Claude Code for data analysis tasks, often telling it to download a SQLite database and then run queries against it to figure out interesting things from the data.</p>\n<p>With a simple CLI tool that produced PNG images I could have Claude use Showboat to build a document with embedded charts to help illustrate its findings.</p>\n<p><strong><a href=\"https://github.com/simonw/chartroom\">Chartroom</a></strong> is exactly that. It's effectively a thin wrapper around the excellent <a href=\"https://matplotlib.org/\">matplotlib</a> Python library, designed to be used by coding agents to create charts that can be embedded in Showboat documents.</p>\n<p>Here's how to render a simple bar chart:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c1\">echo</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>name,value</span>\n<span class=\"pl-s\">Alice,42</span>\n<span class=\"pl-s\">Bob,28</span>\n<span class=\"pl-s\">Charlie,35</span>\n<span class=\"pl-s\">Diana,51</span>\n<span class=\"pl-s\">Eve,19<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">|</span> uvx chartroom bar --csv \\\n  --title <span class=\"pl-s\"><span class=\"pl-pds\">'</span>Sales by Person<span class=\"pl-pds\">'</span></span> --ylabel <span class=\"pl-s\"><span class=\"pl-pds\">'</span>Sales<span class=\"pl-pds\">'</span></span></pre></div>\n<p><a href=\"https://raw.githubusercontent.com/simonw/chartroom/8812afc02e1310e9eddbb56508b06005ff2c0ed5/demo/1f6851ec-2026-02-14.png\" rel=\"noopener noreferrer nofollow\" target=\"_blank\"><img alt=\"A chart of those numbers, with a title and y-axis label\" src=\"https://raw.githubusercontent.com/simonw/chartroom/8812afc02e1310e9eddbb56508b06005ff2c0ed5/demo/1f6851ec-2026-02-14.png\" /></a></p>\n<p>It can also do line charts, bar charts, scatter charts, and histograms - as seen in <a href=\"https://github.com/simonw/chartroom/blob/0.2.1/demo/README.md\">this demo document</a> that was built using Showboat.</p>\n<p>Chartroom can also generate alt text. If you add <code>-f alt</code> to the above it will output the alt text for the chart instead of the image:</p>\n<div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c1\">echo</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>name,value</span>\n<span class=\"pl-s\">Alice,42</span>\n<span class=\"pl-s\">Bob,28</span>\n<span class=\"pl-s\">Charlie,35</span>\n<span class=\"pl-s\">Diana,51</span>\n<span class=\"pl-s\">Eve,19<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">|</span> uvx chartroom bar --csv \\\n  --title <span class=\"pl-s\"><span class=\"pl-pds\">'</span>Sales by Person<span class=\"pl-pds\">'</span></span> --ylabel <span class=\"pl-s\"><span class=\"pl-pds\">'</span>Sales<span class=\"pl-pds\">'</span></span> -f alt</pre></div>\n<p>Outputs:</p>\n<pre><code>Sales by Person. Bar chart of value by name — Alice: 42, Bob: 28, Charlie: 35, Diana: 51, Eve: 19\n</code></pre>\n<p>Or you can use <code>-f html</code> or <code>-f markdown</code> to get the image tag with alt text directly:</p>\n<div class=\"highlight highlight-text-md\"><pre><span class=\"pl-s\">![</span>Sales by Person. Bar chart of value by name — Alice: 42, Bob: 28, Charlie: 35, Diana: 51, Eve: 19<span class=\"pl-s\">]</span><span class=\"pl-s\">(</span><span class=\"pl-corl\">/Users/simon/chart-7.png</span><span class=\"pl-s\">)</span></pre></div>\n<p>I added support for Markdown images with alt text to Showboat in <a href=\"https://github.com/simonw/showboat/releases/tag/v0.5.0\">v0.5.0</a>, to complement this feature of Chartroom.</p>\n<p>Finally, Chartroom has support for different <a href=\"https://matplotlib.org/stable/gallery/style_sheets/style_sheets_reference.html\">matplotlib styles</a>. I had Claude build a Showboat document to demonstrate these all in one place - you can see that at <a href=\"https://github.com/simonw/chartroom/blob/main/demo/styles.md\">demo/styles.md</a>.</p>\n<h4 id=\"how-i-built-chartroom\">How I built Chartroom</h4>\n<p>I started the Chartroom repository with my <a href=\"https://github.com/simonw/click-app\">click-app</a> cookiecutter template, then told a fresh Claude Code for web session:</p>\n<blockquote>\n<p>We are building a Python CLI tool which uses matplotlib to generate a PNG image containing a chart. It will have multiple sub commands for different chart types, controlled by command line options. Everything you need to know to use it will be available in the single \"chartroom --help\" output.</p>\n<p>It will accept data from files or standard input as CSV or TSV or JSON, similar to how sqlite-utils accepts data - clone simonw/sqlite-utils to /tmp for reference there. Clone matplotlib/matplotlib for reference as well</p>\n<p>It will also accept data from --sql path/to/sqlite.db \"select ...\" which runs in read-only mode</p>\n<p>Start by asking clarifying questions - do not use the ask user tool though it is broken - and generate a spec for me to approve</p>\n<p>Once approved proceed using red/green TDD running tests with \"uv run pytest\"</p>\n<p>Also while building maintain a demo/README.md document using the \"uvx showboat --help\" tool - each time you get a new chart type working commit the tests, implementation, root level\nREADME update and a new version of that demo/README.md document with an inline image demo of the new chart type (which should be a UUID image filename managed by the showboat image command and should be stored in the demo/ folder</p>\n<p>Make sure \"uv build\" runs cleanly without complaining about extra directories but also ensure dist/ and uv.lock are in gitignore</p>\n</blockquote>\n<p>This got most of the work done. You can see the rest <a href=\"https://github.com/simonw/chartroom/pulls?q=is%3Apr+is%3Aclosed\">in the PRs</a> that followed.</p>\n<h4 id=\"the-burgeoning-showboat-ecosystem\">The burgeoning Showboat ecosystem</h4>\n<p>The Showboat family of tools now consists of <a href=\"https://github.com/simonw/showboat\">Showboat</a> itself, <a href=\"https://github.com/simonw/rodney\">Rodney</a> for browser automation, <a href=\"https://github.com/simonw/chartroom\">Chartroom</a> for charting and <a href=\"https://github.com/simonw/datasette-showboat\">datasette-showboat</a> for streaming remote Showboat documents to Datasette.</p>\n<p>I'm enjoying how these tools can operate together based on a very loose set of conventions. If a tool can output a path to an image Showboat can include that image in a document. Any tool that can output text can be used with Showboat.</p>\n<p>I'll almost certainly be building more tools that fit this pattern. They're very quick to knock out!</p>\n<p>The environment variable mechanism for Showboat's remote streaming is a fun hack too - so far I'm just using it to stream documents somewhere else, but it's effectively a webhook extension mechanism that could likely be used for all sorts of things I haven't thought of yet.</p>\n    \n        <p>Tags: <a href=\"https://simonwillison.net/tags/projects\">projects</a>, <a href=\"https://simonwillison.net/tags/ai\">ai</a>, <a href=\"https://simonwillison.net/tags/datasette\">datasette</a>, <a href=\"https://simonwillison.net/tags/generative-ai\">generative-ai</a>, <a href=\"https://simonwillison.net/tags/llms\">llms</a>, <a href=\"https://simonwillison.net/tags/ai-assisted-programming\">ai-assisted-programming</a>, <a href=\"https://simonwillison.net/tags/coding-agents\">coding-agents</a>, <a href=\"https://simonwillison.net/tags/claude-code\">claude-code</a>, <a href=\"https://simonwillison.net/tags/showboat\">showboat</a></p>",
      "image_url": "https://static.simonwillison.net/static/2026/datasette-showboat-documents.jpg",
      "published": "2026-02-17T00:43:45+00:00",
      "collected_at": "2026-02-17T03:00:06.747953+00:00",
      "v2_slot": "practitioner_analysis",
      "freshness": 0.945,
      "source_reliability": 1.0,
      "v2_prefilter_score": 3.195,
      "type": "news",
      "llm_label_source": "llm",
      "llm_category": "release",
      "llm_summary_1line": "Showboat ecosystem expands with Chartroom (agent-driven charting) and datasette-showboat (live document streaming)—enables real-time visibility into Claude Code work.",
      "llm_why_1line": "Direct harness for coding agent output visibility; proven patterns for agent-driven documentation, charting, and feedback loops.",
      "v2_llm_score": 4.8,
      "v2_source_bias": 0.08,
      "v2_topical_bias": 0.2,
      "v2_final_score": 4.502,
      "summary_1line": "Showboat ecosystem expands with Chartroom (matplotlib CLI for agents) and datasette-showboat (real-time document streaming), enabling agents to produce documented demos with live chart publishing.",
      "why_it_matters": "Direct harness for coding agent output visibility; proven patterns for agent-driven documentation, charting, and feedback loops.",
      "v2_slot_priority": 0.621,
      "v2_global_score": 5.123
    },
    {
      "id": "a5330106c519e42a",
      "source": "hackernews_ai",
      "source_weight": 1.1,
      "title": "Agent-evals: Overlap, boundary, and metacognitive scoring for coding agents",
      "url": "https://thinkwright.ai/agent-evals",
      "summary": "<p>Article URL: <a href=\"https://thinkwright.ai/agent-evals\">https://thinkwright.ai/agent-evals</a></p>\n<p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47043129\">https://news.ycombinator.com/item?id=47043129</a></p>\n<p>Points: 1</p>\n<p># Comments: 0</p>",
      "image_url": "",
      "published": "Tue, 17 Feb 2026 02:49:57 +0000",
      "collected_at": "2026-02-17T03:00:06.747953+00:00",
      "v2_slot": "community_signal",
      "freshness": 0.989,
      "source_reliability": 1.0,
      "v2_prefilter_score": 3.089,
      "type": "news",
      "llm_label_source": "llm",
      "llm_category": "research",
      "llm_summary_1line": "Framework for evaluating coding agents using overlap, boundary, and metacognitive scoring to assess reliability and reasoning depth.",
      "llm_why_1line": "Core eval methodology for agents; limited concrete evidence without excerpt; needs reproducible benchmarks and code samples.",
      "v2_llm_score": 3.85,
      "v2_source_bias": 0.0,
      "v2_topical_bias": 0.2,
      "v2_final_score": 3.335,
      "summary_1line": "Novel eval framework for coding agents using overlap, boundary, and metacognitive scoring to measure agent reasoning quality beyond task completion.",
      "why_it_matters": "Core eval methodology for agents; limited concrete evidence without excerpt; needs reproducible benchmarks and code samples.",
      "v2_slot_priority": 0.632,
      "v2_global_score": 3.967
    },
    {
      "id": "3448c4e5eb803f1d",
      "source": "simon_willison",
      "source_weight": 1.25,
      "title": "Rodney and Claude Code for Desktop",
      "url": "https://simonwillison.net/2026/Feb/16/rodney-claude-code/#atom-everything",
      "summary": "<p>I'm a very heavy user of <a href=\"https://code.claude.com/docs/en/claude-code-on-the-web\">Claude Code on the web</a>, Anthropic's excellent but poorly named cloud version of Claude Code where everything runs in a container environment managed by them, greatly reducing the risk of anything bad happening to a computer I care about.</p>\n<p>I don't use the web interface at all (hence my dislike of the name) - I access it exclusively through their native iPhone and Mac desktop apps.</p>\n<p>Something I particularly appreciate about the desktop app is that it lets you see images that Claude is \"viewing\" via its <code>Read /path/to/image</code> tool. Here's what that looks like:</p>\n<p><img alt=\"Screenshot of a Claude Code session in Claude Desktop. Claude says: The debug page looks good - all items listed with titles and descriptions. Now let me check the nav\nmenu -  Analyzed menu image file - Bash uvx rodney open &quot;http://localhost:8765/&quot; 2&gt;&amp;1 &amp;&amp; uvx rodney click &quot;details.nav-menu summary&quot; 2&gt;&amp;1 &amp;% sleep 0.5 &amp;&amp; uvx rodney screenshot /tmp/menu.png 2&gt;&amp;1 Output reads: Datasette: test, Clicked, /tmp/menu.png - then it says Read /tmp/menu.png and reveals a screenshot of the Datasette interface with the nav menu open, showing only &quot;Debug&quot; and &quot;Log out&quot; options. Claude continues: The menu now has just &quot;Debug&quot; and “Log out&quot; — much cleaner. Both pages look good. Let me clean up the server and run the remaining tests.\" src=\"https://static.simonwillison.net/static/2026/rodney-claude-desktop.jpg\" /></p>\n<p>This means you can get a visual preview of what it's working on while it's working, without waiting for it to push code to GitHub for you to try out yourself later on.</p>\n<p>The prompt I used to trigger the above screenshot was:</p>\n<blockquote>\n<p><code>Run \"uvx rodney --help\" and then use Rodney to manually test the new pages and menu - look at screenshots from it and check you think they look OK</code></p>\n</blockquote>\n<p>I designed <a href=\"https://simonwillison.net/2026/Feb/10/showboat-and-rodney/#rodney-cli-browser-automation-designed-to-work-with-showboat\">Rodney</a> to have <a href=\"https://github.com/simonw/rodney/blob/main/help.txt\">--help output</a> that provides everything a coding agent needs to know in order to use the tool.</p>\n<p>The Claude iPhone app doesn't display opened images yet, so I <a href=\"https://twitter.com/simonw/status/2023432616066879606\">requested it as a feature</a> just now in a thread on Twitter.</p>\n\n    <p>Tags: <a href=\"https://simonwillison.net/tags/anthropic\">anthropic</a>, <a href=\"https://simonwillison.net/tags/claude\">claude</a>, <a href=\"https://simonwillison.net/tags/ai\">ai</a>, <a href=\"https://simonwillison.net/tags/claude-code\">claude-code</a>, <a href=\"https://simonwillison.net/tags/llms\">llms</a>, <a href=\"https://simonwillison.net/tags/async-coding-agents\">async-coding-agents</a>, <a href=\"https://simonwillison.net/tags/coding-agents\">coding-agents</a>, <a href=\"https://simonwillison.net/tags/generative-ai\">generative-ai</a>, <a href=\"https://simonwillison.net/tags/projects\">projects</a>, <a href=\"https://simonwillison.net/tags/ai-assisted-programming\">ai-assisted-programming</a></p>",
      "image_url": "",
      "published": "2026-02-16T16:38:57+00:00",
      "collected_at": "2026-02-17T03:00:06.747953+00:00",
      "v2_slot": "practitioner_analysis",
      "freshness": 0.772,
      "source_reliability": 1.0,
      "v2_prefilter_score": 3.022,
      "type": "news",
      "llm_label_source": "heuristic",
      "llm_category": "platform",
      "llm_summary_1line": "I'm a very heavy user of Claude Code on the web , Anthropic's excellent but poorly named cloud version of Claude Code where everything runs in a container environment managed by them, greatly reducing the risk of anyt...",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.75,
      "v2_source_bias": 0.08,
      "v2_topical_bias": 0.2,
      "v2_final_score": 2.733,
      "summary_1line": "I'm a very heavy user of Claude Code on the web , Anthropic's excellent but poorly named cloud version of Claude Code where everything runs in a container environment managed by them, greatly reducing the risk of anyt...",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.621,
      "v2_global_score": 3.354
    },
    {
      "id": "b4a1f65fd2c36642",
      "source": "infoq_ai_ml",
      "source_weight": 1.15,
      "title": "Google Explores Scaling Principles for Multi-agent Coordination",
      "url": "https://www.infoq.com/news/2026/02/google-agent-scaling-principles/?utm_campaign=infoq_content&utm_source=infoq&utm_medium=feed&utm_term=AI%2C+ML+%26+Data+Engineering",
      "summary": "<img src=\"https://res.infoq.com/news/2026/02/google-agent-scaling-principles/en/headerimage/google-scaling-agents-principles-1771231654834.jpeg\" /><p>Google Research tried to answer the question of how to design agent systems for optimal performance by running a controlled evaluation of 180 agent configurations. From this, the team derived what they call the \"first quantitative scaling principles for AI agent systems\", showing that multi-agent coordination does not reliably improve results and can even reduce performance.</p> <i>By Sergio De Simone</i>",
      "image_url": "https://res.infoq.com/news/2026/02/google-agent-scaling-principles/en/headerimage/google-scaling-agents-principles-1771231654834.jpeg",
      "published": "Mon, 16 Feb 2026 09:00:00 GMT",
      "collected_at": "2026-02-17T03:00:06.747953+00:00",
      "v2_slot": "practitioner_analysis",
      "freshness": 0.637,
      "source_reliability": 1.0,
      "v2_prefilter_score": 2.787,
      "type": "news",
      "llm_label_source": "heuristic",
      "llm_category": "platform",
      "llm_summary_1line": "Google Research tried to answer the question of how to design agent systems for optimal performance by running a controlled evaluation of 180 agent configurations. From this, the team derived what they call the \"first...",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.6,
      "v2_source_bias": 0.08,
      "v2_topical_bias": 0.2,
      "v2_final_score": 2.586,
      "summary_1line": "Google derives quantitative scaling principles for multi-agent systems; finds coordination often degrades performance vs. single agents.",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.621,
      "v2_global_score": 3.207
    },
    {
      "id": "30232914ce45f89a",
      "source": "arxiv_cs_ai",
      "source_weight": 0.85,
      "title": "Neuromem: A Granular Decomposition of the Streaming Lifecycle in External Memory for LLMs",
      "url": "http://arxiv.org/abs/2602.13967v1",
      "summary": "Most evaluations of External Memory Module assume a static setting: memory is built offline and queried at a fixed state. In practice, memory is streaming: new facts arrive continuously, insertions interleave with retrievals, and the memory state evolves while the model is serving queries. In this regime, accuracy and cost are governed by the full memory lifecycle, which encompasses the ingestion, maintenance, retrieval, and integration of information into generation. We present Neuromem, a scalable testbed that benchmarks External Memory Modules under an interleaved insertion-and-retrieval protocol and decomposes its lifecycle into five dimensions including memory data structure, normalization strategy, consolidation policy, query formulation strategy, and context integration mechanism. Using three representative datasets LOCOMO, LONGMEMEVAL, and MEMORYAGENTBENCH, Neuromem evaluates interchangeable variants within a shared serving stack, reporting token-level F1 and insertion/retrieval latency. Overall, we observe that performance typically degrades as memory grows across rounds, and time-related queries remain the most challenging category. The memory data structure largely determines the attainable quality frontier, while aggressive compression and generative integration mechanisms mostly shift cost between insertion and retrieval with limited accuracy gain.",
      "image_url": "",
      "published": "2026-02-15T02:53:37Z",
      "collected_at": "2026-02-17T03:00:06.747953+00:00",
      "v2_slot": "research_watch",
      "freshness": 0.651,
      "source_reliability": 1.0,
      "v2_prefilter_score": 2.501,
      "type": "paper",
      "llm_label_source": "heuristic",
      "llm_category": "platform",
      "llm_summary_1line": "Most evaluations of External Memory Module assume a static setting: memory is built offline and queried at a fixed state. In practice, memory is streaming: new facts arrive continuously, insertions interleave with ret...",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 3.4,
      "v2_source_bias": -0.35,
      "v2_topical_bias": 0.2,
      "v2_final_score": 2.838,
      "summary_1line": "Neuromem benchmarks streaming external memory for LLMs under realistic interleaved insert/retrieve workloads, decomposing the lifecycle into five dimensions with token-level F1 metrics.",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.321,
      "v2_global_score": 3.159
    },
    {
      "id": "28aeb3b7d9a1e43f",
      "source": "infoq_ai_ml",
      "source_weight": 1.15,
      "title": "Article: Architecting Agentic MLOps: A Layered Protocol Strategy with A2A and MCP",
      "url": "https://www.infoq.com/articles/architecting-agentic-mlops-a2a-mcp/?utm_campaign=infoq_content&utm_source=infoq&utm_medium=feed&utm_term=AI%2C+ML+%26+Data+Engineering",
      "summary": "<img src=\"https://res.infoq.com/articles/architecting-agentic-mlops-a2a-mcp/en/headerimage/architecting-agentic-mlops-a2a-mcp-header-1770303550343.jpg\" /><p>In this article, the authors outline protocols for building extensible multi-agent MLOps systems. The core architecture deliberately decouples orchestration from execution, allowing teams to incrementally add capabilities via discovery and evolve operations from static pipelines toward intelligent, adaptive coordination.</p> <i>By Shashank Kapoor, Sanjay Surendranath Girija, Lakshit Arora</i>",
      "image_url": "https://res.infoq.com/articles/architecting-agentic-mlops-a2a-mcp/en/headerimage/architecting-agentic-mlops-a2a-mcp-header-1770303550343.jpg",
      "published": "Mon, 16 Feb 2026 09:00:00 GMT",
      "collected_at": "2026-02-17T03:00:06.747953+00:00",
      "v2_slot": "practitioner_analysis",
      "freshness": 0.637,
      "source_reliability": 1.0,
      "v2_prefilter_score": 2.787,
      "type": "news",
      "llm_label_source": "heuristic",
      "llm_category": "platform",
      "llm_summary_1line": "In this article, the authors outline protocols for building extensible multi-agent MLOps systems. The core architecture deliberately decouples orchestration from execution, allowing teams to incrementally add capabili...",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.4,
      "v2_source_bias": 0.08,
      "v2_topical_bias": 0.2,
      "v2_final_score": 2.416,
      "summary_1line": "Layered protocol architecture for multi-agent MLOps decouples orchestration from execution using A2A and MCP for incremental capability expansion.",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.621,
      "v2_global_score": 3.037
    },
    {
      "id": "7b8584bc7c0c7261",
      "source": "arxiv_cs_lg",
      "source_weight": 0.85,
      "title": "When Benchmarks Lie: Evaluating Malicious Prompt Classifiers Under True Distribution Shift",
      "url": "http://arxiv.org/abs/2602.14161v1",
      "summary": "Detecting prompt injection and jailbreak attacks is critical for deploying LLM-based agents safely. As agents increasingly process untrusted data from emails, documents, tool outputs, and external APIs, robust attack detection becomes essential. Yet current evaluation practices and production systems have fundamental limitations. We present a comprehensive analysis using a diverse benchmark of 18 datasets spanning harmful requests, jailbreaks, indirect prompt injections, and extraction attacks. We propose Leave-One-Dataset-Out (LODO) evaluation to measure true out-of-distribution generalization, revealing that the standard practice of train-test splits from the same dataset sources severely overestimates performance: aggregate metrics show an 8.4 percentage point AUC inflation, but per-dataset gaps range from 1% to 25% accuracy-exposing heterogeneous failure modes. To understand why classifiers fail to generalize, we analyze Sparse Auto-Encoder (SAE) feature coefficients across LODO folds, finding that 28% of top features are dataset-dependent shortcuts whose class signal depends on specific dataset compositions rather than semantic content. We systematically compare production guardrails (PromptGuard 2, LlamaGuard) and LLM-as-judge approaches on our benchmark, finding all three fail on indirect attacks targeting agents (7-37% detection) and that PromptGuard 2 and LlamaGuard cannot evaluate agentic tool injection due to architectural limitations. Finally, we show that LODO-stable SAE features provide more reliable explanations for classifier decisions by filtering dataset artifacts. We release our evaluation framework at https://github.com/maxf-zn/prompt-mining to establish LODO as the appropriate protocol for prompt attack detection research.",
      "image_url": "",
      "published": "2026-02-15T14:21:43Z",
      "collected_at": "2026-02-17T03:00:06.747953+00:00",
      "v2_slot": "research_watch",
      "freshness": 0.721,
      "source_reliability": 1.0,
      "v2_prefilter_score": 2.571,
      "type": "paper",
      "llm_label_source": "heuristic",
      "llm_category": "platform",
      "llm_summary_1line": "Detecting prompt injection and jailbreak attacks is critical for deploying LLM-based agents safely. As agents increasingly process untrusted data from emails, documents, tool outputs, and external APIs, robust attack...",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.95,
      "v2_source_bias": -0.35,
      "v2_topical_bias": 0.2,
      "v2_final_score": 2.466,
      "summary_1line": "LODO evaluation reveals prompt injection classifiers overestimate safety by 8.4% AUC; production guardrails fail on agentic tool attacks (7-37% detection).",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.321,
      "v2_global_score": 2.787
    },
    {
      "id": "7bdea70aab3e6e06",
      "source": "openai_codex_releases",
      "source_weight": 2.2,
      "title": "0.101.0",
      "url": "https://github.com/openai/codex/releases/tag/rust-v0.101.0",
      "summary": "<h2>Bug Fixes</h2>\n<ul>\n<li>Model resolution now preserves the requested model slug when selecting by prefix, so model references stay stable instead of being rewritten. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11602\">#11602</a>)</li>\n<li>Developer messages are now excluded from phase-1 memory input, reducing noisy or irrelevant content entering memory. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11608\">#11608</a>)</li>\n<li>Memory phase processing concurrency was reduced to make consolidation/staging more stable under load. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11614\">#11614</a>)</li>\n</ul>\n<h2>Chores</h2>\n<ul>\n<li>Cleaned and simplified the phase-1 memory pipeline code paths. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11605\">#11605</a>)</li>\n<li>Minor repository maintenance: formatting and test-suite hygiene updates in remote model tests. (<a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11619\">#11619</a>)</li>\n</ul>\n<h2>Changelog</h2>\n<p>Full Changelog: <a class=\"commit-link\" href=\"https://github.com/openai/codex/compare/rust-v0.100.0...rust-v0.101.0\"><tt>rust-v0.100.0...rust-v0.101.0</tt></a></p>\n<ul>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11605\">#11605</a> chore: drop and clean from phase 1 <a class=\"user-mention notranslate\" href=\"https://github.com/jif-oai\">@jif-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11602\">#11602</a> fix(core) model_info preserves slug <a class=\"user-mention notranslate\" href=\"https://github.com/dylan-hurd-oai\">@dylan-hurd-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11608\">#11608</a> exclude developer messages from phase-1 memory input <a class=\"user-mention notranslate\" href=\"https://github.com/wendyjiao-openai\">@wendyjiao-openai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11591\">#11591</a> Add cwd to memory files <a class=\"user-mention notranslate\" href=\"https://github.com/wendyjiao-openai\">@wendyjiao-openai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11614\">#11614</a> chore: reduce concurrency of memories <a class=\"user-mention notranslate\" href=\"https://github.com/jif-oai\">@jif-oai</a></li>\n<li><a class=\"issue-link js-issue-link\" href=\"https://github.com/openai/codex/pull/11619\">#11619</a> fix: fmt <a class=\"user-mention notranslate\" href=\"https://github.com/jif-oai\">@jif-oai</a></li>\n</ul>",
      "image_url": "",
      "published": "2026-02-12T21:39:49Z",
      "collected_at": "2026-02-17T03:00:06.747953+00:00",
      "v2_slot": "agent_tooling_releases",
      "freshness": 0.164,
      "source_reliability": 1.0,
      "v2_prefilter_score": 3.364,
      "type": "release",
      "llm_label_source": "heuristic",
      "llm_category": "platform",
      "llm_summary_1line": "Bug Fixes Model resolution now preserves the requested model slug when selecting by prefix, so model references stay stable instead of being rewritten. ( #11602 ) Developer messages are now excluded from phase-1 memor...",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.15,
      "v2_source_bias": 0.0,
      "v2_topical_bias": 0.2,
      "v2_final_score": 1.754,
      "summary_1line": "Bug Fixes Model resolution now preserves the requested model slug when selecting by prefix, so model references stay stable instead of being rewritten. ( #11602 ) Developer messages are now excluded from phase-1 memor...",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.392,
      "v2_global_score": 2.146
    },
    {
      "id": "f75baf298ba21604",
      "source": "anthropic_newsroom",
      "source_weight": 1.8,
      "title": "Bengaluru Office Partnerships Across India",
      "url": "https://www.anthropic.com/news/bengaluru-office-partnerships-across-india",
      "summary": "",
      "image_url": "",
      "published": "2026-02-16T21:31:12.000Z",
      "collected_at": "2026-02-17T03:00:06.747953+00:00",
      "v2_slot": "frontier_official",
      "freshness": 0.796,
      "source_reliability": 1.0,
      "v2_prefilter_score": 3.596,
      "type": "news",
      "llm_label_source": "llm",
      "llm_category": "platform",
      "llm_summary_1line": "Anthropic opens Bengaluru office and announces India partnerships; corporate news with no technical content.",
      "llm_why_1line": "Office/partnership announcement; zero relevance to agentic coding, evals, inference, or platform delivery automation.",
      "v2_llm_score": 0.5,
      "v2_source_bias": 0.06,
      "v2_topical_bias": -0.2,
      "v2_final_score": 0.419,
      "summary_1line": "Bengaluru Office Partnerships Across India",
      "why_it_matters": "Office/partnership announcement; zero relevance to agentic coding, evals, inference, or platform delivery automation.",
      "v2_slot_priority": 0.649,
      "v2_global_score": 1.068
    },
    {
      "id": "fe7dbebc903fef59",
      "source": "anthropic_research",
      "source_weight": 1.4,
      "title": "India Brief Economic Index",
      "url": "https://www.anthropic.com/research/india-brief-economic-index",
      "summary": "",
      "image_url": "",
      "published": "2026-02-16T23:13:32.000Z",
      "collected_at": "2026-02-17T03:00:06.747953+00:00",
      "v2_slot": "research_watch",
      "freshness": 0.967,
      "source_reliability": 1.0,
      "v2_prefilter_score": 3.367,
      "type": "research",
      "llm_label_source": "heuristic",
      "llm_category": "platform",
      "llm_summary_1line": "India Brief Economic Index",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.0,
      "v2_source_bias": 0.4,
      "v2_topical_bias": 0.0,
      "v2_final_score": 2.245,
      "summary_1line": "Anthropic releases India Brief Economic Index, a macroeconomic dataset and analysis tool for Indian economy tracking.",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.321,
      "v2_global_score": 2.566
    },
    {
      "id": "a8257b8b88f12ec0",
      "source": "huggingface_blog",
      "source_weight": 1.1,
      "title": "Custom Kernels for All from Codex and Claude",
      "url": "https://huggingface.co/blog/custom-cuda-kernels-agent-skills",
      "summary": "",
      "image_url": "",
      "published": "Fri, 13 Feb 2026 00:00:00 GMT",
      "collected_at": "2026-02-17T03:00:06.747953+00:00",
      "v2_slot": "research_watch",
      "freshness": 0.413,
      "source_reliability": 1.0,
      "v2_prefilter_score": 2.513,
      "type": "research",
      "llm_label_source": "heuristic",
      "llm_category": "platform",
      "llm_summary_1line": "Custom Kernels for All from Codex and Claude",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.0,
      "v2_source_bias": 0.0,
      "v2_topical_bias": 0.2,
      "v2_final_score": 1.962,
      "summary_1line": "Hugging Face explores using Codex and Claude to auto-generate custom CUDA kernels as agent skills for inference optimization.",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.321,
      "v2_global_score": 2.283
    },
    {
      "id": "4a9f636f53197519",
      "source": "claude_code_releases",
      "source_weight": 2.2,
      "title": "v2.1.44",
      "url": "https://github.com/anthropics/claude-code/releases/tag/v2.1.44",
      "summary": "<h2>What's changed</h2>\n<ul>\n<li>Fixed auth refresh errors</li>\n</ul>",
      "image_url": "",
      "published": "2026-02-16T21:35:03Z",
      "collected_at": "2026-02-17T03:00:06.747953+00:00",
      "v2_slot": "agent_tooling_releases",
      "freshness": 0.908,
      "source_reliability": 1.0,
      "v2_prefilter_score": 4.108,
      "type": "release",
      "llm_label_source": "heuristic",
      "llm_category": "platform",
      "llm_summary_1line": "What's changed Fixed auth refresh errors",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.0,
      "v2_source_bias": 0.0,
      "v2_topical_bias": 0.0,
      "v2_final_score": 1.672,
      "summary_1line": "What's changed Fixed auth refresh errors",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.392,
      "v2_global_score": 2.063
    },
    {
      "id": "bc5a3d616129249c",
      "source": "arxiv_cs_cl",
      "source_weight": 0.8,
      "title": "Index Light, Reason Deep: Deferred Visual Ingestion for Visual-Dense Document Question Answering",
      "url": "http://arxiv.org/abs/2602.14162v1",
      "summary": "Existing multimodal document question answering methods universally adopt a supply-side ingestion strategy: running a Vision-Language Model (VLM) on every page during indexing to generate comprehensive descriptions, then answering questions through text retrieval. However, this \"pre-ingestion\" approach is costly (a 113-page engineering drawing package requires approximately 80,000 VLM tokens), end-to-end unreliable (VLM outputs may fail to be correctly retrieved due to format mismatches in the retrieval infrastructure), and irrecoverable once it fails. This paper proposes the Deferred Visual Ingestion (DVI) framework, adopting a demand-side ingestion strategy: the indexing phase performs only lightweight metadata extraction, deferring visual understanding to the moment users pose specific questions. DVI's core principle is \"Index for locating, not understanding\"--achieving page localization through structured metadata indexes and BM25 full-text search, then sending original images along with specific questions to a VLM for targeted analysis. Experiments on two real industrial engineering drawings (113 pages + 7 pages) demonstrate that DVI achieves comparable overall accuracy at zero ingestion VLM cost (46.7% vs. 48.9%), an effectiveness rate of 50% on visually necessary queries (vs. 0% for pre-ingestion), and 100% page localization (98% search space compression). DVI also supports interactive refinement and progressive caching, transforming the \"QA accuracy\" problem into a \"page localization\" problem--once the correct drawing page is found, obtaining the answer becomes a matter of interaction rounds.",
      "image_url": "",
      "published": "2026-02-15T14:23:50Z",
      "collected_at": "2026-02-17T03:00:06.747953+00:00",
      "v2_slot": "research_watch",
      "freshness": 0.721,
      "source_reliability": 1.0,
      "v2_prefilter_score": 2.521,
      "type": "paper",
      "llm_label_source": "heuristic",
      "llm_category": "platform",
      "llm_summary_1line": "Existing multimodal document question answering methods universally adopt a supply-side ingestion strategy: running a Vision-Language Model (VLM) on every page during indexing to generate comprehensive descriptions, t...",
      "llm_why_1line": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_llm_score": 2.0,
      "v2_source_bias": -0.3,
      "v2_topical_bias": 0.2,
      "v2_final_score": 1.708,
      "summary_1line": "DVI framework defers VLM processing until query time for document QA, reducing indexing costs while improving retrieval on visual-heavy engineering drawings.",
      "why_it_matters": "Potential relevance to AI platform engineering; verify practical impact.",
      "v2_slot_priority": 0.321,
      "v2_global_score": 2.029
    }
  ]
}