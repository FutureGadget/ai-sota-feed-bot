{
  "6e2225d549ed5ae2::v:09cb4491e3": {
    "platform_relevant": true,
    "novelty": 3,
    "practicality": 4,
    "hype": 1,
    "why_1line": "Relevant to AI platform engineering workflows.",
    "__label_source": "heuristic"
  },
  "877d9d2f64c35601::v:09cb4491e3": {
    "platform_relevant": true,
    "novelty": 3,
    "practicality": 4,
    "hype": 1,
    "why_1line": "Relevant to AI platform engineering workflows.",
    "__label_source": "heuristic"
  },
  "d62c6c9a740a083f::v:09cb4491e3": {
    "platform_relevant": true,
    "novelty": 3,
    "practicality": 5,
    "hype": 1,
    "why_1line": "Relevant to AI platform engineering workflows.",
    "__label_source": "heuristic"
  },
  "d171b80d5d104921::v:09cb4491e3": {
    "platform_relevant": true,
    "novelty": 3,
    "practicality": 3,
    "hype": 1,
    "why_1line": "Relevant to AI platform engineering workflows.",
    "__label_source": "heuristic"
  },
  "c3a8163196257d7f::v:09cb4491e3": {
    "platform_relevant": true,
    "novelty": 3,
    "practicality": 3,
    "hype": 1,
    "why_1line": "Relevant to AI platform engineering workflows.",
    "__label_source": "heuristic"
  },
  "82c84921d9c73a9e::v:09cb4491e3": {
    "platform_relevant": true,
    "novelty": 3,
    "practicality": 2,
    "hype": 1,
    "why_1line": "Relevant to AI platform engineering workflows.",
    "__label_source": "heuristic"
  },
  "8bed79565182bbc6::v:09cb4491e3": {
    "platform_relevant": true,
    "novelty": 3,
    "practicality": 3,
    "hype": 1,
    "why_1line": "Relevant to AI platform engineering workflows.",
    "__label_source": "heuristic"
  },
  "b67a55266dc20649::v:09cb4491e3": {
    "platform_relevant": true,
    "novelty": 3,
    "practicality": 3,
    "hype": 1,
    "why_1line": "Relevant to AI platform engineering workflows.",
    "__label_source": "heuristic"
  },
  "1ef2c05d1093cdc8::v:09cb4491e3": {
    "platform_relevant": true,
    "novelty": 3,
    "practicality": 3,
    "hype": 1,
    "why_1line": "Relevant to AI platform engineering workflows.",
    "__label_source": "heuristic"
  },
  "0530f2ee25a8efae::v:09cb4491e3": {
    "platform_relevant": true,
    "novelty": 2,
    "practicality": 3,
    "hype": 1,
    "why_1line": "Relevant to AI platform engineering workflows.",
    "__label_source": "heuristic"
  },
  "f26808a6663f56c4::v:09cb4491e3": {
    "platform_relevant": true,
    "novelty": 3,
    "practicality": 3,
    "hype": 1,
    "why_1line": "Relevant to AI platform engineering workflows.",
    "__label_source": "heuristic"
  },
  "9c10e7e1095fc2e0::v:09cb4491e3": {
    "platform_relevant": true,
    "novelty": 3,
    "practicality": 3,
    "hype": 1,
    "why_1line": "Relevant to AI platform engineering workflows.",
    "__label_source": "heuristic"
  },
  "7cd095f5f55dba53::v:09cb4491e3": {
    "platform_relevant": true,
    "novelty": 3,
    "practicality": 3,
    "hype": 1,
    "why_1line": "Relevant to AI platform engineering workflows.",
    "__label_source": "heuristic"
  },
  "0b6403585fa5c6b3::v:09cb4491e3": {
    "platform_relevant": true,
    "novelty": 3,
    "practicality": 3,
    "hype": 1,
    "why_1line": "Relevant to AI platform engineering workflows.",
    "__label_source": "heuristic"
  },
  "671420a2a130cda5::v:09cb4491e3": {
    "platform_relevant": true,
    "novelty": 3,
    "practicality": 3,
    "hype": 1,
    "why_1line": "Relevant to AI platform engineering workflows.",
    "__label_source": "heuristic"
  },
  "ebc920b10350277a::v:09cb4491e3": {
    "platform_relevant": true,
    "novelty": 3,
    "practicality": 3,
    "hype": 1,
    "why_1line": "Relevant to AI platform engineering workflows.",
    "__label_source": "heuristic"
  },
  "5eb1dc4c2b27f35b::v:09cb4491e3": {
    "platform_relevant": true,
    "novelty": 2,
    "practicality": 3,
    "hype": 1,
    "why_1line": "Relevant to AI platform engineering workflows.",
    "__label_source": "heuristic"
  },
  "8c7ff1a869d5d3eb::v:09cb4491e3": {
    "platform_relevant": true,
    "novelty": 2,
    "practicality": 3,
    "hype": 1,
    "why_1line": "Relevant to AI platform engineering workflows.",
    "__label_source": "heuristic"
  },
  "12180bace4bd6103::v:09cb4491e3": {
    "platform_relevant": false,
    "novelty": 2,
    "practicality": 1,
    "hype": 1,
    "why_1line": "Potentially relevant; low direct platform signal.",
    "__label_source": "heuristic"
  },
  "57a72ed8051ad7b3::v:09cb4491e3": {
    "platform_relevant": true,
    "novelty": 2,
    "practicality": 2,
    "hype": 1,
    "why_1line": "Relevant to AI platform engineering workflows.",
    "__label_source": "heuristic"
  },
  "6e2225d549ed5ae2::v:8df1fd40d0": {
    "platform_relevant": true,
    "novelty": 4,
    "practicality": 5,
    "hype": 2,
    "why_1line": "Major serving upgrade: big throughput gains, breaking deps, reliability fixes, and broad infra/kernel changes.",
    "__label_source": "llm"
  },
  "877d9d2f64c35601::v:8df1fd40d0": {
    "platform_relevant": true,
    "novelty": 4,
    "practicality": 5,
    "hype": 2,
    "why_1line": "High-impact serving release: scheduler/cache/kernel/API upgrades with clear latency, throughput, reliability gains.",
    "__label_source": "llm"
  },
  "d62c6c9a740a083f::v:8df1fd40d0": {
    "platform_relevant": true,
    "novelty": 3,
    "practicality": 4,
    "hype": 1,
    "why_1line": "Infra-relevant Triton release: modest perf gain plus many concrete reliability/compatibility caveats.",
    "__label_source": "llm"
  },
  "d171b80d5d104921::v:8df1fd40d0": {
    "platform_relevant": true,
    "novelty": 3,
    "practicality": 4,
    "hype": 1,
    "why_1line": "Triton release adds tuning/stability knobs and perf metrics, with many known issues critical for prod ops.",
    "__label_source": "llm"
  },
  "c3a8163196257d7f::v:8df1fd40d0": {
    "platform_relevant": true,
    "novelty": 4,
    "practicality": 4,
    "hype": 2,
    "why_1line": "Streaming ASR with bounded-latency local attention is deployable infra-relevant for low-TTFT edge serving.",
    "__label_source": "llm"
  },
  "82c84921d9c73a9e::v:8df1fd40d0": {
    "platform_relevant": true,
    "novelty": 3,
    "practicality": 5,
    "hype": 1,
    "why_1line": "High deploy impact: security patches, GPU/kernel fixes, and major cold-start latency reduction in vLLM serving.",
    "__label_source": "llm"
  },
  "8bed79565182bbc6::v:8df1fd40d0": {
    "platform_relevant": true,
    "novelty": 2,
    "practicality": 4,
    "hype": 1,
    "why_1line": "Mostly reliability/security/retry fixes and cost guardrails; useful ops upgrade, limited new architecture.",
    "__label_source": "llm"
  },
  "b67a55266dc20649::v:8df1fd40d0": {
    "platform_relevant": true,
    "novelty": 3,
    "practicality": 5,
    "hype": 1,
    "why_1line": "High deployability impact: security/reliability fixes, new metrics, and concrete serving known-issues/workarounds.",
    "__label_source": "llm"
  },
  "1ef2c05d1093cdc8::v:8df1fd40d0": {
    "platform_relevant": true,
    "novelty": 3,
    "practicality": 5,
    "hype": 1,
    "why_1line": "Triton 2.64 adds concrete serving/reliability fixes (readiness, crash race, OpenAI API stable, multi-LoRA) with deploy caveats.",
    "__label_source": "llm"
  },
  "0530f2ee25a8efae::v:8df1fd40d0": {
    "platform_relevant": true,
    "novelty": 2,
    "practicality": 3,
    "hype": 4,
    "why_1line": "Inference cost/latency is platform-relevant, but this reads like vendor marketing with limited deployable depth.",
    "__label_source": "llm"
  },
  "f26808a6663f56c4::v:8df1fd40d0": {
    "platform_relevant": true,
    "novelty": 3,
    "practicality": 4,
    "hype": 1,
    "why_1line": "Operationally useful Triton serving update: OpenAI API tweaks plus many concrete reliability/security caveats.",
    "__label_source": "llm"
  },
  "9c10e7e1095fc2e0::v:8df1fd40d0": {
    "platform_relevant": true,
    "novelty": 2,
    "practicality": 4,
    "hype": 1,
    "why_1line": "Infra-relevant Triton patch: crash fixes and many known serving caveats impacting prod reliability.",
    "__label_source": "llm"
  },
  "7cd095f5f55dba53::v:8df1fd40d0": {
    "platform_relevant": true,
    "novelty": 2,
    "practicality": 4,
    "hype": 1,
    "why_1line": "Infra-relevant Triton release: security/auth hardening + many deployment caveats impacting reliability/ops.",
    "__label_source": "llm"
  },
  "0b6403585fa5c6b3::v:8df1fd40d0": {
    "platform_relevant": true,
    "novelty": 2,
    "practicality": 4,
    "hype": 1,
    "why_1line": "Infra-relevant Triton update (CUDA 13 + many caveats), useful for serving ops but low new feature depth.",
    "__label_source": "llm"
  },
  "671420a2a130cda5::v:8df1fd40d0": {
    "platform_relevant": true,
    "novelty": 2,
    "practicality": 4,
    "hype": 1,
    "why_1line": "Minor Triton patch: security fixes + many serving caveats; useful for ops reliability, low new capability.",
    "__label_source": "llm"
  },
  "ebc920b10350277a::v:8df1fd40d0": {
    "platform_relevant": true,
    "novelty": 3,
    "practicality": 5,
    "hype": 1,
    "why_1line": "High deployability impact: Triton serving/memory/metrics updates plus critical vLLM stability/security caveats.",
    "__label_source": "llm"
  },
  "5eb1dc4c2b27f35b::v:8df1fd40d0": {
    "platform_relevant": false,
    "novelty": 4,
    "practicality": 2,
    "hype": 2,
    "why_1line": "Strong VLA verification idea, but robotics-focused and weakly applicable to coding-agent platform workflows.",
    "__label_source": "llm"
  },
  "8c7ff1a869d5d3eb::v:8df1fd40d0": {
    "platform_relevant": true,
    "novelty": 4,
    "practicality": 5,
    "hype": 2,
    "why_1line": "Dynamic uncertainty-based compute allocation for web agents boosts success while cutting tokens; directly useful for serving/cost.",
    "__label_source": "llm"
  },
  "12180bace4bd6103::v:8df1fd40d0": {
    "platform_relevant": false,
    "novelty": 4,
    "practicality": 2,
    "hype": 3,
    "why_1line": "Strong kernel/attention work for video diffusion, but weak fit for coding-agent automation platform needs.",
    "__label_source": "llm"
  },
  "57a72ed8051ad7b3::v:8df1fd40d0": {
    "platform_relevant": true,
    "novelty": 4,
    "practicality": 3,
    "hype": 2,
    "why_1line": "Promising few-step DLLM speed/quality gains for serving, but limited immediate coding-agent workflow impact.",
    "__label_source": "llm"
  }
}